[
  {
    "objectID": "reality-checks/rc01/rc01.html",
    "href": "reality-checks/rc01/rc01.html",
    "title": "Reality Check 1",
    "section": "",
    "text": "PROBLEM 1\n\n\nWrite a python function for f(\\theta). The parameters L_1, L_2, L_3, \\gamma, x_1, x_2, y_2 are fixed constants, and the strut lengths p_1, p_2, p_3 will be known for a given pose. To test your code, set the parameters L_1 = 2, L_2 = L_3 = \\sqrt{2}, \\gamma = \\pi/2, and p_1 = p_2 = p_3 = \\sqrt{5}. Then, substituting \\theta = -\\pi/4 or \\theta = \\pi/4, should make f(\\theta) = 0.\nI implemented the Python function f(\\theta) by putting all fixed constants into a Constants object. I initialized the constants with the given values in order to verify that \\theta = -\\pi/4 and \\theta = \\pi/4 were roots.\n\n\nCreate function for f(\\theta)\n\n\nShow code\n# Define the function f(θ) that calculates based on given constants and angle θ\ndef f(theta, constants):\n    \"\"\"\n    Calculates a value based on the given angle theta and constants object.\n\n    Parameters:\n    theta (float): The angle in radians.\n    constants (Constants): An object containing the necessary constants.\n\n    Returns:\n    float: The calculated result.\n    \"\"\"\n    l1, l2, l3 = constants.l1, constants.l2, constants.l3\n    gamma = constants.gamma\n    x1, x2, y2 = constants.x1, constants.x2, constants.y2\n    p1, p2, p3 = constants.p1, constants.p2, constants.p3\n\n    a2 = l3 * np.cos(theta) - x1\n    b2 = l3 * np.sin(theta)\n    a3 = l2 * np.cos(theta + gamma) - x2\n    b3 = l2 * np.sin(theta + gamma) - y2\n    d = 2 * (a2 * b3 - b2 * a3)\n\n    n1 = b3 * (p2**2 - p1**2 - a2**2 - b2**2) - b2 * (p3**2 - p1**2 - a3**2 - b3**2)\n    n2 = -a3 * (p2**2 - p1**2 - a2**2 - b2**2) + a2 * (p3**2 - p1**2 - a3**2 - b3**2)\n\n    return n1**2 + n2**2 - p1**2 * d**2\n\n\n\n\nTest function f(\\theta)\n\n\nShow code\n# Define constants and evaluate f(θ) at a specific angle θ = π/4 for testing purposes\nconstants = Constants(\n    l1=2,\n    l2=np.sqrt(2),\n    l3=np.sqrt(2),\n    gamma=np.pi / 2,\n    x1=4,\n    x2=0,\n    y2=4,\n    p1=np.sqrt(5),\n    p2=np.sqrt(5),\n    p3=np.sqrt(5)\n)\n\ntheta = np.pi / 4\n# Evaluate\nresult = f(theta, constants)\nprint(f'f(θ=π/4) = {result}')\n\n\nf(θ=π/4) = -4.547473508864641e-13\n\n\n\n\n\nPROBLEM 2\n\n\nPlot f(\\theta) on [-\\pi, \\pi]\nI plotted the function f(\\theta) over the interval [-π, π] by generating a range of \\theta values and computing f(\\theta) for each. The graph clearly shows the behavior of f(\\theta) and highlights that the the roots identified in Problem 1 are in fact roots.\n\n\nCreate Plot\n\n\nShow code\n# Generate a range of theta values and compute f(θ) for each value to visualize the function\ntheta_values = np.linspace(-np.pi, np.pi, 400)\nresults = [f(theta, constants) for theta in theta_values]\n\n# Plot f(θ) over the range of theta values\nplt.figure(figsize=(10, 6))\nplt.plot(theta_values, results, label=r'$f(\\theta)$', linewidth=2)\nplt.axhline(0, color='black', linestyle='--', linewidth=0.8)\nplt.axvline(-np.pi/4, color='red', linestyle=':', linewidth=2, label=r'$\\theta = -\\pi/4$')\nplt.axvline(np.pi/4, color='red', linestyle=':', linewidth=2, label=r'$\\theta = \\pi/4$')\nplt.xlabel(r'$\\theta$', fontsize=14)\nplt.ylabel(r'$f(\\theta)$', fontsize=14)\nplt.title(r'Function of $\\theta$ for Stewart Platform', fontsize=16)\nplt.legend(fontsize=12)\nplt.grid(True)\n\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\nPROBLEM 3\n\n\nReproduce Figure 1.15. Plot a red triangle with vertices (u_1, v_1), (u_2, v_2), (u_3, v_3) and place small blue circles at the strut anchor points (0,0), (x_1, 0), (x_2, y_2):\nI utilized several helper functions to efficiently calculate and visualize the Stewart platform’s configuration. The get_x_y() function computes the x and y coordinates based on the given angle \\theta and the fixed constants, determining the position of one vertex of the triangle. The get_points() function then takes these coordinates, along with \\theta and the constants, to calculate the two other vertices of the red triangle. The get_anchor_points() function gets the fixed anchor points (0,0), (x_1, 0), and (x_2, y_2). The plot_triangle() function takes the calculated triangle vertices and anchor points to plot the red triangle and connect the anchor points with blue lines, while also marking the anchor points with blue circles.\n\n\nCreate Helper Functions\n\n\nShow code\n# Define helper functions for calculating x, y coordinates and plotting the Stewart platform triangle\ndef get_x_y(theta, constants):\n    \"\"\"\n    Returns the coordinates x and y for the given angle theta and constants object.\n\n    Parameters:\n    theta (float): The angle in radians.\n    constants (Constants): An object containing the necessary constants.\n\n    Returns:\n    tuple: The coordinates (x, y).\n    \"\"\"\n    l1, l2, l3 = constants.l1, constants.l2, constants.l3\n    gamma = constants.gamma\n    x1, x2, y2 = constants.x1, constants.x2, constants.y2\n    p1, p2, p3 = constants.p1, constants.p2, constants.p3\n\n    a2 = l3 * np.cos(theta) - x1\n    b2 = l3 * np.sin(theta)\n    a3 = l2 * np.cos(theta + gamma) - x2\n    b3 = l2 * np.sin(theta + gamma) - y2\n\n    d = 2 * (a2 * b3 - b2 * a3)\n    n1 = b3 * (p2**2 - p1**2 - a2**2 - b2**2) - b2 * (p3**2 - p1**2 - a3**2 - b3**2)\n    n2 = -a3 * (p2**2 - p1**2 - a2**2 - b2**2) + a2 * (p3**2 - p1**2 - a3**2 - b3**2)\n\n    x = n1 / d\n    y = n2 / d\n\n    return x, y\n\n\ndef get_points(x, y, theta, constants):\n    \"\"\"\n    Calculate the three points (vertices) of the triangle in the Stewart platform based on x, y, and θ.\n\n    Parameters:\n    x (float): The x-coordinate.\n    y (float): The y-coordinate.\n    theta (float): The angle in radians.\n    constants (Constants): Object containing the necessary constants.\n\n    Returns:\n    list: A list containing the three vertices (l1_point, l2_point, l3_point) of the triangle.\n    \"\"\"\n    l1, l2, l3 = constants.l1, constants.l2, constants.l3\n    gamma = constants.gamma\n\n    # First vertex (base point)\n    l1_point = (x, y)\n\n    # Second vertex of the triangle\n    l2_x = x + (l3 * np.cos(theta))\n    l2_y = y + (l3 * np.sin(theta))\n    l2_point = (np.round(l2_x, 3), np.round(l2_y))  # Rounded to 3 decimal places for clarity\n\n    # Third vertex of the triangle\n    l3_x = x + (l2 * np.cos(theta + gamma))\n    l3_y = y + (l2 * np.sin(theta + gamma))\n    l3_point = (np.round(l3_x), np.round(l3_y))  # Rounded to 3 decimal places for clarity\n\n    return [l1_point, l2_point, l3_point]\n\ndef get_anchor_points(constants):\n    \"\"\"\n    Get the anchor points for the Stewart platform based on the constants.\n\n    Parameters:\n    constants (Constants): Object containing the necessary constants.\n\n    Returns:\n    list: A list of tuples representing the anchor points.\n    \"\"\"\n    x1, x2, y2 = constants.x1, constants.x2, constants.y2\n\n    return [(0, 0), (x1, 0), (x2, y2)]\n\ndef plot_triangle(ax, points, anchor_points, x_limits=None, y_limits=None, x_step=None, y_step=None):\n    \"\"\"\n    Plots a triangle given the points and anchor points on the provided axis.\n\n    Parameters:\n    ax: The axis on which to plot the triangle.\n    points: The points of the triangle (list of 3 points).\n    anchor_points: The anchor points (list of 2 or more points).\n    x_limits (tuple, optional): Tuple specifying the x-axis limits (x_min, x_max).\n    y_limits (tuple, optional): Tuple specifying the y-axis limits (y_min, y_max).\n    x_step (float, optional): Step size for the x-axis grid.\n    y_step (float, optional): Step size for the y-axis grid.\n\n    Returns:\n    None\n    \"\"\"\n    points = np.array(points)\n    anchor_points = np.array(anchor_points)\n\n    # Extract x and y coordinates for the triangle points\n    x_coords = points[:, 0]\n    y_coords = points[:, 1]\n\n    # Close the triangle by appending the first point at the end\n    x_closed = np.append(x_coords, x_coords[0])\n    y_closed = np.append(y_coords, y_coords[0])\n\n    # Plot the triangle with red lines\n    ax.plot(x_closed, y_closed, 'r-', linewidth=3.5)\n\n    # Plot blue dots at the triangle vertices\n    ax.plot(x_coords, y_coords, 'bo', markersize=8)\n\n    # Plot lines from anchor points to triangle points\n    for i, anchor in enumerate(anchor_points):\n        if i &lt; len(points):  # Ensure we stay within bounds\n            ax.plot([anchor[0], points[i, 0]], [anchor[1], points[i, 1]], 'b-', linewidth=1.5)\n\n    # Plot blue dots at the anchor points\n    ax.plot(anchor_points[:, 0], anchor_points[:, 1], 'bo', markersize=8)\n\n    # Set axis labels\n    ax.set_xlabel(\"x\")\n    ax.set_ylabel(\"y\")\n\n    # Set x-axis limits if provided\n    if x_limits is not None:\n        ax.set_xlim(x_limits)\n    # Set y-axis limits if provided\n    if y_limits is not None:\n        ax.set_ylim(y_limits)\n    # Set grid step increments if limits are provided\n    if x_step is not None and x_limits is not None:\n        ax.set_xticks(np.arange(x_limits[0], x_limits[1] + x_step, x_step))  # Adjust x-axis ticks\n    if y_step is not None and y_limits is not None:\n        ax.set_yticks(np.arange(y_limits[0], y_limits[1] + y_step, y_step))  # Adjust y-axis ticks\n\n    # Add grid for better visualization\n    ax.grid(True)\n\n\n\n\nCreate Plot\n\n\nShow code\n# Create a plot to visualize the Stewart platform configurations for two different angles\ntheta = np.pi / 4\ntheta_negative = -np.pi / 4\n\n# Calculate the coordinates and points for the triangles\nx, y = get_x_y(theta_negative, constants)\npoints1 = get_points(x, y, theta_negative, constants)\nanchor_points = get_anchor_points(constants)\n\nx, y = get_x_y(theta, constants)\npoints2 = get_points(x, y, theta, constants)\n\n# Create side-by-side subplots to visualize the two triangles\nfig, axes = plt.subplots(1, 2, figsize=(11, 5))\n\n# Plot the triangles on each subplot\nplot_triangle(axes[0], points1, anchor_points, x_limits=(-0.25, 4.25), y_limits=(-0.25, 4.25))\nplot_triangle(axes[1], points2, anchor_points, x_limits=(-0.25, 4.25), y_limits=(-0.25, 4.25))\n\nplt.tight_layout()\nplt.savefig('stewart_platform_two_triangles_plot.png', dpi=300, bbox_inches='tight')\n\n\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\nPROBLEM 4\n\n\nSolve the forward kinematics problem for the planar Stewart platform specified by x_1 = 5, (x_2, y_2) = (0,6), L_1 = L_3 = 3, L_2 = 3\\sqrt{2}, \\gamma = \\pi / 4, p_1 = p_2 = 5, p_3 = 3. Begin by plotting f(\\theta). Use an equation solver of your choice to find all four poses (roots of f(\\theta)), and plot them. Check your answers by verifying that p_1, p_2, p_3 are the lengths of the struts in your plot.\nI organized all the fixed parameters into a Constants object and plotted the function f(\\theta) over the interval [-π, π] to visualize its behavior. Using the fsolve function with strategically chosen initial guesses, I identified all four roots of f(\\theta), each root representing a unique pose of the Stewart platform. For each detected root, I plotted the corresponding triangle configuration and verified that the strut lengths p_1, p_2, p_3 matched the expected values.\n\n\n4A)\n\n\nShow code\n# Create new constants object\nconstants = Constants(\n    l1=3,\n    l2=3 * np.sqrt(2),\n    l3=3,\n    gamma=np.pi / 4,\n    x1=5,\n    x2=0,\n    y2=6,\n    p1=5,\n    p2=5,\n    p3=3\n)\n\n# Generate an array of θ values between -π and π\ntheta_values = np.linspace(-np.pi, np.pi, 400)\n\n# Plot the function f(θ) over the range of θ values using the given constants\nplt.figure(figsize=(10, 6))\nplt.plot(theta_values, f(theta_values, constants), label=r'$f(\\theta)$')\nplt.axhline(0, color='black', linestyle='--', linewidth=0.8)\nplt.xlabel(r'$\\theta$', fontsize=14)\nplt.ylabel(r'$f(\\theta)$', fontsize=14)\nplt.title(r'Function of $\\theta$ for Stewart Platform', fontsize=16)\nplt.legend(fontsize=12)\nplt.grid(True)\n\n\n\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n4B)\n\n\nShow code\n# Function to find roots of f(θ) using fsolve\ndef find_roots(constants, initial_guesses):\n    \"\"\"\n    Finds roots of f(θ) using different initial guesses and the fsolve method.\n\n    Parameters:\n    constants (Constants): Object containing the necessary constants.\n    initial_guesses (list or array): List of initial guesses for fsolve to start from.\n\n    Returns:\n    list: A list of unique roots.\n    \"\"\"\n\n    # Create an empty list to store the roots found\n    roots = []\n    # Iterate over each initial guess and find the root using fsolve\n    for guess in initial_guesses:\n        root = fsolve(f, guess, args=(constants), xtol=1e-12)[0] # Find root for each guess\n        roots.append(root) # Append the found root to the list\n\n    # Return only unique roots to avoid duplicates\n    unique_roots = np.unique(roots)\n    return unique_roots\n\n# Define initial guesses for fsolve to start the root-finding process\ninitial_guesses = [- 1, np.pi / 3, .5, 2]\n\n# Find and print the roots using the initial guesses\nroots = find_roots(constants, initial_guesses)\nprint(f\"The roots of f(θ) in the interval are : {roots}\")\n\n# Function to calculate the length of the struts\ndef calculate_strut_lengths(points, anchor_points):\n    lengths = []\n    # Loop through the 3 points and calculate the Euclidean distance to each corresponding anchor point\n    for i in range(3):\n        length = np.sqrt((points[i][0] - anchor_points[i][0])**2 + (points[i][1] - anchor_points[i][1])**2)\n        lengths.append(length) # Append each calculated length to the list\n    return lengths\n\n\nThe roots of f(θ) in the interval are : [-0.7208492  -0.33100518  1.14368552  2.11590901]\n\n\n\n\nShow code\n# Create a 2x2 grid of subplots to visualize the four roots and their corresponding triangles\nfig, axes = plt.subplots(2, 2, figsize=(10, 10))\naxes = axes.flatten() # Flatten the 2D array of subplots into a 1D array for easier access\n\n# Get the anchor points for the Stewart platform\nanchor_points = get_anchor_points(constants)\n\n# Loop through up to four roots and plot the corresponding triangles\nfor i, theta in enumerate(roots[:4]):\n    x, y = get_x_y(theta, constants)\n    points = get_points(x, y, theta, constants)\n\n    # Plot the triangle in the corresponding subplot with custom limits\n    plot_triangle(axes[i], points, anchor_points, x_limits=(-2.5, 7.5), y_limits=(-2, 7), x_step=2.5, y_step=2)\n    axes[i].set_title(rf\"$\\theta$ = {theta}\")\n\n    # Calculate and verify strut lengths\n    lengths = calculate_strut_lengths(points, anchor_points)\n    print(f\"For root {np.round(theta, 3)}, strut lengths are: {np.round(lengths)}\")\n    print(f\"Expected: p1={constants.p1}, p2={constants.p2}, p3={constants.p3}\\n\")\n\n# Turn off any unused subplots if fewer than four roots\nfor j in range(len(roots), 4):\n    axes[j].axis('off')\n\n# Adjust layout\nplt.tight_layout()\n\nplt.savefig('p4_function_plot.png', dpi=300, bbox_inches='tight')\nplt.show()\n\n\nFor root -0.721, strut lengths are: [5. 5. 3.]\nExpected: p1=5, p2=5, p3=3\n\nFor root -0.331, strut lengths are: [5. 5. 3.]\nExpected: p1=5, p2=5, p3=3\n\nFor root 1.144, strut lengths are: [5. 5. 3.]\nExpected: p1=5, p2=5, p3=3\n\nFor root 2.116, strut lengths are: [5. 5. 3.]\nExpected: p1=5, p2=5, p3=3\n\n\n\n\n\n\n\n\n\n\n\n\n\nPROBLEM 5\n\n\nChange strut length to p_2 = 7 and re-solve the problem. For these parameters, there are six poses.\nI updated the strut length p_2 to 7 and re-solved the forward kinematics for the Stewart platform. To do that I modified the Constants object with the new p_2 value and plotted the updated function f(\\theta) over the interval [-π, π] to see its behavior. I made a new set of initial guesses for the find_roots() function and successfully found all six roots corresponding to six possible poses. For each root, I plotted the corresponding triangle configuration and verified that the strut lengths p_1, p_2, p_3 matched the expected values.\n\n\n5A)\n\n\nShow code\n# Update the constants to reflect the new strut length p2 = 7\nconstants = Constants(\n    l1=3,\n    l2=3 * np.sqrt(2),\n    l3=3,\n    gamma=np.pi / 4,\n    x1=5,\n    x2=0,\n    y2=6,\n    p1=5,\n    p2=7,\n    p3=3\n)\n\n# Generate the θ values again to visualize the updated f(θ)\ntheta_values = np.linspace(-np.pi, np.pi, 400)\n\n# Plot f(θ) for the new strut length\nplt.figure(figsize=(10, 6))\nplt.plot(theta_values, f(theta_values, constants), label=r'$f(\\theta)$')\nplt.axhline(0, color='black', linestyle='--', linewidth=0.8)\nplt.xlabel(r'$\\theta$', fontsize=14)\nplt.ylabel(r'$f(\\theta)$', fontsize=14)\nplt.title(r'Function of $\\theta$ for Stewart Platform', fontsize=16)\nplt.legend(fontsize=12)\nplt.grid(True)\n\n\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n5B)\n\n\nShow code\n# Provide new initial guesses to find six distinct roots for this configuration\ninitial_guesses = [-.7, -.4, .01, .4, .9, 2.5 ]  # Customize this list\n\n# Find and print the roots using the initial guesses\nroots = find_roots(constants, initial_guesses)\nprint(f\"The roots of f(θ) in the interval are : {roots}\")\n\n# Set up the 2x3 grid for plotting the six poses\nfig, axes = plt.subplots(2, 3, figsize=(9, 6))  # Create a 2x3 grid\naxes = axes.flatten()  # Flatten the 2D array of axes for easier access\n\n# Get the anchor points\nanchor_points = get_anchor_points(constants)\n\n# Loop through the six roots and plot each pose\nfor i, theta in enumerate(roots[:6]):\n    x, y = get_x_y(theta, constants)\n    points = get_points(x, y, theta, constants)\n    # Plot the triangle in the corresponding subplot with custom limits\n    plot_triangle(axes[i], points, anchor_points, x_limits=(-5.5, 5.5), y_limits=(-.5, 10), )\n    axes[i].set_title(rf\"$\\theta$ = {theta}\")\n\n    # Calculate and verify strut lengths\n    lengths = calculate_strut_lengths(points, anchor_points)\n    print(f\"For root {np.round(theta, 3)}, strut lengths are: {np.round(lengths)}\")\n    print(f\"Expected: p1={constants.p1}, p2={constants.p2}, p3={constants.p3}\\n\")\n\n# Turn off any unused subplots (though in this case, we should have exactly 6)\nfor j in range(len(roots), 6):\n    axes[j].axis('off')\n\n# Adjust layout\nplt.tight_layout()\n\n\nplt.show()\n\n\nThe roots of f(θ) in the interval are : [-0.67315749 -0.35474027  0.03776676  0.45887818  0.9776729   2.5138528 ]\nFor root -0.673, strut lengths are: [5. 7. 3.]\nExpected: p1=5, p2=7, p3=3\n\nFor root -0.355, strut lengths are: [5. 7. 3.]\nExpected: p1=5, p2=7, p3=3\n\nFor root 0.038, strut lengths are: [5. 7. 3.]\nExpected: p1=5, p2=7, p3=3\n\nFor root 0.459, strut lengths are: [5. 7. 3.]\nExpected: p1=5, p2=7, p3=3\n\nFor root 0.978, strut lengths are: [5. 7. 3.]\nExpected: p1=5, p2=7, p3=3\n\nFor root 2.514, strut lengths are: [5. 7. 3.]\nExpected: p1=5, p2=7, p3=3\n\n\n\n\n\n\n\n\n\n\n\n\n\nPROBLEM 6\n\n\nFind a strut length p_2, with the rest of the parameters as in Step 4, for which there are only two poses.\nTo identify a strut length for p_2 that results in exactly two poses for the Stewart platform I systematically adjusted p_2 and utilizing the fsolve function to find the corresponding roots of the function f(\\theta). This method enabled me to determine a specific p_2 value that achieves the desired two-pose configuration.\n\n\nShow code\n# Set a threshold for considering a valid root (how close to zero we want f(theta) to be)\nROOT_THRESHOLD = 1e-6\n\n# Function to find roots for a given p2, and check if they are valid\ndef find_roots_for_p2(p2_value, constants, initial_guesses, ax=None):\n    \"\"\"\n    Adjusts p2 in the constants object, finds the roots, and returns the number of unique roots.\n    Also plots f(theta) for the current p2 value on the provided axis.\n    \"\"\"\n    # Update p2 in constants\n    constants.p2 = p2_value\n\n    # Generate theta values and compute f(theta)\n    theta_values = np.linspace(-np.pi, np.pi, 400)\n    f_values = [f(theta, constants) for theta in theta_values]\n\n    # Plot f(theta) for the current p2 value on the provided axis\n    ax.plot(theta_values, f_values,)\n    ax.axhline(0, color='black', linestyle='--', linewidth=0.8)\n    ax.set_xlabel(r'$\\theta$', fontsize=14)\n    ax.set_ylabel(r'$f(\\theta)$', fontsize=14)\n    ax.set_title(fr'$p_2 = {p2_value:.3f}$')\n    ax.legend(fontsize=10)\n    ax.grid(True)\n\n    # Find the roots for the given p2 value\n    roots = []\n    for guess in initial_guesses:\n        root = fsolve(f, guess, args=(constants))[0]\n\n        # Check if the found root is valid (i.e., f(root) is close to zero)\n        if abs(f(root, constants)) &lt; ROOT_THRESHOLD:\n            roots.append(root)\n\n    # Convert to numpy array and round the roots to avoid precision issues\n    roots = np.round(np.array(roots), decimals=6)\n    unique_roots = np.unique(roots)\n\n    # Print the number of valid roots and the roots themselves\n    print(f\"p2 = {p2_value:.3f}: Found {len(unique_roots)} valid roots: {unique_roots}\")\n\n    return unique_roots\n\n# Function to iterate over possible p2 values and append plots in a grid (wrap after 3)\ndef find_p2_with_two_roots(constants, initial_guesses, p2_start=-1, total_plots=6):\n    \"\"\"\n    Iterates over possible p2 values starting at p2_start, plots f(theta), and prints the number of roots.\n    The plots wrap after 3 per row.\n\n    Parameters:\n    - constants: The Constants object.\n    - initial_guesses: List of initial guesses for root finding.\n    - p2_start: Starting value of p2.\n    - total_plots: Number of plots to show before stopping.\n    \"\"\"\n    p2 = p2_start\n    plot_count = 0\n    max_plots_per_row = 3  # Wrap after 3 plots per row\n\n    # Calculate the number of rows needed (wrap after 3)\n    num_rows = (total_plots + max_plots_per_row - 1) // max_plots_per_row\n\n    # Create a figure with a 3xN grid\n    fig, axes = plt.subplots(num_rows, max_plots_per_row, figsize=(11, num_rows * 3))\n    axes = axes.flatten()  # Flatten the 2D array of axes for easier access\n    fig.subplots_adjust(hspace=0.3, wspace=0.3)  # Adjust the space between subplots\n\n    # Iterate to plot p2 and find roots\n    while plot_count &lt; total_plots:\n        # Plot for the current p2 value and check the roots\n        unique_roots = find_roots_for_p2(p2, constants, initial_guesses, ax=axes[plot_count])\n\n        if len(unique_roots) == 2:  # Check if there are exactly 2 unique roots\n            print(f\"Found p2={p2} with two distinct roots: {unique_roots}\")\n\n        # Increment p2 and plot the next iteration\n        p2 += 1\n        plot_count += 1\n\n    # Show the final figure with all appended plots\n    plt.tight_layout()\n\n\n    plt.show()\n\n# Example constants (with p2 placeholder)\nconstants = Constants(\n    l1=3,\n    l2=3 * np.sqrt(2),\n    l3=3,\n    gamma=np.pi / 4,\n    x1=5,\n    x2=0,\n    y2=6,\n    p1=5,\n    p2=None,  # To be found\n    p3=3\n)\n\n# Initial guesses for root finding\ninitial_guesses = [-np.pi/2, 0, np.pi/2]\n\n# Start p2 at -1 and increment by 1 each time, looking for exactly 2 roots\nfind_p2_with_two_roots(constants, initial_guesses, p2_start=-1, total_plots=6)\n\n\np2 = -1.000: Found 0 valid roots: []\np2 = 0.000: Found 0 valid roots: []\np2 = 1.000: Found 0 valid roots: []\np2 = 2.000: Found 0 valid roots: []\np2 = 3.000: Found 0 valid roots: []\np2 = 4.000: Found 2 valid roots: [1.331642 1.777514]\nFound p2=4 with two distinct roots: [1.331642 1.777514]\n\n\n\n\n\n\n\n\n\n\n\n\nPROBLEM 7\n\n\nCalculate the intervals in p_2, with the rest of the parameters as in Step 4, for which there are 0, 2, 4, and 6 poses, respectively.\nIn transitioning from Problem 6 to Problem 7, I found that using fsolve with predefined initial guesses was too inaccurate for reliably identifying roots. This method often missed valid roots or produced duplicates due to its sensitivity to starting points. To improve accuracy, I switched to detecting sign changes in the function f(\\theta) and used the brentq algorithm, which efficiently locates roots where the function changes from positive to negative or vice versa. This approach greatly improved the precision of root detection.\n\n\nShow code\ndef count_roots(constants, theta_min=-np.pi, theta_max=np.pi, num_points=1000):\n    \"\"\"\n    Counts roots of f(theta) = 0 within [theta_min, theta_max].\n\n    Parameters:\n    constants (Constants): Stewart platform constants.\n    theta_min (float): Lower bound of theta.\n    theta_max (float): Upper bound of theta.\n    num_points (int): Sampling points.\n\n    Returns:\n    int: Number of unique roots.\n    list: Root values.\n    \"\"\"\n    theta_vals = np.linspace(theta_min, theta_max, num_points)\n\n    # Evaluate f(theta) over the range\n    f_vals = np.array([f(theta, constants) for theta in theta_vals])\n\n    roots = []\n\n    # Detect sign changes indicating roots\n    for i in range(len(theta_vals)-1):\n        if np.sign(f_vals[i]) != np.sign(f_vals[i+1]):\n            try:\n                root = brentq(f, theta_vals[i], theta_vals[i+1], args=(constants,))\n                if theta_min &lt;= root &lt;= theta_max:\n                    roots.append(root)\n            except ValueError:\n                pass  # No root in this interval\n\n    # Eliminate duplicate roots\n    unique_roots = []\n    for r in roots:\n        if not any(np.isclose(r, ur, atol=1e-5) for ur in unique_roots):\n            unique_roots.append(r)\n\n    return len(unique_roots), unique_roots\n\ndef find_p2_intervals(constants, p2_min, p2_max, p2_step):\n    \"\"\"\n    Finds p2 intervals with specific numbers of roots.\n\n    Parameters:\n    constants (Constants): Stewart platform constants.\n    p2_min (float): Starting p2 value.\n    p2_max (float): Ending p2 value.\n    p2_step (float): Increment step for p2.\n\n    Returns:\n    dict: Pose counts as keys and p2 lists as values.\n    \"\"\"\n    p2_values = np.arange(p2_min, p2_max + p2_step, p2_step)\n    root_counts = {0: [], 2: [], 4: [], 6: []}\n\n    for p2 in p2_values:\n        constants.p2 = p2\n        num_roots, _ = count_roots(constants)\n        if num_roots in root_counts:\n            root_counts[num_roots].append(p2)\n\n    return root_counts\n\n#### 4. Implement Problem 7\n\n# Initialize constants\nconstants = Constants(\n    l1=3,\n    l2=3 * np.sqrt(2),\n    l3=3,\n    gamma=np.pi / 4,\n    x1=5,\n    x2=0,\n    y2=6,\n    p1=5,\n    p2=5,  # Initial p2; will be varied\n    p3=3\n)\n\n# Set p2 range\np2_min = 0.0\np2_max = 12.98  # Extended to capture p2 &gt;= 9.27\np2_step = 0.01\n\n# Get root counts\nroot_counts = find_p2_intervals(constants, p2_min, p2_max, p2_step)\n\n# Plotting\nplt.figure(figsize=(12, 6))\ncolors = {0: 'blue', 2: 'green', 4: 'orange', 6: 'red'}\n\nfor num_roots, p2_list in root_counts.items():\n    plt.scatter(p2_list, [num_roots]*len(p2_list), label=f'{num_roots} poses', s=10, color=colors.get(num_roots, 'grey'))\n\nplt.xlabel('$p_2$', fontsize=14)\nplt.ylabel('Number of Poses (Roots)', fontsize=14)\nplt.title('Number of Poses vs Length of Strut $p_2$', fontsize=16)\nplt.legend()\nplt.grid(True)\n\nplt.savefig('p7_function_plot.png', dpi=300, bbox_inches='tight')\nplt.show()\n\n# Identify intervals\nintervals_dict = {0: [], 2: [], 4: [], 6: []}\ntol = 1e-6  # Tolerance for precision\n\nfor num_roots, p2_list in root_counts.items():\n    if p2_list:\n        p2_sorted = np.sort(p2_list)\n        diffs = np.diff(p2_sorted)\n        split_indices = np.where(diffs &gt; (p2_step + tol))[0] + 1\n        intervals = np.split(p2_sorted, split_indices)\n\n        for interval in intervals:\n            p2_start, p2_end = interval[0], interval[-1]\n            intervals_dict[num_roots].append((p2_start, p2_end))\n\n# Print first and last intervals for each pose count\nfor num_roots, intervals in intervals_dict.items():\n    if intervals:\n        print(f\"\\nIntervals with {num_roots} poses:\")\n        if len(intervals) == 1:\n            p2_start, p2_end = intervals[0]\n            p2_end_str = \"infinity\" if np.isclose(p2_end, p2_max, atol=tol) else f\"{p2_end:.2f}\"\n            print(f\"  p2 from {p2_start:.2f} to {p2_end_str}\")\n        else:\n            # First interval\n            p2_start, p2_end = intervals[0]\n            p2_end_str = \"infinity\" if np.isclose(p2_end, p2_max, atol=tol) else f\"{p2_end:.2f}\"\n            print(f\"  p2 from {p2_start:.2f} to {p2_end_str}\")\n\n            # Last interval\n            p2_start, p2_end = intervals[-1]\n            p2_end_str = \"infinity\" if np.isclose(p2_end, p2_max, atol=tol) else f\"{p2_end:.2f}\"\n            print(f\"  p2 from {p2_start:.2f} to {p2_end_str}\")\n\n\n\n\n\n\n\n\n\n\nIntervals with 0 poses:\n  p2 from 0.00 to 3.71\n  p2 from 9.27 to infinity\n\nIntervals with 2 poses:\n  p2 from 3.72 to 4.86\n  p2 from 7.85 to 9.26\n\nIntervals with 4 poses:\n  p2 from 4.87 to 6.96\n  p2 from 7.03 to 7.84\n\nIntervals with 6 poses:\n  p2 from 6.97 to 7.02"
  },
  {
    "objectID": "homework/w02/exercise3-1-2c.html",
    "href": "homework/w02/exercise3-1-2c.html",
    "title": "Exercise 3.1.1c (C3-P1)",
    "section": "",
    "text": "Use Newton’s Divided Differences to find a polynomial that passes through the points (0, -2), (2, 1), and (4, 4).\n\n\nThe points are:\n\n(x_1, y_1) = (0, -2)\n(x_2, y_2) = (2, 1)\n(x_3, y_3) = (4, 4)\n\nWe will first construct the divided differences table and use it to construct the Newton interpolating polynomial.\n\n\n\n\n\n\nx\nf[x]\nf[x_1, x_2]\nf[x_1, x_2, x_3]\n\n\n\n\n0\n-2\n\n\n\n\n2\n1\n1.5\n\n\n\n4\n4\n1.5\n0\n\n\n\n\n\n\n\nZeroth order divided differences:\n f[x_1] = y_1 = -2, \\quad f[x_2] = y_2 = 1, \\quad f[x_3] = y_3 = 4 \nFirst order divided differences:\n f[x_1, x_2] = \\frac{f[x_2] - f[x_1]}{x_2 - x_1} = \\frac{1 - (-2)}{2 - 0} = \\frac{3}{2} = 1.5 \n f[x_2, x_3] = \\frac{f[x_3] - f[x_2]}{x_3 - x_2} = \\frac{4 - 1}{4 - 2} = \\frac{3}{2} = 1.5 \nSecond order divided difference:\n f[x_1, x_2, x_3] = \\frac{f[x_2, x_3] - f[x_1, x_2]}{x_3 - x_1} = \\frac{1.5 - 1.5}{4 - 0} = 0 \n\n\n\n\nThe Newton polynomial is given by:\n\nP(x) = f[x_1] + f[x_1, x_2](x - x_1) + f[x_1, x_2, x_3](x - x_1)(x - x_2)\n\nSubstitute the values:\n\nP(x) = -2 + 1.5(x - 0) + 0(x - 0)(x - 2)\n\nSimplify:\n\nP(x) = -2 + 1.5x\n\nSo the final polynomial is:\n\nP(x) = 1.5x - 2\n\nThis is the Newton interpolating polynomial for the points (0, -2), (2, 1), and (4, 4).\n\n\nCreate graph with resulting polynomial\n# Define the Newton interpolating polynomial\ndef newton_polynomial(x):\n    return 1.5 * x - 2\n\n# Create an array of x values from -1 to 5 for the graph\nx_values = np.linspace(-1, 5, 400)\n\n# Compute the corresponding y values using the polynomial function\ny_values = newton_polynomial(x_values)\n\n# Plot the polynomial curve\nplt.figure(figsize=(8, 6))\nplt.plot(x_values, y_values, label=\"P(x) = 1.5x - 2\", color=\"blue\")\n\n# Plot the given points (0,-2), (2,1), (4,4)\ndata_points_x = [0, 2, 4]\ndata_points_y = [-2, 1, 4]\nplt.scatter(data_points_x, data_points_y, color=\"red\", label=\"Data Points\", zorder=5)\n\n# Add labels, title, and legend\nplt.title(\"Newton's Divided Differences Polynomial\")\nplt.xlabel(\"x\")\nplt.ylabel(\"P(x)\")\n\n# Set x and y ticks to have increments of 1\nplt.xticks(np.arange(-1, 6, 1))\nplt.yticks(np.arange(-4, 5, 1))\n\nplt.axhline(0, color='black',linewidth=0.5)\nplt.axvline(0, color='black',linewidth=0.5)\nplt.grid(True)\nplt.legend()\n\n# Show the plot\nplt.show()"
  },
  {
    "objectID": "homework/w02/exercise3-1-2c.html#question",
    "href": "homework/w02/exercise3-1-2c.html#question",
    "title": "Exercise 3.1.1c (C3-P1)",
    "section": "",
    "text": "Use Newton’s Divided Differences to find a polynomial that passes through the points (0, -2), (2, 1), and (4, 4).\n\n\nThe points are:\n\n(x_1, y_1) = (0, -2)\n(x_2, y_2) = (2, 1)\n(x_3, y_3) = (4, 4)\n\nWe will first construct the divided differences table and use it to construct the Newton interpolating polynomial.\n\n\n\n\n\n\nx\nf[x]\nf[x_1, x_2]\nf[x_1, x_2, x_3]\n\n\n\n\n0\n-2\n\n\n\n\n2\n1\n1.5\n\n\n\n4\n4\n1.5\n0\n\n\n\n\n\n\n\nZeroth order divided differences:\n f[x_1] = y_1 = -2, \\quad f[x_2] = y_2 = 1, \\quad f[x_3] = y_3 = 4 \nFirst order divided differences:\n f[x_1, x_2] = \\frac{f[x_2] - f[x_1]}{x_2 - x_1} = \\frac{1 - (-2)}{2 - 0} = \\frac{3}{2} = 1.5 \n f[x_2, x_3] = \\frac{f[x_3] - f[x_2]}{x_3 - x_2} = \\frac{4 - 1}{4 - 2} = \\frac{3}{2} = 1.5 \nSecond order divided difference:\n f[x_1, x_2, x_3] = \\frac{f[x_2, x_3] - f[x_1, x_2]}{x_3 - x_1} = \\frac{1.5 - 1.5}{4 - 0} = 0 \n\n\n\n\nThe Newton polynomial is given by:\n\nP(x) = f[x_1] + f[x_1, x_2](x - x_1) + f[x_1, x_2, x_3](x - x_1)(x - x_2)\n\nSubstitute the values:\n\nP(x) = -2 + 1.5(x - 0) + 0(x - 0)(x - 2)\n\nSimplify:\n\nP(x) = -2 + 1.5x\n\nSo the final polynomial is:\n\nP(x) = 1.5x - 2\n\nThis is the Newton interpolating polynomial for the points (0, -2), (2, 1), and (4, 4).\n\n\nCreate graph with resulting polynomial\n# Define the Newton interpolating polynomial\ndef newton_polynomial(x):\n    return 1.5 * x - 2\n\n# Create an array of x values from -1 to 5 for the graph\nx_values = np.linspace(-1, 5, 400)\n\n# Compute the corresponding y values using the polynomial function\ny_values = newton_polynomial(x_values)\n\n# Plot the polynomial curve\nplt.figure(figsize=(8, 6))\nplt.plot(x_values, y_values, label=\"P(x) = 1.5x - 2\", color=\"blue\")\n\n# Plot the given points (0,-2), (2,1), (4,4)\ndata_points_x = [0, 2, 4]\ndata_points_y = [-2, 1, 4]\nplt.scatter(data_points_x, data_points_y, color=\"red\", label=\"Data Points\", zorder=5)\n\n# Add labels, title, and legend\nplt.title(\"Newton's Divided Differences Polynomial\")\nplt.xlabel(\"x\")\nplt.ylabel(\"P(x)\")\n\n# Set x and y ticks to have increments of 1\nplt.xticks(np.arange(-1, 6, 1))\nplt.yticks(np.arange(-4, 5, 1))\n\nplt.axhline(0, color='black',linewidth=0.5)\nplt.axvline(0, color='black',linewidth=0.5)\nplt.grid(True)\nplt.legend()\n\n# Show the plot\nplt.show()"
  },
  {
    "objectID": "homework/w02/exercise3-1-1c.html",
    "href": "homework/w02/exercise3-1-1c.html",
    "title": "Exercise 3.1.1c (C3-P1)",
    "section": "",
    "text": "Use Lagrange interpolation to find a polynomial that passes through the points (0, -2), (2, 1), (4, 4).\nThe Lagrange interpolation polynomial for three points (x_1, y_1), (x_2, y_2), and (x_3, y_3) is given by the formula:\nP(x) = y_1 \\frac{(x - x_2)(x - x_3)}{(x_1 - x_2)(x_1 - x_3)} + y_2 \\frac{(x - x_1)(x - x_3)}{(x_2 - x_1)(x_2 - x_3)} + y_3 \\frac{(x - x_1)(x - x_2)}{(x_3 - x_1)(x_3 - x_2)}\nThe points are:\n\n(x_1, y_1) = (0, -2)\n(x_2, y_2) = (2, 1)\n(x_3, y_3) = (4, 4)\n\n\n\n\nFirst term (corresponding to (x_1, y_1) = (0, -2)):\n\n\n-2 \\cdot \\frac{(x - 2)(x - 4)}{(0 - 2)(0 - 4)} = -2 \\cdot \\frac{(x - 2)(x - 4)}{(-2)(-4)} = -2 \\cdot \\frac{(x - 2)(x - 4)}{8} = \\frac{-1}{4}(x - 2)(x - 4)\n\n\nSecond term (corresponding to (x_2, y_2) = (2, 1))\n\n\n1 \\cdot \\frac{(x - 0)(x - 4)}{(2 - 0)(2 - 4)} = 1 \\cdot \\frac{x(x - 4)}{(2)(-2)} = \\frac{x(x - 4)}{-4}\n\n\nThird term (corresponding to (x_3, y_3) = (4, 4)):\n\n\n4 \\cdot \\frac{(x - 0)(x - 2)}{(4 - 0)(4 - 2)} = 4 \\cdot \\frac{x(x - 2)}{(4)(2)} = 4 \\cdot \\frac{x(x - 2)}{8} = \\frac{x(x - 2)}{2}\n\n\n\n\n\nP(x) = \\frac{-1}{4}(x - 2)(x - 4) + \\frac{x(x - 4)}{-4} + \\frac{x(x - 2)}{2}\n\n\n\n\nFirst term:\n\n\\frac{-1}{4}(x - 2)(x - 4) = \\frac{-x^2 + 6x - 8}{4}\n\nSecond term:\n\n\\frac{-x(x - 4)}{4} = \\frac{-x^2 + 4x}{4}\n\nThird term:\n\n\\frac{x(x - 2)}{2} = \\frac{x^2 - 2x}{2}\n\nCombine the terms:\n\nP(x) = \\frac{-x^2 + 6x - 8}{4} + \\frac{-x^2 + 4x}{4} + \\frac{x^2 - 2x}{2}\n\nTo combine, first rewrite everything with a denominator of 4:\n\nP(x) = \\frac{-x^2 + 6x - 8 - x^2 + 4x}{4} + \\frac{x^2 - 2x}{2}\n\nConvert the second term to have a denominator of 4:\n\nP(x) = \\frac{-x^2 + 6x - 8 - x^2 + 4x}{4} + \\frac{2x^2 - 4x}{4}\n\nNow simplify:\n\nP(x) = \\frac{-2x^2 + 10x - 8}{4} + \\frac{2x^2 - 4x}{4}\n\n\nP(x) = \\frac{6x - 8}{4} = \\frac{3x - 4}{2}\n\nFinal polynomial:\n\nP(x) = \\frac{3x - 4}{2}\n\nThis is the interpolating polynomial that passes through the points (0, -2), (2, 1), and (4, 4).\n\n\nCreate graph with resulting polynomial\n# Define the Lagrange interpolating polynomial\ndef lagrange_polynomial(x):\n    return (3 * x - 4) / 2\n\n# Create an array of x values from -1 to 5 for the graph\nx_values = np.linspace(-1, 5, 400)\n\n# Compute the corresponding y values using the polynomial function\ny_values = lagrange_polynomial(x_values)\n\n# Plot the polynomial curve\nplt.figure(figsize=(8, 6))\nplt.plot(x_values, y_values, label=\"P(x) = (3x - 4) / 2\", color=\"blue\")\n\n# Plot the given points (0,-2), (2,1), (4,4)\ndata_points_x = [0, 2, 4]\ndata_points_y = [-2, 1, 4]\nplt.scatter(data_points_x, data_points_y, color=\"red\", label=\"Data Points\", zorder=5)\n\n# Add labels, title, and legend\nplt.title(\"Lagrange Interpolating Polynomial\")\nplt.xlabel(\"x\")\nplt.ylabel(\"P(x)\")\n\n# Set x and y ticks to have increments of 1\nplt.xticks(np.arange(-1, 6, 1))\nplt.yticks(np.arange(-4, 5, 1))\n\nplt.axhline(0, color='black',linewidth=0.5)\nplt.axvline(0, color='black',linewidth=0.5)\nplt.grid(True)\nplt.legend()\n\n# Show the plot\nplt.show()"
  },
  {
    "objectID": "homework/w02/exercise3-1-1c.html#question",
    "href": "homework/w02/exercise3-1-1c.html#question",
    "title": "Exercise 3.1.1c (C3-P1)",
    "section": "",
    "text": "Use Lagrange interpolation to find a polynomial that passes through the points (0, -2), (2, 1), (4, 4).\nThe Lagrange interpolation polynomial for three points (x_1, y_1), (x_2, y_2), and (x_3, y_3) is given by the formula:\nP(x) = y_1 \\frac{(x - x_2)(x - x_3)}{(x_1 - x_2)(x_1 - x_3)} + y_2 \\frac{(x - x_1)(x - x_3)}{(x_2 - x_1)(x_2 - x_3)} + y_3 \\frac{(x - x_1)(x - x_2)}{(x_3 - x_1)(x_3 - x_2)}\nThe points are:\n\n(x_1, y_1) = (0, -2)\n(x_2, y_2) = (2, 1)\n(x_3, y_3) = (4, 4)\n\n\n\n\nFirst term (corresponding to (x_1, y_1) = (0, -2)):\n\n\n-2 \\cdot \\frac{(x - 2)(x - 4)}{(0 - 2)(0 - 4)} = -2 \\cdot \\frac{(x - 2)(x - 4)}{(-2)(-4)} = -2 \\cdot \\frac{(x - 2)(x - 4)}{8} = \\frac{-1}{4}(x - 2)(x - 4)\n\n\nSecond term (corresponding to (x_2, y_2) = (2, 1))\n\n\n1 \\cdot \\frac{(x - 0)(x - 4)}{(2 - 0)(2 - 4)} = 1 \\cdot \\frac{x(x - 4)}{(2)(-2)} = \\frac{x(x - 4)}{-4}\n\n\nThird term (corresponding to (x_3, y_3) = (4, 4)):\n\n\n4 \\cdot \\frac{(x - 0)(x - 2)}{(4 - 0)(4 - 2)} = 4 \\cdot \\frac{x(x - 2)}{(4)(2)} = 4 \\cdot \\frac{x(x - 2)}{8} = \\frac{x(x - 2)}{2}\n\n\n\n\n\nP(x) = \\frac{-1}{4}(x - 2)(x - 4) + \\frac{x(x - 4)}{-4} + \\frac{x(x - 2)}{2}\n\n\n\n\nFirst term:\n\n\\frac{-1}{4}(x - 2)(x - 4) = \\frac{-x^2 + 6x - 8}{4}\n\nSecond term:\n\n\\frac{-x(x - 4)}{4} = \\frac{-x^2 + 4x}{4}\n\nThird term:\n\n\\frac{x(x - 2)}{2} = \\frac{x^2 - 2x}{2}\n\nCombine the terms:\n\nP(x) = \\frac{-x^2 + 6x - 8}{4} + \\frac{-x^2 + 4x}{4} + \\frac{x^2 - 2x}{2}\n\nTo combine, first rewrite everything with a denominator of 4:\n\nP(x) = \\frac{-x^2 + 6x - 8 - x^2 + 4x}{4} + \\frac{x^2 - 2x}{2}\n\nConvert the second term to have a denominator of 4:\n\nP(x) = \\frac{-x^2 + 6x - 8 - x^2 + 4x}{4} + \\frac{2x^2 - 4x}{4}\n\nNow simplify:\n\nP(x) = \\frac{-2x^2 + 10x - 8}{4} + \\frac{2x^2 - 4x}{4}\n\n\nP(x) = \\frac{6x - 8}{4} = \\frac{3x - 4}{2}\n\nFinal polynomial:\n\nP(x) = \\frac{3x - 4}{2}\n\nThis is the interpolating polynomial that passes through the points (0, -2), (2, 1), and (4, 4).\n\n\nCreate graph with resulting polynomial\n# Define the Lagrange interpolating polynomial\ndef lagrange_polynomial(x):\n    return (3 * x - 4) / 2\n\n# Create an array of x values from -1 to 5 for the graph\nx_values = np.linspace(-1, 5, 400)\n\n# Compute the corresponding y values using the polynomial function\ny_values = lagrange_polynomial(x_values)\n\n# Plot the polynomial curve\nplt.figure(figsize=(8, 6))\nplt.plot(x_values, y_values, label=\"P(x) = (3x - 4) / 2\", color=\"blue\")\n\n# Plot the given points (0,-2), (2,1), (4,4)\ndata_points_x = [0, 2, 4]\ndata_points_y = [-2, 1, 4]\nplt.scatter(data_points_x, data_points_y, color=\"red\", label=\"Data Points\", zorder=5)\n\n# Add labels, title, and legend\nplt.title(\"Lagrange Interpolating Polynomial\")\nplt.xlabel(\"x\")\nplt.ylabel(\"P(x)\")\n\n# Set x and y ticks to have increments of 1\nplt.xticks(np.arange(-1, 6, 1))\nplt.yticks(np.arange(-4, 5, 1))\n\nplt.axhline(0, color='black',linewidth=0.5)\nplt.axvline(0, color='black',linewidth=0.5)\nplt.grid(True)\nplt.legend()\n\n# Show the plot\nplt.show()"
  },
  {
    "objectID": "notes/w03/runge-phenomenon.html",
    "href": "notes/w03/runge-phenomenon.html",
    "title": "Runge Phenomenon",
    "section": "",
    "text": "The Runge Phenomenon refers to the oscillatory behavior that occurs when using high-degree polynomial interpolation on evenly spaced data points, particularly near the endpoints of an interval. The phenomenon is named after Carl Runge, who discovered this issue while studying interpolation of functions with large oscillations near the boundaries of an interval.\n\n\nWhen interpolating a smooth function using polynomials of high degree, the interpolation can become highly oscillatory near the edges of the interval, even if the function being interpolated is smooth and well-behaved. This is particularly problematic with equally spaced points, as the polynomial tries to fit too closely to the data points near the boundaries, leading to large errors.\n\n\n\nThe most famous example illustrating the Runge phenomenon is based on the Runge function:\n\\[\nf(x) = \\frac{1}{1 + 25x^2}\n\\]\nRunge showed that using high-degree polynomial interpolation on this function with evenly spaced points over the interval \\([-5, 5]\\) leads to significant oscillations near the edges. The interpolation error grows as the degree of the polynomial increases, especially near the endpoints of the interval.\n\n\n\nThe Runge phenomenon arises because high-degree polynomials tend to oscillate more as their degree increases, especially when they are forced to pass through many points. With equally spaced points, the interpolation error is concentrated near the edges of the interval, causing large deviations from the true function in those regions.\nMathematically, for a function \\(f(x)\\) interpolated at \\(n\\) evenly spaced points using a polynomial \\(P_n(x)\\) of degree \\(n-1\\), the interpolation error is given by:\n\\[\n|f(x) - P_n(x)| = \\frac{|f^{(n)}(c)|}{n!} \\prod_{i=1}^{n}(x - x_i)\n\\]\nAs the number of interpolation points \\(n\\) increases, the product term \\(\\prod_{i=1}^{n}(x - x_i)\\) becomes very large near the endpoints of the interval, causing the interpolation error to increase dramatically.\n\n\n\nThe following figure illustrates the Runge phenomenon. For the Runge function \\(f(x) = \\frac{1}{1 + 25x^2}\\), the polynomial interpolation for large \\(n\\) shows excessive oscillations near the interval boundaries:\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndef runge_function(x):\n    return 1 / (1 + 25 * x**2)\n\n# Define the x values\nx_values = np.linspace(-5, 5, 1000)\n\n# Plot the original Runge function\nplt.figure(figsize=(8, 6))\nplt.plot(x_values, runge_function(x_values), label=\"Runge Function\", color=\"blue\")\n\n# Show interpolation for degree 5 and degree 10 polynomials\nplt.title(\"Runge Phenomenon\")\nplt.xlabel(\"x\")\nplt.ylabel(\"f(x)\")\nplt.legend()\nplt.grid(True)\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nThe Runge phenomenon can be mitigated by using Chebyshev nodes instead of equally spaced points. Chebyshev nodes distribute the points more densely near the edges of the interval, where the oscillations are most likely to occur. This results in more accurate interpolation with less oscillation near the boundaries.\nChebyshev nodes \\(x_i\\) for \\(n\\) interpolation points on the interval \\([-1, 1]\\) are given by:\n\\[\nx_i = \\cos\\left(\\frac{(2i - 1)\\pi}{2n}\\right)\n\\]\nUsing Chebyshev interpolation reduces the risk of large oscillations near the endpoints, providing a more stable approximation.\n\n\n\nThe Runge phenomenon highlights the dangers of using high-degree polynomials for interpolation with evenly spaced points. To avoid this issue, it is recommended to use Chebyshev interpolation or lower-degree polynomial interpolation in smaller intervals (piecewise interpolation)."
  },
  {
    "objectID": "notes/w03/runge-phenomenon.html#introduction",
    "href": "notes/w03/runge-phenomenon.html#introduction",
    "title": "Runge Phenomenon",
    "section": "",
    "text": "The Runge Phenomenon refers to the oscillatory behavior that occurs when using high-degree polynomial interpolation on evenly spaced data points, particularly near the endpoints of an interval. The phenomenon is named after Carl Runge, who discovered this issue while studying interpolation of functions with large oscillations near the boundaries of an interval.\n\n\nWhen interpolating a smooth function using polynomials of high degree, the interpolation can become highly oscillatory near the edges of the interval, even if the function being interpolated is smooth and well-behaved. This is particularly problematic with equally spaced points, as the polynomial tries to fit too closely to the data points near the boundaries, leading to large errors.\n\n\n\nThe most famous example illustrating the Runge phenomenon is based on the Runge function:\n\\[\nf(x) = \\frac{1}{1 + 25x^2}\n\\]\nRunge showed that using high-degree polynomial interpolation on this function with evenly spaced points over the interval \\([-5, 5]\\) leads to significant oscillations near the edges. The interpolation error grows as the degree of the polynomial increases, especially near the endpoints of the interval.\n\n\n\nThe Runge phenomenon arises because high-degree polynomials tend to oscillate more as their degree increases, especially when they are forced to pass through many points. With equally spaced points, the interpolation error is concentrated near the edges of the interval, causing large deviations from the true function in those regions.\nMathematically, for a function \\(f(x)\\) interpolated at \\(n\\) evenly spaced points using a polynomial \\(P_n(x)\\) of degree \\(n-1\\), the interpolation error is given by:\n\\[\n|f(x) - P_n(x)| = \\frac{|f^{(n)}(c)|}{n!} \\prod_{i=1}^{n}(x - x_i)\n\\]\nAs the number of interpolation points \\(n\\) increases, the product term \\(\\prod_{i=1}^{n}(x - x_i)\\) becomes very large near the endpoints of the interval, causing the interpolation error to increase dramatically.\n\n\n\nThe following figure illustrates the Runge phenomenon. For the Runge function \\(f(x) = \\frac{1}{1 + 25x^2}\\), the polynomial interpolation for large \\(n\\) shows excessive oscillations near the interval boundaries:\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndef runge_function(x):\n    return 1 / (1 + 25 * x**2)\n\n# Define the x values\nx_values = np.linspace(-5, 5, 1000)\n\n# Plot the original Runge function\nplt.figure(figsize=(8, 6))\nplt.plot(x_values, runge_function(x_values), label=\"Runge Function\", color=\"blue\")\n\n# Show interpolation for degree 5 and degree 10 polynomials\nplt.title(\"Runge Phenomenon\")\nplt.xlabel(\"x\")\nplt.ylabel(\"f(x)\")\nplt.legend()\nplt.grid(True)\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nThe Runge phenomenon can be mitigated by using Chebyshev nodes instead of equally spaced points. Chebyshev nodes distribute the points more densely near the edges of the interval, where the oscillations are most likely to occur. This results in more accurate interpolation with less oscillation near the boundaries.\nChebyshev nodes \\(x_i\\) for \\(n\\) interpolation points on the interval \\([-1, 1]\\) are given by:\n\\[\nx_i = \\cos\\left(\\frac{(2i - 1)\\pi}{2n}\\right)\n\\]\nUsing Chebyshev interpolation reduces the risk of large oscillations near the endpoints, providing a more stable approximation.\n\n\n\nThe Runge phenomenon highlights the dangers of using high-degree polynomials for interpolation with evenly spaced points. To avoid this issue, it is recommended to use Chebyshev interpolation or lower-degree polynomial interpolation in smaller intervals (piecewise interpolation)."
  },
  {
    "objectID": "notes/w07/lu-factorization.html",
    "href": "notes/w07/lu-factorization.html",
    "title": "LU Factorization",
    "section": "",
    "text": "LU Factorization (or LU Decomposition) is a powerful technique in linear algebra for breaking down a matrix \\(A\\) into the product of a lower triangular matrix \\(L\\) and an upper triangular matrix \\(U\\). This factorization is commonly used for solving linear systems, computing determinants, and inverting matrices. This note explores LU Factorization’s definition, properties, computation, and applications."
  },
  {
    "objectID": "notes/w07/lu-factorization.html#introduction",
    "href": "notes/w07/lu-factorization.html#introduction",
    "title": "LU Factorization",
    "section": "",
    "text": "LU Factorization (or LU Decomposition) is a powerful technique in linear algebra for breaking down a matrix \\(A\\) into the product of a lower triangular matrix \\(L\\) and an upper triangular matrix \\(U\\). This factorization is commonly used for solving linear systems, computing determinants, and inverting matrices. This note explores LU Factorization’s definition, properties, computation, and applications."
  },
  {
    "objectID": "notes/w07/lu-factorization.html#definition-and-decomposition",
    "href": "notes/w07/lu-factorization.html#definition-and-decomposition",
    "title": "LU Factorization",
    "section": "Definition and Decomposition",
    "text": "Definition and Decomposition\nFor a square matrix \\(A\\), LU Factorization is given by:\n\\[\nA = LU\n\\]\nwhere:\n\n\\(L\\) is a lower triangular matrix with ones on the diagonal.\n\\(U\\) is an upper triangular matrix.\n\nIf \\(A\\) cannot be decomposed directly, partial pivoting may be applied, resulting in:\n\\[\nPA = LU\n\\]\nwhere \\(P\\) is a permutation matrix that records row exchanges."
  },
  {
    "objectID": "notes/w07/lu-factorization.html#conditions-for-lu-factorization",
    "href": "notes/w07/lu-factorization.html#conditions-for-lu-factorization",
    "title": "LU Factorization",
    "section": "Conditions for LU Factorization",
    "text": "Conditions for LU Factorization\nLU Factorization is valid when:\n\nMatrix is Square: \\(A\\) must be a square matrix.\nNon-Singular Leading Submatrices: Each leading principal submatrix (upper-left submatrix) of \\(A\\) must be non-singular.\n\nWhen these conditions are not met, row pivoting enables decomposition."
  },
  {
    "objectID": "notes/w07/lu-factorization.html#factorization-process",
    "href": "notes/w07/lu-factorization.html#factorization-process",
    "title": "LU Factorization",
    "section": "Factorization Process",
    "text": "Factorization Process\nTo factorize \\(A\\) into \\(L\\) and \\(U\\):\n\nEliminate Elements: Perform row operations to create zeros below the main diagonal of \\(U\\).\nStore Multipliers: Record the multipliers in \\(L\\).\n\n\nExample\nGiven a \\(3 \\times 3\\) matrix:\n\\[\nA = \\begin{pmatrix} 2 & 3 & 1 \\\\ 4 & 7 & -1 \\\\ -2 & 3 & 5 \\end{pmatrix}\n\\]\n\nTransform \\(A\\) into \\(U\\) using row operations.\nRecord elimination factors in \\(L\\).\nThe result satisfies \\(A = LU\\)."
  },
  {
    "objectID": "notes/w07/lu-factorization.html#solving-systems-with-lu-factorization",
    "href": "notes/w07/lu-factorization.html#solving-systems-with-lu-factorization",
    "title": "LU Factorization",
    "section": "Solving Systems with LU Factorization",
    "text": "Solving Systems with LU Factorization\nLU Factorization allows us to solve \\(Ax = b\\) by breaking it down into two simpler systems:\n\nSolve \\(Ly = b\\): Use forward substitution, as \\(L\\) is lower triangular.\nSolve \\(Ux = y\\): Use back substitution with \\(U\\) as an upper triangular matrix.\n\n\nEfficiency\nThis approach reduces computation time, especially when solving multiple systems with the same \\(A\\) but different \\(b\\) vectors, as the factorization needs to be computed only once."
  },
  {
    "objectID": "notes/w07/lu-factorization.html#pivoting-and-permutation",
    "href": "notes/w07/lu-factorization.html#pivoting-and-permutation",
    "title": "LU Factorization",
    "section": "Pivoting and Permutation",
    "text": "Pivoting and Permutation\nIn cases where \\(A\\) has zeros or small values on the diagonal, partial pivoting improves numerical stability by reordering rows to place a larger element on the diagonal:\n\\[\nPA = LU\n\\]\nwhere \\(P\\) is a permutation matrix that tracks row exchanges."
  },
  {
    "objectID": "notes/w07/lu-factorization.html#advantages-of-lu-factorization",
    "href": "notes/w07/lu-factorization.html#advantages-of-lu-factorization",
    "title": "LU Factorization",
    "section": "Advantages of LU Factorization",
    "text": "Advantages of LU Factorization\n\nEfficient Linear System Solving: Faster than Gaussian elimination for repeated systems.\nDeterminant Computation: The determinant of \\(A\\) is the product of the diagonal elements of \\(U\\).\nMatrix Inversion: LU Factorization simplifies inversion by inverting \\(L\\) and \\(U\\) separately."
  },
  {
    "objectID": "notes/w07/lu-factorization.html#applications-of-lu-factorization",
    "href": "notes/w07/lu-factorization.html#applications-of-lu-factorization",
    "title": "LU Factorization",
    "section": "Applications of LU Factorization",
    "text": "Applications of LU Factorization\nLU Factorization is widely used across various fields due to its computational efficiency:\n\nNumerical Linear Algebra: Fundamental for solving linear systems.\nOptimization: Integral in algorithms that rely on matrix decompositions.\nComputer Graphics: Enables transformations and projections.\nScientific Computing: Common in simulations and solving differential equations."
  },
  {
    "objectID": "notes/w07/lu-factorization.html#example-problem",
    "href": "notes/w07/lu-factorization.html#example-problem",
    "title": "LU Factorization",
    "section": "Example Problem",
    "text": "Example Problem\nProblem: For the matrix\n\\[\nA = \\begin{pmatrix} 3 & -7 & -2 \\\\ -3 & 5 & 1 \\\\ 6 & -4 & 0 \\end{pmatrix}\n\\]\n\nFactorize \\(A\\) into \\(L\\) and \\(U\\).\nSolve \\(Ax = b\\) for \\(b = \\begin{pmatrix} 5 \\\\ -1 \\\\ 3 \\end{pmatrix}\\).\n\n\nSolution Steps\n\nPerform row operations to decompose \\(A\\) into \\(L\\) and \\(U\\).\nSolve \\(Ly = b\\) via forward substitution.\nSolve \\(Ux = y\\) via back substitution."
  },
  {
    "objectID": "notes/w07/lu-factorization.html#conclusion",
    "href": "notes/w07/lu-factorization.html#conclusion",
    "title": "LU Factorization",
    "section": "Conclusion",
    "text": "Conclusion\nLU Factorization is an essential tool in linear algebra, providing a simplified method to solve linear systems efficiently. By breaking matrices into triangular forms, it reduces computational complexity and lays the groundwork for more advanced numerical techniques."
  },
  {
    "objectID": "notes/w03/interpolation-error-formula.html",
    "href": "notes/w03/interpolation-error-formula.html",
    "title": "Interpolation Error Formula",
    "section": "",
    "text": "The Interpolation Error Formula helps estimate how much error exists between an interpolating polynomial \\(P(x)\\) and the true function \\(f(x)\\) that we are approximating. This formula is important in numerical analysis when constructing polynomials to approximate functions based on given data points.\n\n\nIf we are given \\(n\\) distinct data points \\((x_1, y_1), (x_2, y_2), \\dots, (x_n, y_n)\\), the interpolation error at a point \\(x\\) between the data points is given by:\n\\[\nf(x) - P(x) = \\frac{(x - x_1)(x - x_2) \\cdots (x - x_n)}{n!} f^{(n)}(c)\n\\]\nHere:\n\n\\(f(x)\\) is the true function we are approximating.\n\\(P(x)\\) is the interpolating polynomial of degree \\(n - 1\\) that passes through all the given data points.\n\\(f^{(n)}(c)\\) is the \\(n\\)-th derivative of \\(f\\), evaluated at some unknown point \\(c\\), which lies between the smallest and largest \\(x\\)-values.\n\\((x - x_1)(x - x_2) \\cdots (x - x_n)\\) is the product of terms \\((x - x_i)\\), which depend on how far the point \\(x\\) is from the given data points.\n\\(n!\\) is the factorial of \\(n\\), the number of data points.\n\n\n\n\n\nFactorial Growth: The denominator includes a factor of \\(n!\\), which grows quickly as the number of points increases. This reduces the impact of the higher-order term, especially for larger \\(n\\).\nDerivative Behavior: The \\(n\\)-th derivative \\(f^{(n)}(c)\\) plays a crucial role in determining the size of the error. If the \\(n\\)-th derivative of the function is small, the error will be smaller.\nCloseness to Data Points: The term \\((x - x_1)(x - x_2) \\cdots (x - x_n)\\) increases when \\(x\\) is far from the given data points. Thus, the error tends to be smaller when \\(x\\) is near the center of the interpolation points and larger when it is near the boundaries.\n\n\n\n\nFor example, consider the function \\(f(x) = \\sin(x)\\) and the interpolating polynomial \\(P(x)\\) constructed using data points at \\(0, \\frac{\\pi}{6}, \\frac{\\pi}{3}, \\frac{\\pi}{2}\\). The error at \\(x = 1\\) can be calculated using the formula:\n\\[\n\\sin(1) - P(1) \\leq \\frac{(1 - 0)(1 - \\frac{\\pi}{6})(1 - \\frac{\\pi}{3})(1 - \\frac{\\pi}{2})}{4!} \\cdot |f^{(4)}(c)|\n\\]\nSince \\(|f^{(4)}(c)| \\leq 1\\) (for \\(\\sin(x)\\), the fourth derivative does not exceed 1), we can calculate the upper bound for the error.\n\n\n\nThe Interpolation Error Formula is a powerful tool for estimating how close an interpolating polynomial \\(P(x)\\) is to the true function \\(f(x)\\). While it is often difficult to calculate the exact error, the formula helps provide an upper bound on the error, especially useful for functions with known derivatives. The error tends to be smaller in the middle of the interpolation interval and larger near the edges, which is a key factor in numerical interpolation."
  },
  {
    "objectID": "notes/w03/interpolation-error-formula.html#interpolation-error-formula",
    "href": "notes/w03/interpolation-error-formula.html#interpolation-error-formula",
    "title": "Interpolation Error Formula",
    "section": "",
    "text": "The Interpolation Error Formula helps estimate how much error exists between an interpolating polynomial \\(P(x)\\) and the true function \\(f(x)\\) that we are approximating. This formula is important in numerical analysis when constructing polynomials to approximate functions based on given data points.\n\n\nIf we are given \\(n\\) distinct data points \\((x_1, y_1), (x_2, y_2), \\dots, (x_n, y_n)\\), the interpolation error at a point \\(x\\) between the data points is given by:\n\\[\nf(x) - P(x) = \\frac{(x - x_1)(x - x_2) \\cdots (x - x_n)}{n!} f^{(n)}(c)\n\\]\nHere:\n\n\\(f(x)\\) is the true function we are approximating.\n\\(P(x)\\) is the interpolating polynomial of degree \\(n - 1\\) that passes through all the given data points.\n\\(f^{(n)}(c)\\) is the \\(n\\)-th derivative of \\(f\\), evaluated at some unknown point \\(c\\), which lies between the smallest and largest \\(x\\)-values.\n\\((x - x_1)(x - x_2) \\cdots (x - x_n)\\) is the product of terms \\((x - x_i)\\), which depend on how far the point \\(x\\) is from the given data points.\n\\(n!\\) is the factorial of \\(n\\), the number of data points.\n\n\n\n\n\nFactorial Growth: The denominator includes a factor of \\(n!\\), which grows quickly as the number of points increases. This reduces the impact of the higher-order term, especially for larger \\(n\\).\nDerivative Behavior: The \\(n\\)-th derivative \\(f^{(n)}(c)\\) plays a crucial role in determining the size of the error. If the \\(n\\)-th derivative of the function is small, the error will be smaller.\nCloseness to Data Points: The term \\((x - x_1)(x - x_2) \\cdots (x - x_n)\\) increases when \\(x\\) is far from the given data points. Thus, the error tends to be smaller when \\(x\\) is near the center of the interpolation points and larger when it is near the boundaries.\n\n\n\n\nFor example, consider the function \\(f(x) = \\sin(x)\\) and the interpolating polynomial \\(P(x)\\) constructed using data points at \\(0, \\frac{\\pi}{6}, \\frac{\\pi}{3}, \\frac{\\pi}{2}\\). The error at \\(x = 1\\) can be calculated using the formula:\n\\[\n\\sin(1) - P(1) \\leq \\frac{(1 - 0)(1 - \\frac{\\pi}{6})(1 - \\frac{\\pi}{3})(1 - \\frac{\\pi}{2})}{4!} \\cdot |f^{(4)}(c)|\n\\]\nSince \\(|f^{(4)}(c)| \\leq 1\\) (for \\(\\sin(x)\\), the fourth derivative does not exceed 1), we can calculate the upper bound for the error.\n\n\n\nThe Interpolation Error Formula is a powerful tool for estimating how close an interpolating polynomial \\(P(x)\\) is to the true function \\(f(x)\\). While it is often difficult to calculate the exact error, the formula helps provide an upper bound on the error, especially useful for functions with known derivatives. The error tends to be smaller in the middle of the interpolation interval and larger near the edges, which is a key factor in numerical interpolation."
  },
  {
    "objectID": "notes/w02/newtons-divided-differences.html",
    "href": "notes/w02/newtons-divided-differences.html",
    "title": "Newton’s Divided Differences",
    "section": "",
    "text": "Newton’s Divided Differences is an efficient method for computing an interpolating polynomial for a given set of data points. This method builds the polynomial iteratively and offers better efficiency for incremental data points compared to Lagrange interpolation."
  },
  {
    "objectID": "notes/w02/newtons-divided-differences.html#the-newton-divided-difference-formula",
    "href": "notes/w02/newtons-divided-differences.html#the-newton-divided-difference-formula",
    "title": "Newton’s Divided Differences",
    "section": "The Newton Divided Difference Formula",
    "text": "The Newton Divided Difference Formula\nGiven \\(n\\) data points \\((x_1, y_1), (x_2, y_2), ..., (x_n, y_n)\\), the Newton divided difference interpolating polynomial \\(P(x)\\) can be expressed as:\n\\[\nP(x) = f[x_1] + f[x_1, x_2](x - x_1) + f[x_1, x_2, x_3](x - x_1)(x - x_2) + \\cdots + f[x_1, x_2, \\ldots, x_n](x - x_1)(x - x_2)\\cdots(x - x_{n-1})\n\\]\nWhere \\(f[x_i, x_j, ..., x_k]\\) are the divided differences and are recursively defined as follows:\n\\[\nf[x_i] = y_i\n\\]\n\\[\nf[x_i, x_j] = \\frac{f[x_j] - f[x_i]}{x_j - x_i}\n\\]\n\\[\nf[x_i, x_j, x_k] = \\frac{f[x_j, x_k] - f[x_i, x_j]}{x_k - x_i}\n\\]\nAnd so on for higher orders of divided differences.\n\nRecursive Formula for Divided Differences\nThe divided differences are computed recursively. For the first-order difference between two points, the formula is:\n\\[\nf[x_i, x_{i+1}] = \\frac{f(x_{i+1}) - f(x_i)}{x_{i+1} - x_i}\n\\]\nFor the second-order difference between three points:\n\\[\nf[x_i, x_{i+1}, x_{i+2}] = \\frac{f[x_{i+1}, x_{i+2}] - f[x_i, x_{i+1}]}{x_{i+2} - x_i}\n\\]\nThis recursive approach continues for higher orders of differences.\n\n\nStep-by-Step Construction of the Newton Polynomial\n\nStart with the first point \\((x_1, y_1)\\), where \\(f[x_1] = y_1\\).\nFirst-order divided difference between \\((x_1, y_1)\\) and \\((x_2, y_2)\\) is:\n\n\\[\nf[x_1, x_2] = \\frac{y_2 - y_1}{x_2 - x_1}\n\\]\n\nSecond-order divided difference between \\((x_1, y_1)\\), \\((x_2, y_2)\\), and \\((x_3, y_3)\\):\n\n\\[\nf[x_1, x_2, x_3] = \\frac{f[x_2, x_3] - f[x_1, x_2]}{x_3 - x_1}\n\\]\n\nContinue this process for higher-order divided differences.\n\nHere’s the corrected example in the same format as your original:\n\n\n\nExample\nLet’s consider the data points ( (1, 1) ), ( (2, 4) ), ( (3, 9) ), and ( (4, 16) ). The goal is to find the interpolating polynomial using Newton’s divided differences.\n\nFirst point:\n\n\\[\nf[1] = 1\n\\]\n\nFirst-order divided differences:\n\n\\[\nf[1, 2] = \\frac{4 - 1}{2 - 1} = 3\n\\]\n\\[\nf[2, 3] = \\frac{9 - 4}{3 - 2} = 5\n\\]\n\\[\nf[3, 4] = \\frac{16 - 9}{4 - 3} = 7\n\\]\n\nSecond-order divided differences:\n\n\\[\nf[1, 2, 3] = \\frac{f[2, 3] - f[1, 2]}{3 - 1} = \\frac{5 - 3}{2} = 1\n\\]\n\\[\nf[2, 3, 4] = \\frac{f[3, 4] - f[2, 3]}{4 - 2} = \\frac{7 - 5}{2} = 1\n\\]\n\nThird-order divided difference:\n\n\\[\nf[1, 2, 3, 4] = \\frac{f[2, 3, 4] - f[1, 2, 3]}{4 - 1} = \\frac{1 - 1}{3} = 0\n\\]\nNow, the Newton polynomial can be written as:\n\\[\nP(x) = 1 + 3(x - 1) + 1(x - 1)(x - 2) + 0(x - 1)(x - 2)(x - 3)\n\\]\nSimplifying:\n\\[\nP(x) = 1 + 3(x - 1) + (x - 1)(x - 2)\n\\]\nExpanding the terms:\n\\[\nP(x) = 1 + 3x - 3 + (x^2 - 3x + 2)\n\\]\nSimplifying further:\n\\[\nP(x) = x^2\n\\]\n\n\nGeneral Properties of Newton’s Divided Differences\n\nEfficiency: Newton’s divided differences offer better computational efficiency when adding new points to the data set compared to Lagrange interpolation because earlier divided differences can be reused.\nUniqueness: The Newton polynomial is unique, meaning for a given set of \\(n\\) distinct points, there is exactly one polynomial of degree \\(n-1\\) that interpolates the points.\nIterative Construction: The method allows for iterative construction, which is useful when dealing with real-time updates or adding new data points.\n\n\n\nApplications of Newton’s Divided Differences\n\nPolynomial Interpolation: Newton’s divided differences are commonly used to find an interpolating polynomial for a given set of data points.\nNumerical Differentiation: The method is used to approximate derivatives of functions when analytical differentiation is not feasible.\nCurve Fitting: It is used in applications requiring curve fitting, especially in scientific computing and data analysis.\n\n\n\nAdvantages of Newton’s Divided Differences\n\nEfficient for Incremental Data: If you need to add a new data point, you don’t have to recompute the entire polynomial. Only the new divided differences need to be computed.\nEasy to Implement: The recursive approach to finding divided differences makes this method easy to implement in code.\n\n\n\nLimitations of Newton’s Divided Differences\n\nNumerical Stability: Like other polynomial interpolation methods, Newton’s divided differences can suffer from numerical instability, especially with large datasets or unevenly spaced data.\nOscillations: High-degree interpolating polynomials may oscillate significantly between data points, especially if the data is not well-distributed (similar to Runge’s phenomenon).\n\n\n\nConclusion\nNewton’s Divided Differences is a powerful method for constructing interpolating polynomials, especially when efficiency and incremental data updates are needed. Its recursive nature allows for fast updates when new data points are added, making it useful in applications such as numerical analysis, interpolation, and curve fitting."
  },
  {
    "objectID": "notes/w01/secant-method.html",
    "href": "notes/w01/secant-method.html",
    "title": "Secant Method",
    "section": "",
    "text": "The Secant Method is a numerical method for finding roots of a nonlinear equation \\(f(x) = 0\\). It is similar to Newton’s Method, but it does not require the computation of the derivative \\(f'(x)\\). Instead, the Secant Method approximates the derivative using a secant line through two points on the function."
  },
  {
    "objectID": "notes/w01/secant-method.html#the-secant-method-formula",
    "href": "notes/w01/secant-method.html#the-secant-method-formula",
    "title": "Secant Method",
    "section": "The Secant Method Formula",
    "text": "The Secant Method Formula\nGiven two initial approximations \\(x_{k-1}\\) and \\(x_k\\), the next approximation \\(x_{k+1}\\) is computed using the secant line through these points. The formula is:\n\\[\nx_{k+1} = x_k - \\frac{f(x_k)(x_k - x_{k-1})}{f(x_k) - f(x_{k-1})}\n\\]\nThis equation is derived by approximating the derivative \\(f'(x_k)\\) using the difference quotient:\n\\[\nf'(x_k) \\approx \\frac{f(x_k) - f(x_{k-1})}{x_k - x_{k-1}}\n\\]\nThe main advantage of the Secant Method is that it avoids the need to compute the derivative \\(f'(x)\\), making it useful for functions where the derivative is difficult to compute or does not exist.\n\nAlgorithm\n\nInitial Guesses: Start with two initial approximations \\(x_0\\) and \\(x_1\\).\nIteration Formula: Compute successive approximations using the formula:\n\n\\[\nx_{k+1} = x_k - \\frac{f(x_k)(x_k - x_{k-1})}{f(x_k) - f(x_{k-1})}\n\\]\n\nRepeat: Continue iterating until the difference between successive approximations is less than a specified tolerance \\(\\epsilon\\), or until \\(|f(x_k)| &lt; \\epsilon\\).\n\n\n\nConvergence\nThe Secant Method typically converges faster than the Bisection Method but slower than Newton’s Method. It has a convergence rate of approximately \\(1.618\\), known as superlinear convergence. This is faster than the linear convergence of the Bisection Method, but slower than the quadratic convergence of Newton’s Method.\n\n\nExample\nLet’s solve the equation \\(f(x) = x^2 - 4 = 0\\) using the Secant Method, which has roots at \\(x = \\pm 2\\).\n\nInitial Guesses: Let \\(x_0 = 3\\) and \\(x_1 = 2.5\\).\nFirst Iteration:\n\\[\nx_2 = x_1 - \\frac{f(x_1)(x_1 - x_0)}{f(x_1) - f(x_0)} = 2.5 - \\frac{(2.5^2 - 4)(2.5 - 3)}{(2.5^2 - 4) - (3^2 - 4)} = 2.05\n\\]\nSecond Iteration:\n\\[\nx_3 = x_2 - \\frac{f(x_2)(x_2 - x_1)}{f(x_2) - f(x_1)} = 2.05 - \\frac{(2.05^2 - 4)(2.05 - 2.5)}{(2.05^2 - 4) - (2.5^2 - 4)} \\approx 2.0006\n\\]\nFurther Iterations: Continue until the difference between successive approximations is less than a specified tolerance (e.g., \\(\\epsilon = 10^{-5}\\)).\n\nIn this case, after just two iterations, we are already very close to the root \\(x = 2\\).\n\n\nGeneral Properties of the Secant Method\n\nNo Derivatives Needed: Unlike Newton’s Method, the Secant Method does not require the computation of the derivative \\(f'(x)\\), making it useful for functions that are not differentiable or where computing the derivative is expensive.\nSuperlinear Convergence: The Secant Method converges faster than the Bisection Method but slower than Newton’s Method. Its convergence rate is superlinear with a rate of approximately \\(1.618\\).\nRequires Two Initial Guesses: The method requires two initial approximations, \\(x_0\\) and \\(x_1\\), unlike Newton’s Method, which only needs one initial guess.\n\n\n\nApplications of the Secant Method\n\nRoot Finding: The Secant Method is widely used to find roots of non-linear equations, especially in cases where the derivative is not available or is costly to compute.\nOptimization: It can be used in optimization problems where the objective is to minimize or maximize a function without requiring the calculation of the derivative.\n\n\n\nAdvantages of the Secant Method\n\nNo Derivatives: The method does not require the calculation of \\(f'(x)\\), making it easier to apply in situations where the derivative is not known.\nFaster than Bisection: The Secant Method generally converges more quickly than the Bisection Method, especially when the initial guesses are close to the root.\n\n\n\nLimitations of the Secant Method\n\nSlower than Newton’s Method: While it converges faster than the Bisection Method, the Secant Method typically converges more slowly than Newton’s Method, which has quadratic convergence.\nConvergence is Not Guaranteed: The Secant Method does not always converge, especially if the initial guesses are not close to the actual root. If \\(f(x_k) = f(x_{k-1})\\), the method will fail due to division by zero.\nRequires Good Initial Guesses: Poor choices for the initial approximations \\(x_0\\) and \\(x_1\\) can result in slow convergence or failure to converge.\n\n\n\nConclusion\nThe Secant Method provides a good balance between speed and ease of use, especially when derivatives are difficult or costly to compute. It is faster than the Bisection Method but not as fast as Newton’s Method when derivatives are available. Careful selection of initial guesses is important for ensuring successful convergence."
  },
  {
    "objectID": "notes/w01/fixed-point-iteration.html",
    "href": "notes/w01/fixed-point-iteration.html",
    "title": "Fixed-Point Iteration",
    "section": "",
    "text": "Fixed-Point Iteration is a simple numerical method used to solve equations of the form \\(x = g(x)\\). The method is based on the idea that a root of the equation \\(f(x) = 0\\) can be found by rewriting it as \\(x = g(x)\\), and then iterating the function \\(g(x)\\) until the sequence of values converges to a solution."
  },
  {
    "objectID": "notes/w01/fixed-point-iteration.html#the-fixed-point-iteration-formula",
    "href": "notes/w01/fixed-point-iteration.html#the-fixed-point-iteration-formula",
    "title": "Fixed-Point Iteration",
    "section": "The Fixed-Point Iteration Formula",
    "text": "The Fixed-Point Iteration Formula\nThe fixed-point iteration method involves the recursive formula:\n\\[\nx_{k+1} = g(x_k)\n\\]\nHere, \\(x_k\\) is the \\(k\\)-th approximation of the root, and \\(g(x)\\) is a function chosen such that the equation \\(x = g(x)\\) has the same solution as \\(f(x) = 0\\). The sequence \\(x_k\\) is expected to converge to the fixed point \\(x^*\\), where \\(x^* = g(x^*)\\).\n\nConvergence Criteria\nFor fixed-point iteration to converge, certain conditions must be met:\n\nThe function \\(g(x)\\) must be continuous in the interval around the fixed point.\nThe derivative \\(g'(x)\\) must satisfy the following condition for convergence at the fixed point \\(x^*\\):\n\n\\[\n|g'(x^*)| &lt; 1\n\\]\nIf \\(|g'(x^*)| \\geq 1\\), the iteration may not converge.\n\n\nStep-by-Step Procedure\n\nChoose an initial guess \\(x_0\\).\nApply the recursive formula:\n\n\\[\nx_{k+1} = g(x_k)\n\\]\n\nRepeat the iteration until the difference between successive approximations is sufficiently small (i.e., \\(|x_{k+1} - x_k| &lt; \\epsilon\\), where \\(\\epsilon\\) is a small tolerance value).\nThe value of \\(x_k\\) is the approximate solution to the equation.\n\n\n\nExample\nLet’s go through an example where we solve the equation \\(x^2 - 2 = 0\\), which has a solution at \\(x = \\sqrt{2}\\). We can rewrite this equation in the form \\(x = g(x)\\) as:\n\\[\ng(x) = \\frac{2}{x}\n\\]\n\nInitial guess: Let \\(x_0 = 1.5\\).\nFirst iteration: Using the recursive formula \\(x_{k+1} = g(x_k)\\):\n\n\\[\nx_1 = g(x_0) = \\frac{2}{1.5} = 1.3333\n\\]\n\nSecond iteration:\n\n\\[\nx_2 = g(x_1) = \\frac{2}{1.3333} = 1.5\n\\]\n\nThird iteration:\n\n\\[\nx_3 = g(x_2) = \\frac{2}{1.5} = 1.3333\n\\]\nIn this case, the iterations quickly begin to oscillate around the solution. Further iterations will converge to \\(\\sqrt{2}\\), depending on the tolerance value.\n\n\nConvergence and Stability\nThe method converges when the derivative \\(|g'(x^*)| &lt; 1\\), ensuring that the successive values get closer to the actual solution. If \\(|g'(x)| &gt; 1\\) near the fixed point, the iterations may diverge, oscillate, or converge very slowly.\n\n\nAcceleration Techniques\n\nAitken’s \\(\\Delta^2\\)-Process: This method accelerates convergence by extrapolating the sequence of approximations.\nRelaxation Methods: Modifying the iterative formula to include a relaxation parameter \\(\\lambda\\), such as in under-relaxation and over-relaxation, to speed up convergence:\n\n\\[\nx_{k+1} = (1 - \\lambda)x_k + \\lambda g(x_k)\n\\]\nWhere \\(\\lambda \\in (0,1)\\) for under-relaxation and \\(\\lambda &gt; 1\\) for over-relaxation.\n\n\nApplications of Fixed-Point Iteration\n\nRoot-Finding: It is commonly used to find roots of non-linear equations.\nDynamical Systems: Fixed-point iterations are used to model and analyze the behavior of dynamical systems that stabilize at an equilibrium point.\nOptimization: In optimization problems, fixed-point methods can help solve systems of equations that arise from optimization constraints.\n\n\n\nAdvantages of Fixed-Point Iteration\n\nSimple Implementation: The method is easy to implement and requires only basic operations.\nApplicable to Various Problems: It can be applied to a wide range of equations and is useful in many scientific and engineering applications.\n\n\n\nLimitations of Fixed-Point Iteration\n\nSlow Convergence: Fixed-point iteration may converge slowly, especially if the function \\(g(x)\\) is poorly chosen.\nSensitive to Initial Guess: The success and speed of convergence depend heavily on the choice of the initial guess. A poor initial guess can lead to divergence.\nNot Always Convergent: If \\(|g'(x)| \\geq 1\\), the method may not converge to a solution, and alternative methods like Newton’s Method or Bisection Method may be preferred.\n\n\n\nConclusion\nFixed-point iteration is a fundamental and simple numerical method for finding roots of equations. However, it is essential to ensure the proper choice of function \\(g(x)\\) and initial guess to ensure convergence. While it is not always the fastest method, its simplicity makes it a good starting point for solving non-linear equations."
  },
  {
    "objectID": "notes/index.html",
    "href": "notes/index.html",
    "title": "Notes",
    "section": "",
    "text": "Bisection Method\nFixed-Point Iteration\nNewtons’s Method\nSecant Method"
  },
  {
    "objectID": "notes/index.html#week-1",
    "href": "notes/index.html#week-1",
    "title": "Notes",
    "section": "",
    "text": "Bisection Method\nFixed-Point Iteration\nNewtons’s Method\nSecant Method"
  },
  {
    "objectID": "notes/index.html#week-2",
    "href": "notes/index.html#week-2",
    "title": "Notes",
    "section": "Week 2",
    "text": "Week 2\n\nLagrange Interpolation\nNewton’s Divided Differences"
  },
  {
    "objectID": "notes/index.html#week-3",
    "href": "notes/index.html#week-3",
    "title": "Notes",
    "section": "Week 3",
    "text": "Week 3\n\nInterpolation Error Formula\nRunge Phenomenon\nChebyshev Interpolation"
  },
  {
    "objectID": "notes/index.html#week-4",
    "href": "notes/index.html#week-4",
    "title": "Notes",
    "section": "Week 4",
    "text": "Week 4\n\nTrapezoidal Rule"
  },
  {
    "objectID": "notes/index.html#week-5",
    "href": "notes/index.html#week-5",
    "title": "Notes",
    "section": "Week 5",
    "text": "Week 5"
  },
  {
    "objectID": "notes/index.html#week-6",
    "href": "notes/index.html#week-6",
    "title": "Notes",
    "section": "Week 6",
    "text": "Week 6"
  },
  {
    "objectID": "notes/index.html#week-7",
    "href": "notes/index.html#week-7",
    "title": "Notes",
    "section": "Week 7",
    "text": "Week 7\n\nLU Factorization\n\n\n\n\n\n\n\nWeek 8\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWeek 9\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWeek 10\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWeek 11\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWeek 12\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWeek"
  },
  {
    "objectID": "homework/w07/exercise2-4-4a.html",
    "href": "homework/w07/exercise2-4-4a.html",
    "title": "Exercise 2.4.4a (C2-P9)",
    "section": "",
    "text": "Solve the system by finding the \\(PA = LU\\) factorization and then carrying out the two-step back substitution:\n\\[\n\\begin{pmatrix} 4 & 2 & 0 \\\\ 4 & 4 & 2 \\\\ 2 & 2 & 3 \\end{pmatrix} \\begin{pmatrix} x_1 \\\\ x_2 \\\\ x_3 \\end{pmatrix} = \\begin{pmatrix} 2 \\\\ 4 \\\\ 6 \\end{pmatrix}\n\\]"
  },
  {
    "objectID": "homework/w07/exercise2-4-4a.html#lu-factorization-with-partial-pivoting",
    "href": "homework/w07/exercise2-4-4a.html#lu-factorization-with-partial-pivoting",
    "title": "Exercise 2.4.4a (C2-P9)",
    "section": "LU Factorization with Partial Pivoting",
    "text": "LU Factorization with Partial Pivoting\nStep 1: First Column\n\nPivot Selection: Both \\(a_{11} = 4\\) and \\(a_{21} = 4\\) are tied for the largest absolute value. Choose \\(a_{11}\\) as the pivot (no row swap needed).\nCompute Multipliers and Eliminate Below Pivot:\n\nRow 2:\n\\[\nL_{21} = \\dfrac{a_{21}}{a_{11}} = \\dfrac{4}{4} = 1\n\\]\n\\[\n\\text{Row 2} \\rightarrow \\text{Row 2} - L_{21} \\times \\text{Row 1}\n\\]\n\\[\n\\begin{pmatrix} 4 & 2 & 0 \\\\ 0 & 2 & 2 \\\\ 2 & 2 & 3 \\end{pmatrix}\n\\]\nRow 3: \\[\nL_{31} = \\dfrac{a_{31}}{a_{11}} = \\dfrac{2}{4} = \\dfrac{1}{2}\n\\] \\[\n\\text{Row 3} \\rightarrow \\text{Row 3} - L_{31} \\times \\text{Row 1}\n\\] \\[\n\\begin{pmatrix} 4 & 2 & 0 \\\\ 0 & 2 & 2 \\\\ 0 & 1 & 3 \\end{pmatrix}\n\\]\n\n\nStep 2: Second Column\n\nPivot Selection: \\(U_{22} = 2\\) is the largest absolute value below the pivot (no row swap needed).\nCompute Multiplier and Eliminate Below Pivot:\n\nRow 3: \\[\nL_{32} = \\dfrac{U_{32}}{U_{22}} = \\dfrac{1}{2}\n\\] \\[\n\\text{Row 3} \\rightarrow \\text{Row 3} - L_{32} \\times \\text{Row 2}\n\\] \\[\n\\begin{pmatrix} 4 & 2 & 0 \\\\ 0 & 2 & 2 \\\\ 0 & 0 & 2 \\end{pmatrix}\n\\]\n\n\nResulting Matrices\n\nLower Triangular Matrix \\(L\\):\n\\[\nL = \\begin{pmatrix}\n1 & 0 & 0 \\\\\n1 & 1 & 0 \\\\\n\\dfrac{1}{2} & \\dfrac{1}{2} & 1\n\\end{pmatrix}\n\\]\nUpper Triangular Matrix \\(U\\):\n\\[\nU = \\begin{pmatrix}\n4 & 2 & 0 \\\\\n0 & 2 & 2 \\\\\n0 & 0 & 2\n\\end{pmatrix}\n\\]\nPermutation Matrix \\(P\\): \\[\nP = I \\quad (\\text{identity matrix, since no row swaps were performed})\n\\]"
  },
  {
    "objectID": "homework/w07/exercise2-4-4a.html#forward-substitution-solve-ly-b",
    "href": "homework/w07/exercise2-4-4a.html#forward-substitution-solve-ly-b",
    "title": "Exercise 2.4.4a (C2-P9)",
    "section": "Forward Substitution: Solve \\(Ly = b\\)",
    "text": "Forward Substitution: Solve \\(Ly = b\\)\n\\[\nL \\begin{pmatrix} y_1 \\\\ y_2 \\\\ y_3 \\end{pmatrix} = \\begin{pmatrix} 2 \\\\ 4 \\\\ 6 \\end{pmatrix}\n\\]\n\nEquation 1:\n\\[\ny_1 = 2\n\\]\nEquation 2:\n\\[\ny_2 = b_2 - L_{21} y_1 = 4 - (1)(2) = 2\n\\]\nEquation 3: \\[\ny_3 = b_3 - L_{31} y_1 - L_{32} y_2 = 6 - \\left( \\dfrac{1}{2} \\times 2 \\right) - \\left( \\dfrac{1}{2} \\times 2 \\right) = 6 - 1 - 1 = 4\n\\]\n\nSolution:\n\\[\ny = \\begin{pmatrix} 2 \\\\ 2 \\\\ 4 \\end{pmatrix}\n\\]"
  },
  {
    "objectID": "homework/w07/exercise2-4-4a.html#back-substitution-solve-ux-y",
    "href": "homework/w07/exercise2-4-4a.html#back-substitution-solve-ux-y",
    "title": "Exercise 2.4.4a (C2-P9)",
    "section": "Back Substitution: Solve \\(Ux = y\\)",
    "text": "Back Substitution: Solve \\(Ux = y\\)\n\\[\nU \\begin{pmatrix} x_1 \\\\ x_2 \\\\ x_3 \\end{pmatrix} = \\begin{pmatrix} 2 \\\\ 2 \\\\ 4 \\end{pmatrix}\n\\]\n\nEquation 3:\n\\[\n2 x_3 = y_3 \\implies x_3 = \\dfrac{y_3}{2} = \\dfrac{4}{2} = 2\n\\]\nEquation 2:\n\\[\n2 x_2 + 2 x_3 = y_2 \\implies x_2 = \\dfrac{y_2 - 2 x_3}{2} = \\dfrac{2 - (2 \\times 2)}{2} = \\dfrac{-2}{2} = -1\n\\]\nEquation 1: \\[\n4 x_1 + 2 x_2 = y_1 \\implies x_1 = \\dfrac{y_1 - 2 x_2}{4} = \\dfrac{2 - (2 \\times -1)}{4} = \\dfrac{2 + 2}{4} = \\dfrac{4}{4} = 1\n\\]\n\nSolution:\n\\[\nx = \\begin{pmatrix} 1 \\\\ -1 \\\\ 2 \\end{pmatrix}\n\\]\nFinal Answer\nThe solution to the system is:\n\\[\nx_1 = 1, \\quad x_2 = -1, \\quad x_3 = 2\n\\]"
  },
  {
    "objectID": "homework/w04/exercise5-2-1a.html",
    "href": "homework/w04/exercise5-2-1a.html",
    "title": "Exercise 5.2.1a (C5-P1)",
    "section": "",
    "text": "Problem\n\nApply the composite Trapezoid Rule with m = 1, 2, and 4 panels to approximate the integral. Compute the error by comparing with the exact value from calculus.\n\n\\int_0^1 x^2 \\, dx\n\n\n\nKey Concepts\n\n\nComposite Trapezoidal Rule\nThe formula for the composite trapezoidal rule is:\n\nT_m = \\frac{h}{2} \\left( f(a) + 2 \\sum_{i=1}^{m-1} f(x_i) + f(b) \\right)\n\nwhere:\n\nh = \\frac{b - a}{m}\nx_i = a + i \\cdot h for i = 1, 2, \\ldots, m-1\n\n\n\n\nSolution\n\n\n1. Exact Value of the Integral\nWe first compute the exact value of the integral:\n\n\\int_0^1 x^2 \\, dx = \\left[ \\frac{x^3}{3} \\right]_0^1 = \\frac{1^3}{3} - \\frac{0^3}{3} = \\frac{1}{3} \\approx 0.3333\n\n\n\n\n2. Approximations Using the Composite Trapezoidal Rule\n\nCase m = 1:\n\nh = \\frac{1 - 0}{1} = 1\nPoints: x_0 = 0, x_1 = 1\nApproximation:\n\n\nT_1 = \\frac{1}{2} \\left( f(0) + f(1) \\right) = \\frac{1}{2} \\left( 0^2 + 1^2 \\right) = \\frac{1}{2} \\cdot 1 = 0.5\n\n\nError:\n\n\n\\text{Error} = \\left| 0.3333 - 0.5 \\right| = 0.1667\n\n\n\n\nCase m = 2:\n\nh = \\frac{1 - 0}{2} = 0.5\nPoints: x_0 = 0, x_1 = 0.5, x_2 = 1\nApproximation:\n\n\nT_2 = \\frac{0.5}{2} \\left( f(0) + 2 \\cdot f(0.5) + f(1) \\right) = \\frac{0.5}{2} \\left( 0^2 + 2 \\cdot 0.5^2 + 1^2 \\right)\n\n\nT_2 = \\frac{0.5}{2} \\cdot (0 + 2 \\cdot 0.25 + 1) = \\frac{0.5}{2} \\cdot 1.5 = 0.375\n\n\nError:\n\n\n\\text{Error} = \\left| 0.3333 - 0.375 \\right| = 0.0417\n\n\n\n\nCase m = 4:\n\nh = \\frac{1 - 0}{4} = 0.25\nPoints: x_0 = 0, x_1 = 0.25, x_2 = 0.5, x_3 = 0.75, x_4 = 1\nApproximation:\n\n\nT_4 = \\frac{0.25}{2} \\left( f(0) + 2 \\cdot \\left( f(0.25) + f(0.5) + f(0.75) \\right) + f(1) \\right)\n\n\nT_4 = \\frac{0.25}{2} \\left( 0^2 + 2 \\cdot (0.25^2 + 0.5^2 + 0.75^2) + 1^2 \\right)\n\n\nT_4 = \\frac{0.25}{2} \\cdot (0 + 2 \\cdot (0.0625 + 0.25 + 0.5625) + 1) = \\frac{0.25}{2} \\cdot 2.75 = 0.34375\n\n\nError:\n\n\n\\text{Error} = \\left| 0.3333 - 0.34375 \\right| = 0.0104\n\n\n\n\n\n3. Summary of Results\n\n\n\nm\nApproximation\nError\n\n\n\n\n1\n0.5000\n0.1667\n\n\n2\n0.3750\n0.0417\n\n\n4\n0.3438\n0.0104\n\n\n\n\n\n\n4. Conclusion\nAs the number of panels m increases, the approximation becomes more accurate, and the error decreases. This demonstrates that the composite trapezoidal rule converges to the exact value as the number of panels increases."
  },
  {
    "objectID": "homework/w03/exercise3-2-5.html",
    "href": "homework/w03/exercise3-2-5.html",
    "title": "Exercise 3.1.6 (C3-P6)",
    "section": "",
    "text": "How do we construct a polynomial of degree exactly 5 that interpolates four points?\nGiven four points (1, 1), (2, 3), (3, 3), and (4, 4), the standard interpolation methods (such as Newton’s or Lagrange’s methods) would give us a unique polynomial of degree 3. However, constructing a polynomial of degree exactly 5 requires a different approach.\n\n\n\nTheorem 3.2 (Main Theorem of Polynomial Interpolation) guarantees that a unique polynomial of degree n-1 exists for n distinct points.\nTo create a polynomial of degree 5 when you only have 4 points, you need to add an extra term that still passes through all the original points but elevates the polynomial’s degree.\n\n\n\n\nTo create a degree 5 polynomial that still passes through all four points (1, 1), (2, 3), (3, 3), and (4, 4), follow these steps:\n\nFind the degree 3 polynomial P_3(x):\n\nUse either Newton’s divided differences or Lagrange interpolation to find the polynomial of degree 3 that passes through the given points. Let’s call this polynomial P_3(x).\n\nAdd a higher-degree term:\n\nTo turn this degree 3 polynomial into a degree 5 polynomial, we add a term that evaluates to zero at the given points:\n\n\nP_5(x) = P_3(x) + c(x - 1)(x - 2)(x - 3)(x - 4)\n\nThe new term (x - 1)(x - 2)(x - 3)(x - 4) is zero at x = 1, 2, 3, 4, so it won’t affect the interpolation at those points. By multiplying this term by a constant c, we ensure that the degree of the polynomial is elevated to 5, but the polynomial still interpolates the original points.\n\n\n\n\nThus, the degree 5 polynomial is given by:\nP_5(x) = P_3(x) + c(x - 1)(x - 2)(x - 3)(x - 4)\n\nP_3(x) is the degree 3 polynomial found using standard interpolation methods.\nc is an arbitrary constant that determines the shape of the polynomial outside the interpolation points.\n\n\n\n\nLet’s assume the degree 3 polynomial P_3(x) through the points (1, 1), (2, 3), (3, 3), (4, 4) is:\nP_3(x) = 1 + 2(x - 1) + 3(x - 1)(x - 2)\nThen the degree 5 polynomial becomes:\nP_5(x) = P_3(x) + c(x - 1)(x - 2)(x - 3)(x - 4)\n\n\n\nNo, the value of c does not affect the interpolation at the given points. Since the additional term evaluates to 0 at x = 1, 2, 3, 4, the polynomial will still pass through the points, regardless of c.\nHowever, changing c affects the behavior of the polynomial outside the interpolation points. For different values of c, the polynomial will look different beyond the four points, but it will still pass through (1, 1), $(2, 3) $, $ (3, 3) $, and $ (4, 4)$."
  },
  {
    "objectID": "homework/w03/exercise3-2-5.html#question",
    "href": "homework/w03/exercise3-2-5.html#question",
    "title": "Exercise 3.1.6 (C3-P6)",
    "section": "",
    "text": "How do we construct a polynomial of degree exactly 5 that interpolates four points?\nGiven four points (1, 1), (2, 3), (3, 3), and (4, 4), the standard interpolation methods (such as Newton’s or Lagrange’s methods) would give us a unique polynomial of degree 3. However, constructing a polynomial of degree exactly 5 requires a different approach.\n\n\n\nTheorem 3.2 (Main Theorem of Polynomial Interpolation) guarantees that a unique polynomial of degree n-1 exists for n distinct points.\nTo create a polynomial of degree 5 when you only have 4 points, you need to add an extra term that still passes through all the original points but elevates the polynomial’s degree.\n\n\n\n\nTo create a degree 5 polynomial that still passes through all four points (1, 1), (2, 3), (3, 3), and (4, 4), follow these steps:\n\nFind the degree 3 polynomial P_3(x):\n\nUse either Newton’s divided differences or Lagrange interpolation to find the polynomial of degree 3 that passes through the given points. Let’s call this polynomial P_3(x).\n\nAdd a higher-degree term:\n\nTo turn this degree 3 polynomial into a degree 5 polynomial, we add a term that evaluates to zero at the given points:\n\n\nP_5(x) = P_3(x) + c(x - 1)(x - 2)(x - 3)(x - 4)\n\nThe new term (x - 1)(x - 2)(x - 3)(x - 4) is zero at x = 1, 2, 3, 4, so it won’t affect the interpolation at those points. By multiplying this term by a constant c, we ensure that the degree of the polynomial is elevated to 5, but the polynomial still interpolates the original points.\n\n\n\n\nThus, the degree 5 polynomial is given by:\nP_5(x) = P_3(x) + c(x - 1)(x - 2)(x - 3)(x - 4)\n\nP_3(x) is the degree 3 polynomial found using standard interpolation methods.\nc is an arbitrary constant that determines the shape of the polynomial outside the interpolation points.\n\n\n\n\nLet’s assume the degree 3 polynomial P_3(x) through the points (1, 1), (2, 3), (3, 3), (4, 4) is:\nP_3(x) = 1 + 2(x - 1) + 3(x - 1)(x - 2)\nThen the degree 5 polynomial becomes:\nP_5(x) = P_3(x) + c(x - 1)(x - 2)(x - 3)(x - 4)\n\n\n\nNo, the value of c does not affect the interpolation at the given points. Since the additional term evaluates to 0 at x = 1, 2, 3, 4, the polynomial will still pass through the points, regardless of c.\nHowever, changing c affects the behavior of the polynomial outside the interpolation points. For different values of c, the polynomial will look different beyond the four points, but it will still pass through (1, 1), $(2, 3) $, $ (3, 3) $, and $ (4, 4)$."
  },
  {
    "objectID": "homework/w02/exercise3-1-6.html",
    "href": "homework/w02/exercise3-1-6.html",
    "title": "Exercise 3.1.6 (C3-P6)",
    "section": "",
    "text": "How do we construct a polynomial of degree exactly 5 that interpolates four points?\nGiven four points (1, 1), (2, 3), (3, 3), and (4, 4), the standard interpolation methods (such as Newton’s or Lagrange’s methods) would give us a unique polynomial of degree 3. However, constructing a polynomial of degree exactly 5 requires a different approach.\n\n\n\nTheorem 3.2 (Main Theorem of Polynomial Interpolation) guarantees that a unique polynomial of degree n-1 exists for n distinct points.\nTo create a polynomial of degree 5 when you only have 4 points, you need to add an extra term that still passes through all the original points but elevates the polynomial’s degree.\n\n\n\n\n\nWe will use Newton’s divided differences to first construct the degree 3 polynomial, and then extend it to a degree 5 polynomial.\n\n\n\nWe will use the given points (x_1, y_1) = (1, 1), (x_2, y_2) = (2, 3), (x_3, y_3) = (3, 3), and (x_4, y_4) = (4, 4) to compute the divided differences and build the polynomial.\n\n\n\n\n\n\n\n\n\n\nx\nf(x)\nFirst Difference f[x_i, x_{i+1}]\nSecond Difference f[x_i, x_{i+1}, x_{i+2}]\nThird Difference f[x_i, x_{i+1}, x_{i+2}, x_{i+3}]\n\n\n\n\n1\n1\n\n\n\n\n\n2\n3\n\\frac{3 - 1}{2 - 1} = 2\n\n\n\n\n3\n3\n\\frac{3 - 3}{3 - 2} = 0\n\\frac{0 - 2}{3 - 1} = -1\n\n\n\n4\n4\n\\frac{4 - 3}{4 - 3} = 1\n\\frac{1 - 0}{4 - 2} = \\frac{1}{2}\n\\frac{\\frac{1}{2} - (-1)}{4 - 1} = \\frac{3}{6} = \\frac{1}{2}\n\n\n\n\n\n\nThe Newton’s divided difference form of the interpolating polynomial is:\n\nP_3(x) = f[x_1] + f[x_1, x_2](x - x_1) + f[x_1, x_2, x_3](x - x_1)(x - x_2) + f[x_1, x_2, x_3, x_4](x - x_1)(x - x_2)(x - x_3)\n\nSubstituting the values from the divided difference table:\n\nP_3(x) = 1 + 2(x - 1) - (x - 1)(x - 2) + \\frac{1}{2}(x - 1)(x - 2)(x - 3)\n\n\n\n\nTo create a degree 5 polynomial, we add an extra term c(x - 1)(x - 2)(x - 3)(x - 4), which evaluates to zero at the given points:\n\nP_5(x) = P_3(x) + c(x - 1)(x - 2)(x - 3)(x - 4)\n\nSubstitute P_3(x):\n\nP_5(x) = 1 + 2(x - 1) - (x - 1)(x - 2) + \\frac{1}{2}(x - 1)(x - 2)(x - 3) + c(x - 1)(x - 2)(x - 3)(x - 4)\n\n\n\n\nThe value of c does not affect the polynomial at the given points. The additional term evaluates to 0 at x = 1, 2, 3, 4, so no matter what c is, the polynomial will pass through the points (1, 1), (2, 3), (3, 3), (4, 4).\nHowever, changing c will affect the polynomial’s behavior outside the given points. For different values of c, the polynomial will look different outside the interpolation points.\n\n\n\n\nThus, the degree 5 polynomial is:\n\nP_5(x) = 1 + 2(x - 1) - (x - 1)(x - 2) + \\frac{1}{2}(x - 1)(x - 2)(x - 3) + c(x - 1)(x - 2)(x - 3)(x - 4)\n\nThis polynomial passes through the points (1, 1), (2, 3), (3, 3), (4, 4), and c is an arbitrary constant that influences how the polynomial behaves outside of those points."
  },
  {
    "objectID": "homework/w02/exercise3-1-6.html#question",
    "href": "homework/w02/exercise3-1-6.html#question",
    "title": "Exercise 3.1.6 (C3-P6)",
    "section": "",
    "text": "How do we construct a polynomial of degree exactly 5 that interpolates four points?\nGiven four points (1, 1), (2, 3), (3, 3), and (4, 4), the standard interpolation methods (such as Newton’s or Lagrange’s methods) would give us a unique polynomial of degree 3. However, constructing a polynomial of degree exactly 5 requires a different approach.\n\n\n\nTheorem 3.2 (Main Theorem of Polynomial Interpolation) guarantees that a unique polynomial of degree n-1 exists for n distinct points.\nTo create a polynomial of degree 5 when you only have 4 points, you need to add an extra term that still passes through all the original points but elevates the polynomial’s degree.\n\n\n\n\n\nWe will use Newton’s divided differences to first construct the degree 3 polynomial, and then extend it to a degree 5 polynomial.\n\n\n\nWe will use the given points (x_1, y_1) = (1, 1), (x_2, y_2) = (2, 3), (x_3, y_3) = (3, 3), and (x_4, y_4) = (4, 4) to compute the divided differences and build the polynomial.\n\n\n\n\n\n\n\n\n\n\nx\nf(x)\nFirst Difference f[x_i, x_{i+1}]\nSecond Difference f[x_i, x_{i+1}, x_{i+2}]\nThird Difference f[x_i, x_{i+1}, x_{i+2}, x_{i+3}]\n\n\n\n\n1\n1\n\n\n\n\n\n2\n3\n\\frac{3 - 1}{2 - 1} = 2\n\n\n\n\n3\n3\n\\frac{3 - 3}{3 - 2} = 0\n\\frac{0 - 2}{3 - 1} = -1\n\n\n\n4\n4\n\\frac{4 - 3}{4 - 3} = 1\n\\frac{1 - 0}{4 - 2} = \\frac{1}{2}\n\\frac{\\frac{1}{2} - (-1)}{4 - 1} = \\frac{3}{6} = \\frac{1}{2}\n\n\n\n\n\n\nThe Newton’s divided difference form of the interpolating polynomial is:\n\nP_3(x) = f[x_1] + f[x_1, x_2](x - x_1) + f[x_1, x_2, x_3](x - x_1)(x - x_2) + f[x_1, x_2, x_3, x_4](x - x_1)(x - x_2)(x - x_3)\n\nSubstituting the values from the divided difference table:\n\nP_3(x) = 1 + 2(x - 1) - (x - 1)(x - 2) + \\frac{1}{2}(x - 1)(x - 2)(x - 3)\n\n\n\n\nTo create a degree 5 polynomial, we add an extra term c(x - 1)(x - 2)(x - 3)(x - 4), which evaluates to zero at the given points:\n\nP_5(x) = P_3(x) + c(x - 1)(x - 2)(x - 3)(x - 4)\n\nSubstitute P_3(x):\n\nP_5(x) = 1 + 2(x - 1) - (x - 1)(x - 2) + \\frac{1}{2}(x - 1)(x - 2)(x - 3) + c(x - 1)(x - 2)(x - 3)(x - 4)\n\n\n\n\nThe value of c does not affect the polynomial at the given points. The additional term evaluates to 0 at x = 1, 2, 3, 4, so no matter what c is, the polynomial will pass through the points (1, 1), (2, 3), (3, 3), (4, 4).\nHowever, changing c will affect the polynomial’s behavior outside the given points. For different values of c, the polynomial will look different outside the interpolation points.\n\n\n\n\nThus, the degree 5 polynomial is:\n\nP_5(x) = 1 + 2(x - 1) - (x - 1)(x - 2) + \\frac{1}{2}(x - 1)(x - 2)(x - 3) + c(x - 1)(x - 2)(x - 3)(x - 4)\n\nThis polynomial passes through the points (1, 1), (2, 3), (3, 3), (4, 4), and c is an arbitrary constant that influences how the polynomial behaves outside of those points."
  },
  {
    "objectID": "homework/index.html",
    "href": "homework/index.html",
    "title": "Homework",
    "section": "",
    "text": "Suggested Homework"
  },
  {
    "objectID": "homework/index.html#week-1",
    "href": "homework/index.html#week-1",
    "title": "Homework",
    "section": "Week 1",
    "text": "Week 1\n\n(C0-P1)\n(C1-P1) Exercise 1.1.4ab\n(C1-P2) Exercise 1.2.2\n(C1-P3)\n(C1-P4) Exercise 1.2.14\n(C1-P5) Exercise 1.4.1\n(C1-P6) Exercise 1.4.3"
  },
  {
    "objectID": "homework/index.html#week-2",
    "href": "homework/index.html#week-2",
    "title": "Homework",
    "section": "Week 2",
    "text": "Week 2\n\n(C1-P7) Exercise 1.4.6\n(C1-P8) Exercise 1.4.8\n(C1-P9) Computer Problem 1.4.7\n(C1-P10) Exercise 1.5.1\n(C1-P11)\n(C3-P1) Exercise 3.1.1a\n(C3-P1) Exercise 3.1.1c\n(C3-P2) Exercise 3.1.2a\n(C3-P2) Exercise 3.1.2c\n(C3-P3) Exercise 3.1.6"
  },
  {
    "objectID": "homework/index.html#week-3",
    "href": "homework/index.html#week-3",
    "title": "Homework",
    "section": "Week 3",
    "text": "Week 3\n\n(C0-P2)\n(C3-P4) Exercise 3.2.2\n(C3-P5) Exercise 3.2.5\n(C3-P6) Exercise 3.2.6\n(C3-P7) Computer Problem 3.1.3\n(C3-P8) Exercise 3.3.1ac\n(C3-P9) Exercise 3.3.2ac\n(C3-P10) Exercise 3.3.3"
  },
  {
    "objectID": "homework/index.html#week-4",
    "href": "homework/index.html#week-4",
    "title": "Homework",
    "section": "Week 4",
    "text": "Week 4\n\n(C5-P1) Exercise 5.2.1a\n(C5-P1) Exercise 5.2.1b\n(C5-P2) Exercise 5.2.2ab\n(C5-P3) Exercise 5.2.3ab\n(C5-P4) Exercise 5.2.10\n(C5-P5) Exercise 5.2.12\n(C5-P6) Computer Problem 5.2.1ac\n(C5-P7) Computer Problem 5.2.2de\n(C5-P8) Computer Problem 5.2.9bf"
  },
  {
    "objectID": "homework/index.html#week-5",
    "href": "homework/index.html#week-5",
    "title": "Homework",
    "section": "Week 5",
    "text": "Week 5\n\n(C5-P9) Exercise 5.5.1ab\n(C5-P10) Exercise 5.5.4cd\n(C5-P11) Computer Problem 5.4.1acd\n(C5-P12) Computer Problem 5.4.2\n(C5-P13) Computer Problem 5.4.3acd\n(C5-P14) Exercise 5.5.5cd\n(C5-P15) Exercise 5.5.7"
  },
  {
    "objectID": "homework/index.html#week-6",
    "href": "homework/index.html#week-6",
    "title": "Homework",
    "section": "Week 6",
    "text": "Week 6\n\n(C2-P1) Exercise 2.1.2ac\n(C2-P2) Computer Problem 2.1.2ac\n(C2-P3) Exercise 2.2.1ab\n(C2-P4) Exercise 2.2.2ab"
  },
  {
    "objectID": "homework/index.html#week-7",
    "href": "homework/index.html#week-7",
    "title": "Homework",
    "section": "Week 7",
    "text": "Week 7\n\n(C2-P5) Exercise 2.2.4\n(C2-P6) Computer Problem 2.2.1ab\n(C2-P7) Exercise 2.4.1ab\n(C2-P8) Exercise 2.4.2ab\n(C2-P9) Exercise 2.4.4a\n(C2-P10) Exercise 2.4.6"
  },
  {
    "objectID": "homework/index.html#week-8",
    "href": "homework/index.html#week-8",
    "title": "Homework",
    "section": "Week 8",
    "text": "Week 8\n\n(C2-P11) Exercise 2.5.2ab\n(C2-P12) Computer Problem 2.5.2 (solve using both Jacobi and Gauss-Seidel, compare results)\n(C4-P1) Exercise 4.1.2\n(C4-P2) Computer Problem 4.1.5 (also use a quadratic fit and compare)\n(C4-P3) Exercise 4.3.2"
  },
  {
    "objectID": "homework/index.html#week-9",
    "href": "homework/index.html#week-9",
    "title": "Homework",
    "section": "Week 9",
    "text": "Week 9\n\n(C4-P4) Exercise 4.3.4 (use the matrix from Exercise 4.3.1d)\n(C4-P5) Exercise 4.3.7 (you can use your QR factorizations from Exercise 4.3.2)\n(C4-P6) Computer Problem 4.3.4 Additional instructions: Write a classical Gram-Schmidt code only. Use the matrices in Exercise 4.3.2 to check your code. If you use the code I provided, you must comment it (explain what every line does)."
  },
  {
    "objectID": "homework/index.html#week-10",
    "href": "homework/index.html#week-10",
    "title": "Homework",
    "section": "Week 10",
    "text": "Week 10\n\n(C4-P7) Exercise 4.4.2\n(C4-P8) Exercise 4.4.3\n(C4-P9) Computer Problem 4.4.2 (find a preconditioned GMRES Python code and use it)"
  },
  {
    "objectID": "homework/index.html#week-11",
    "href": "homework/index.html#week-11",
    "title": "Homework",
    "section": "Week 11",
    "text": "Week 11\nNone"
  },
  {
    "objectID": "homework/index.html#week-12",
    "href": "homework/index.html#week-12",
    "title": "Homework",
    "section": "Week 12",
    "text": "Week 12\n\n(C10-P1) Exercise 10.1.1ad (also, find the inverse DFT of your result, compare to the original vector)\n(C10-P2) Exercise 10.1.8\n(C10-P3) Exercise 10.2.1ab\n(C10-P4) Exercise 10.2.3ab\n(C10-P5) Exercise 10.2.3 (plot data and function to show your interpolating function does interpolate the data)\n(C10-P6) Computer Problem 10.2.4\n(C10-P7) Exercise 10.3.2ab"
  },
  {
    "objectID": "homework/index.html#week-13",
    "href": "homework/index.html#week-13",
    "title": "Homework",
    "section": "Week 13",
    "text": "Week 13\n\n(C10-P8) Computer Problem 10.3.2cd\n(C10-P9) Exercise 10.3.5 (Complete the ( _{j=0}^{n-1} ) result only)\n(C10-P10) Exercise 10.1.6"
  },
  {
    "objectID": "homework/w03/exercise3-2-6.html",
    "href": "homework/w03/exercise3-2-6.html",
    "title": "MATH411",
    "section": "",
    "text": "w03/exercise3-2-5.qmd— title: “Exercise 3.1.6 (C3-P6)” subtitle: “MATH411” author: “Nathan Lunceford” format: html: self-contained: true page-layout: full title-block-banner: true toc: true toc-depth: 3 toc-location: body number-sections: false html-math-method: katex code-fold: true code-summary: “Show the code” code-overflow: wrap code-copy: hover code-tools: source: false toggle: true caption: See code"
  },
  {
    "objectID": "homework/w03/exercise3-2-6.html#question",
    "href": "homework/w03/exercise3-2-6.html#question",
    "title": "MATH411",
    "section": "Question",
    "text": "Question\nHow do we construct a polynomial of degree exactly 5 that interpolates four points?\nGiven four points \\((1, 1)\\), \\((2, 3)\\), \\((3, 3)\\), and \\((4, 4)\\), the standard interpolation methods (such as Newton’s or Lagrange’s methods) would give us a unique polynomial of degree 3. However, constructing a polynomial of degree exactly 5 requires a different approach.\n\nKey Concepts\n\nTheorem 3.2 (Main Theorem of Polynomial Interpolation) guarantees that a unique polynomial of degree \\(n-1\\) exists for \\(n\\) distinct points.\nTo create a polynomial of degree 5 when you only have 4 points, you need to add an extra term that still passes through all the original points but elevates the polynomial’s degree.\n\n\n\nSolution\nTo create a degree 5 polynomial that still passes through all four points \\((1, 1)\\), \\((2, 3)\\), \\((3, 3)\\), and \\((4, 4)\\), follow these steps:\n\nFind the degree 3 polynomial \\(P_3(x)\\):\n\nUse either Newton’s divided differences or Lagrange interpolation to find the polynomial of degree 3 that passes through the given points. Let’s call this polynomial \\(P_3(x)\\).\n\nAdd a higher-degree term:\n\nTo turn this degree 3 polynomial into a degree 5 polynomial, we add a term that evaluates to zero at the given points:\n\n\n\\[P_5(x) = P_3(x) + c(x - 1)(x - 2)(x - 3)(x - 4)\\]\n\nThe new term \\((x - 1)(x - 2)(x - 3)(x - 4)\\) is zero at \\(x = 1, 2, 3, 4\\), so it won’t affect the interpolation at those points. By multiplying this term by a constant \\(c\\), we ensure that the degree of the polynomial is elevated to 5, but the polynomial still interpolates the original points.\n\n\n\nFinal Degree 5 Polynomial\nThus, the degree 5 polynomial is given by:\n\\[P_5(x) = P_3(x) + c(x - 1)(x - 2)(x - 3)(x - 4)\\]\n\n\\(P_3(x)\\) is the degree 3 polynomial found using standard interpolation methods.\n\\(c\\) is an arbitrary constant that determines the shape of the polynomial outside the interpolation points.\n\n\n\nExample\nLet’s assume the degree 3 polynomial \\(P_3(x)\\) through the points \\((1, 1)\\), \\((2, 3)\\), \\((3, 3)\\), \\((4, 4)\\) is:\n\\[P_3(x) = 1 + 2(x - 1) + 3(x - 1)(x - 2)\\]\nThen the degree 5 polynomial becomes:\n\\[P_5(x) = P_3(x) + c(x - 1)(x - 2)(x - 3)(x - 4)\\]\n\n\nDoes the Value of \\(c\\) Matter?\nNo, the value of \\(c\\) does not affect the interpolation at the given points. Since the additional term evaluates to 0 at \\(x = 1, 2, 3, 4\\), the polynomial will still pass through the points, regardless of \\(c\\).\nHowever, changing \\(c\\) affects the behavior of the polynomial outside the interpolation points. For different values of \\(c\\), the polynomial will look different beyond the four points, but it will still pass through \\((1, 1)\\), $(2, 3) $, $ (3, 3) $, and $ (4, 4)$."
  },
  {
    "objectID": "homework/math411-suggested-homework.html",
    "href": "homework/math411-suggested-homework.html",
    "title": "MATH411 Suggested Homework - Fall 2024",
    "section": "",
    "text": "Week 1\n\n(C0-P1) Read/work through the Getting Started with Python notebook (see Modules &gt; Homework &gt; Getting_Started_with_Python.ipynb). Then complete the following exercises in a separate notebook or .py file:\n\nWhat is the difference between the outputs generated by the following two lines of code?\n\nnp.array([i for i in range(10)])\nnp.linspace(0, 9, 10, endpoint=True)\n\nUse both np.linspace() and np.arange() to create an array containing floating point numbers starting at 1.0, ending at 4.0, equally spaced with separation 0.2. In other words, the array should contain 1.0, 1.2, 1.4, …, 3.8, 4.0.\nCreate an array consisting of the floats 1.0, 2.0, 3.0, 4.0, and 5.0. Create a second array containing the square root of each of these numbers. Then, use a for loop to compute the sum of the squared differences between the two arrays:\n\n\\[\n\\sum_{i=1}^n \\left(x_i - \\sqrt{x_i}\\right)^2\n\\]\nExtra Challenge: Can you do this without a loop?\n\nStarting with \\(x = 1\\), use a while loop to divide by 2 until \\(x &lt; 10^{-4}\\). Display (print) the list 1.0, 0.5, 0.25, …, and report the number of divisions by 2 needed such that the \\((k-1)\\)th division produces \\(x &gt; 10^{-4}\\) and the \\(k\\)th division produces \\(x &lt; 10^{-4}\\).\nWrite code to create a function to compute \\(f(x) = e^{-x} \\cos x\\), where \\(x\\) is a vector (array) of one or more numbers. Then evaluate \\(f(x)\\) at the points 0, 0.1, 0.2, …, 1.0.\nWrite code to plot the function \\(h(x) = e^{x} \\cos^2 x - 2\\) on the interval -0.5 to 5.5 and visually estimate the roots of \\(h(x)\\) on that interval.\n\n(C1-P1) Exercise 1.1.4ab\n(C1-P2) Exercise 1.2.2\n(C1-P3) Computer Problem 1.2.2ab. For each equation, find an initial point \\(x_0\\) and a function \\(g(x)\\) such that the fixed-point iteration \\(x_{k+1} = g(x_k)\\) converges to \\(x\\), where \\(g(x) = x\\). If this is not possible, explain why.\n(C1-P4) Exercise 1.2.14\n(C1-P5) Exercise 1.4.1\n(C1-P6) Exercise 1.4.3\n\n\nWeek 2\n\n(C1-P7) Exercise 1.4.6\n(C1-P8) Exercise 1.4.8\n(C1-P9) Computer Problem 1.4.7\n(C1-P10) Exercise 1.5.1\n(C1-P11) Use Python to compare results obtained using the Bisection Method, Newton’s Method, and the Secant Method to solve the equation \\(\\ln x + x^2 = 3\\). Note that Python code for these methods is available on I-Learn.\n\nSolve the problem using each of the three methods. Report starting values and the number of iterations required to obtain 6 correct decimal places of accuracy. Hint: a graph of the function may help with starting values.\nOn the same axes, plot \\(\\log(\\epsilon_{i+1})\\) vs. \\(\\log(\\epsilon_i)\\) for the three methods. Explain your plot. How is it related to the rate or order of convergence? Use the errors to determine if your results are consistent with theory. How would you compute the error if you didn’t have an exact value for the root?\n\n(C3-P1) Exercise 3.1.1ac\n(C3-P2) Exercise 3.1.2ac\n(C3-P3) Exercise 3.1.6\n\n\nWeek 3\n\n(C0-P2) Create a Python function that takes as input three points (six scalars, three pairs, or perhaps a 6-element numpy array—choose a method that makes sense to you) and uses the matplotlib package to create a figure window and then render a triangle with small open circles at each of the points and straight lines between each pair of circles. Include code to save your figure to a .png or .jpg file. Validate your function with the points (1, 2), (2, 1), and (2, 3).\n(C3-P4) Exercise 3.2.2\n(C3-P5) Exercise 3.2.5\n(C3-P6) Exercise 3.2.6 Note: the two additional points in the next-to-last sentence should be \\((x_7, y_7) = (0.1, f(0.1))\\) and \\((x_8, y_8) = (0.5, f(0.5))\\).\n(C3-P7) Computer Problem 3.1.3. To demonstrate that your function works, interpolate \\(\\sin(x)\\) on the interval \\([-\\pi, \\pi]\\) using nodes \\(-\\pi, -\\frac{\\pi}{2}, 0, \\frac{\\pi}{2}, \\pi\\). Plot your interpolating polynomial. Plot \\(\\sin(x)\\) on the same graph, and use the numpy functions polyfit and polyval to plot an interpolating polynomial from Python on the same graph. Use a legend to make clear which curve is yours and which one came from Python. Hint: the code on p. 146 should help. Python versions of newtdd and nest (p. 3) are available in Canvas.\n(C3-P8) Exercise 3.3.2ac\n(C3-P9) Exercise 3.3.2ac\n(C3-P10) Exercise 3.3.3\n\n\nWeek 4\n\n(C5-P1) Exercise 5.2.1ab\n(C5-P2) Exercise 5.2.2ab\n(C5-P3) Exercise 5.2.3ab\n(C5-P4) Exercise 5.2.10\n(C5-P5) Exercise 5.2.12\n(C5-P6) Computer Problem 5.2.1ac\n(C5-P7) Computer Problem 5.2.2de\n(C5-P8) Computer Problem 5.2.9bf\n\n\nWeek 5\n\n(C5-P9) Exercise 5.5.1ab\n(C5-P10) Exercise 5.5.4cd\n(C5-P11) Computer Problem 5.4.1acd\n(C5-P12) Computer Problem 5.4.2\n(C5-P13) Computer Problem 5.4.3acd\n(C5-P14) Exercise 5.5.5cd\n(C5-P15) Exercise 5.5.7\n\n\nWeek 6\n\n(C2-P1) Exercise 2.1.2ac\n(C2-P2) Computer Problem 2.1.2ac\n(C2-P3) Exercise 2.2.1ab\n(C2-P4) Exercise 2.2.2ab\n\n\nWeek 7\n\n(C2-P5) Exercise 2.2.4\n(C2-P6) Computer Problem 2.2.1ab\n(C2-P7) Exercise 2.4.1ab\n(C2-P8) Exercise 2.4.2ab\n(C2-P9) Exercise 2.4.4a\n(C2-P10) Exercise 2.4.6\n\n\nWeek 8\n\n(C2-P11) Exercise 2.5.2ab\n(C2-P12) Computer Problem 2.5.2 (solve using both Jacobi and Gauss-Seidel, compare results)\n(C4-P1) Exercise 4.1.2\n(C4-P2) Computer Problem 4.1.5 (also use a quadratic fit and compare)\n(C4-P3) Exercise 4.3.2\n\n\nWeek 9\n\n(C4-P4) Exercise 4.3.4 (use the matrix from Exercise 4.3.1d)\n(C4-P5) Exercise 4.3.7 (you can use your QR factorizations from Exercise 4.3.2)\n(C4-P6) Computer Problem 4.3.4 Additional instructions: Write a classical Gram-Schmidt code only. Use the matrices in Exercise 4.3.2 to check your code. If you use the code I provided, you must comment it (explain what every line does).\n\n\nWeek 10\n\n(C4-P7) Exercise 4.4.2\n(C4-P8) Exercise 4.4.3\n(C4-P9) Computer Problem 4.4.2 (find a preconditioned GMRES Python code and use it)\n\n\nWeek 11\n\nNone\nExam 2 in class on Monday Week 11\nAttempt the first several Week 12 problems before Monday Week 12\n\n\nWeek 12\n\n(C10-P1) Exercise 10.1.1ad (also, find the inverse DFT of your result, compare to the original vector)\n(C10-P2) Exercise 10.1.8\n(C10-P3) Exercise 10.2.1ab\n(C10-P4) Exercise 10.2.3ab\n(C10-P5) Exercise 10.2.3 (plot data and function to show your interpolating function does interpolate the data)\n(C10-P6) Computer Problem 10.2.4\n(C10-P7) Exercise 10.3.2ab\n\n\nWeek 13\n\n(C10-P8) Computer Problem 10.3.2cd\n(C10-P9) Exercise 10.3.5 (Complete the \\(\\sum_{j=0}^{n-1} \\cos \\frac{2 \\pi j k}{n} \\cos \\frac{2 \\pi j l}{n}\\) result only)\n(C10-P10) Exercise 10.1.6"
  },
  {
    "objectID": "homework/w03/exercise3-2-2.html",
    "href": "homework/w03/exercise3-2-2.html",
    "title": "Exercise 3.2.2 (C3-P4)",
    "section": "",
    "text": "Question\n\n\nGiven the data points (1, 0), (2, \\ln 2), and (4, \\ln 4), find the degree 2 interpolating polynomial.\n\nUse the result of (a) to approximate \\ln 3.\n\nUse Theorem 3.3 to give an error bound for the approximation in part (b).\n\nCompare the actual error to your error bound.\n\n\n\nKey Concepts\n\n\nError in Polynomial Interpolation:\nThe error between the actual function f(x) and the interpolated polynomial P_{n-1}(x) is given by the following bound:\n\n|f(x) - P_{n-1}(x)| \\leq \\left| \\frac{(x - x_0)(x - x_1) \\dots (x - x_n)}{n!} f^{(n)}(c) \\right|\n\nwhere:\n\nn is the number of interpolation points.\nx_0, x_1, \\dots, x_n are the known data points.\nf^{(n)}(c) is the n-th derivative of the actual function f(x), evaluated at some point c in the interval [x_0, x_n].\n\n\n\n\nSolution\n\n\n(a) Finding the Degree 2 Interpolating Polynomial\nGiven the points (1, 0), (2, \\ln 2), and (4, \\ln 4), we apply the Lagrange interpolation formula.\n\nLagrange Basis Polynomials:\n\nL_0(x):\n\nL_0(x) = \\frac{(x - 2)(x - 4)}{(1 - 2)(1 - 4)} = \\frac{(x - 2)(x - 4)}{3}\n\nL_1(x):\n\nL_1(x) = \\frac{(x - 1)(x - 4)}{(2 - 1)(2 - 4)} = -\\frac{(x - 1)(x - 4)}{2}\n\nL_2(x): \nL_2(x) = \\frac{(x - 1)(x - 2)}{(4 - 1)(4 - 2)} = \\frac{(x - 1)(x - 2)}{6}\n\n\n\n\nPolynomial Construction:\nNow, the interpolating polynomial becomes:\n\nP(x) = y_0 L_0(x) + y_1 L_1(x) + y_2 L_2(x)\n\nSince y_0 = 0, we have:\n\nP(x) = \\ln 2 \\cdot \\left(-\\frac{(x - 1)(x - 4)}{2}\\right) + \\ln 4 \\cdot \\frac{(x - 1)(x - 2)}{6}\n\nWe know that \\ln 4 = 2 \\ln 2, so the polynomial simplifies to:\n\nP(x) = \\ln 2 \\cdot \\left(-\\frac{(x - 1)(x - 4)}{2} + \\frac{(x - 1)(x - 2)}{3}\\right)\n\n\n\n\n(b) Approximation of \\ln 3\nTo approximate \\ln 3, substitute x = 3 into the polynomial:\n\nP(3) = \\ln 2 \\cdot \\left(-\\frac{(3 - 1)(3 - 4)}{2} + \\frac{(3 - 1)(3 - 2)}{3}\\right)\n\nSimplifying:\n\nP(3) = \\ln 2 \\cdot \\left(1 + \\frac{2}{3}\\right) = \\ln 2 \\cdot \\frac{5}{3}\n\nSince \\ln 2 \\approx 0.6931, we have:\n\nP(3) \\approx \\frac{5}{3} \\cdot 0.6931 \\approx 1.1552\n\nThus, the approximation for \\ln 3 is:\n\nP(3) \\approx 1.1552\n\n\n\n(c) Error Bound using Theorem 3.3\nThe error formula for degree 2 interpolation is:\n\n|f(x) - P(x)| \\leq \\left| \\frac{(x - x_0)(x - x_1)(x - x_2)}{3!} f^{(3)}(c) \\right|\n\nwhere f(x) = \\ln(x) and f^{(3)}(x) = \\frac{2}{x^3}. The maximum of f^{(3)}(x) occurs at x = 1, giving:\n\nf^{(3)}(1) = 2\n\nSubstituting into the error formula for x = 3:\n\nE(3) = \\frac{(3 - 1)(3 - 2)(3 - 4)}{6} \\cdot 2 = \\frac{(2)(1)(-1)}{6} \\cdot 2 = -\\frac{4}{6} = -\\frac{2}{3}\n\nTherefore, the error bound is approximately -\\frac{2}{3} \\approx -0.6667.\n\n\n(d) Comparison of Actual Error and Error Bound\nThe actual value of \\ln 3 is approximately:\n\n\\ln 3 \\approx 1.0986\n\nOur approximation was P(3) \\approx 1.1552. Therefore, the actual error is:\n\n\\text{Actual error} = |1.0986 - 1.1552| \\approx 0.0566\n\nThe error bound is approximately 0.6667, which is larger than the actual error. This confirms that the actual error is well within the error bound, as expected."
  },
  {
    "objectID": "homework/w03/exercise3-3-3.html",
    "href": "homework/w03/exercise3-3-3.html",
    "title": "Exercise 3.3.3 (C3-P10)",
    "section": "",
    "text": "Assume that Chebyshev interpolation is used to find a fifth-degree interpolating polynomial Q_5(x) on the interval [-1, 1] for the function f(x) = e^x. Use the interpolation error formula to find a worst-case estimate for the error |e^x - Q_5(x)| that is valid for x throughout the interval [-1, 1]. How many digits after the decimal point will be correct when Q_5(x) is used to approximate e^x?\n\n\n\nWe need to compute the worst-case error for the interpolation of f(x) = e^x using a Chebyshev interpolating polynomial Q_5(x). We will use the interpolation error formula:\n\n|f(x) - P(x)| \\leq \\frac{M}{(n+1)!} \\cdot \\max_{x \\in [-1,1]} |(x - x_1)(x - x_2) \\cdots (x - x_n)|\n\nWhere M is an upper bound on the 6th derivative of f(x) = e^x over [-1, 1], and x_1, x_2, \\dots, x_n are the Chebyshev nodes.\n\n\n\n\nChebyshev Node Bound: For Chebyshev interpolation on the interval [-1, 1], the product (x - x_1)(x - x_2) \\cdots (x - x_n) is bounded by \\frac{1}{2^n}. For n = 5, this becomes:\n\n\\frac{1}{2^5} = \\frac{1}{32}\n\nSixth Derivative of e^x: The 6th derivative of f(x) = e^x is f^{(6)}(x) = e^x, and the maximum value of this derivative on the interval [-1, 1] is at x = 1, where f^{(6)}(1) = e \\approx 2.718.\nFactorial Term: The term 6! = 720.\nError Bound Formula: Now, we plug these values into the error bound formula:\n\n|e^x - Q_5(x)| \\leq \\frac{e}{6!} \\cdot \\frac{1}{32}\n\nSubstituting e \\approx 2.718, we get:\n\n|e^x - Q_5(x)| \\leq \\frac{2.718}{720 \\times 32} \\approx \\frac{2.718}{23,040} \\approx 0.000118\n\nThis is the worst-case error estimate for the approximation of e^x on the interval [-1, 1].\nCorrect Decimal Places: Since the error bound is approximately 0.000118, this means we can expect approximately 3 correct digits after the decimal point. The error affects the fourth decimal place, but the first three digits are expected to be correct.\nTherefore, the approximation Q_5(x) will be accurate to 3 digits after the decimal point when approximating e^x on the interval [-1, 1]."
  },
  {
    "objectID": "homework/w03/exercise3-3-3.html#question",
    "href": "homework/w03/exercise3-3-3.html#question",
    "title": "Exercise 3.3.3 (C3-P10)",
    "section": "",
    "text": "Assume that Chebyshev interpolation is used to find a fifth-degree interpolating polynomial Q_5(x) on the interval [-1, 1] for the function f(x) = e^x. Use the interpolation error formula to find a worst-case estimate for the error |e^x - Q_5(x)| that is valid for x throughout the interval [-1, 1]. How many digits after the decimal point will be correct when Q_5(x) is used to approximate e^x?\n\n\n\nWe need to compute the worst-case error for the interpolation of f(x) = e^x using a Chebyshev interpolating polynomial Q_5(x). We will use the interpolation error formula:\n\n|f(x) - P(x)| \\leq \\frac{M}{(n+1)!} \\cdot \\max_{x \\in [-1,1]} |(x - x_1)(x - x_2) \\cdots (x - x_n)|\n\nWhere M is an upper bound on the 6th derivative of f(x) = e^x over [-1, 1], and x_1, x_2, \\dots, x_n are the Chebyshev nodes.\n\n\n\n\nChebyshev Node Bound: For Chebyshev interpolation on the interval [-1, 1], the product (x - x_1)(x - x_2) \\cdots (x - x_n) is bounded by \\frac{1}{2^n}. For n = 5, this becomes:\n\n\\frac{1}{2^5} = \\frac{1}{32}\n\nSixth Derivative of e^x: The 6th derivative of f(x) = e^x is f^{(6)}(x) = e^x, and the maximum value of this derivative on the interval [-1, 1] is at x = 1, where f^{(6)}(1) = e \\approx 2.718.\nFactorial Term: The term 6! = 720.\nError Bound Formula: Now, we plug these values into the error bound formula:\n\n|e^x - Q_5(x)| \\leq \\frac{e}{6!} \\cdot \\frac{1}{32}\n\nSubstituting e \\approx 2.718, we get:\n\n|e^x - Q_5(x)| \\leq \\frac{2.718}{720 \\times 32} \\approx \\frac{2.718}{23,040} \\approx 0.000118\n\nThis is the worst-case error estimate for the approximation of e^x on the interval [-1, 1].\nCorrect Decimal Places: Since the error bound is approximately 0.000118, this means we can expect approximately 3 correct digits after the decimal point. The error affects the fourth decimal place, but the first three digits are expected to be correct.\nTherefore, the approximation Q_5(x) will be accurate to 3 digits after the decimal point when approximating e^x on the interval [-1, 1]."
  },
  {
    "objectID": "homework/w07/exercise2-4-6.html",
    "href": "homework/w07/exercise2-4-6.html",
    "title": "Exercise 2.4.6 (C2-P10)",
    "section": "",
    "text": "(a) Write down the \\(4 \\times 4\\) matrix \\(P\\) such that multiplying a matrix on the left by \\(P\\) causes the second and fourth rows of the matrix to be exchanged.\n(b) What is the effect of multiplying on the right by \\(P\\)? Demonstrate with an example."
  },
  {
    "objectID": "homework/w07/exercise2-4-6.html#a-constructing-the-permutation-matrix-p",
    "href": "homework/w07/exercise2-4-6.html#a-constructing-the-permutation-matrix-p",
    "title": "Exercise 2.4.6 (C2-P10)",
    "section": "(a) Constructing the Permutation Matrix \\(P\\)",
    "text": "(a) Constructing the Permutation Matrix \\(P\\)\nTo create a permutation matrix \\(P\\) that exchanges the second and fourth rows when multiplied on the left, start with the \\(4 \\times 4\\) identity matrix \\(I_4\\) and swap its second and fourth rows.\nIdentity Matrix \\(I_4\\):\n\\[\nI_4 = \\begin{pmatrix}\n1 & 0 & 0 & 0 \\\\\n0 & 1 & 0 & 0 \\\\\n0 & 0 & 1 & 0 \\\\\n0 & 0 & 0 & 1 \\\\\n\\end{pmatrix}\n\\]\nPermutation Matrix \\(P\\) (after swapping rows 2 and 4):\n\\[\nP = \\begin{pmatrix}\n1 & 0 & 0 & 0 \\\\\n0 & 0 & 0 & 1 \\\\\n0 & 0 & 1 & 0 \\\\\n0 & 1 & 0 & 0 \\\\\n\\end{pmatrix}\n\\]\nWhen \\(P\\) multiplies any \\(4 \\times n\\) matrix \\(A\\) on the left (\\(PA\\)), it exchanges the second and fourth rows of \\(A\\)."
  },
  {
    "objectID": "homework/w07/exercise2-4-6.html#b-effect-of-multiplying-on-the-right-by-p",
    "href": "homework/w07/exercise2-4-6.html#b-effect-of-multiplying-on-the-right-by-p",
    "title": "Exercise 2.4.6 (C2-P10)",
    "section": "(b) Effect of Multiplying on the Right by \\(P\\)",
    "text": "(b) Effect of Multiplying on the Right by \\(P\\)\nMultiplying a matrix on the right by \\(P\\) rearranges its columns (instead of rows) according to the pattern defined by \\(P\\). In this case, it specifically swaps the matrix’s second and fourth columns.\nDemonstration with an Example:\nLet’s consider a \\(4 \\times 4\\) matrix \\(A\\):\n\\[\nA = \\begin{pmatrix}\na_{11} & a_{12} & a_{13} & a_{14} \\\\\na_{21} & a_{22} & a_{23} & a_{24} \\\\\na_{31} & a_{32} & a_{33} & a_{34} \\\\\na_{41} & a_{42} & a_{43} & a_{44} \\\\\n\\end{pmatrix}\n\\]\nCompute \\(AP\\):\n\\[\nAP = A \\times P = A \\times \\begin{pmatrix}\n1 & 0 & 0 & 0 \\\\\n0 & 0 & 0 & 1 \\\\\n0 & 0 & 1 & 0 \\\\\n0 & 1 & 0 & 0 \\\\\n\\end{pmatrix}\n\\]\nResulting Matrix \\(AP\\):\n\\[\nAP = \\begin{pmatrix}\na_{11} & a_{14} & a_{13} & a_{12} \\\\\na_{21} & a_{24} & a_{23} & a_{22} \\\\\na_{31} & a_{34} & a_{33} & a_{32} \\\\\na_{41} & a_{44} & a_{43} & a_{42} \\\\\n\\end{pmatrix}\n\\]\nNumerical Example:\n\\[\nA = \\begin{pmatrix}\n1 & 2 & 3 & 4 \\\\\n5 & 6 & 7 & 8 \\\\\n9 & 10 & 11 & 12 \\\\\n13 & 14 & 15 & 16 \\\\\n\\end{pmatrix}\n\\]\nCompute \\(AP\\):\n\\[\nAP = A \\times \\begin{pmatrix}\n1 & 0 & 0 & 0 \\\\\n0 & 0 & 0 & 1 \\\\\n0 & 0 & 1 & 0 \\\\\n0 & 1 & 0 & 0 \\\\\n\\end{pmatrix} = \\begin{pmatrix}\n1 & 4 & 3 & 2 \\\\\n5 & 8 & 7 & 6 \\\\\n9 & 12 & 11 & 10 \\\\\n13 & 16 & 15 & 14 \\\\\n\\end{pmatrix}\n\\]\nFinal Answer\n(a) The \\(4 \\times 4\\) permutation matrix \\(P\\) that exchanges the second and fourth rows when multiplied on the left is:\n\\[\nP = \\begin{pmatrix}\n1 & 0 & 0 & 0 \\\\\n0 & 0 & 0 & 1 \\\\\n0 & 0 & 1 & 0 \\\\\n0 & 1 & 0 & 0 \\\\\n\\end{pmatrix}\n\\]\n(b) Multiplying on the right by \\(P\\) exchanges the second and fourth columns of a matrix. For example, for the matrix:\n\\[\nA = \\begin{pmatrix}\n1 & 2 & 3 & 4 \\\\\n5 & 6 & 7 & 8 \\\\\n9 & 10 & 11 & 12 \\\\\n13 & 14 & 15 & 16 \\\\\n\\end{pmatrix}\n\\]\nMultiplying on the right by \\(P\\) yields:\n\\[\nAP = \\begin{pmatrix}\n1 & 4 & 3 & 2 \\\\\n5 & 8 & 7 & 6 \\\\\n9 & 12 & 11 & 10 \\\\\n13 & 16 & 15 & 14 \\\\\n\\end{pmatrix}\n\\]\nwhich is \\(A\\) with its second and fourth columns exchanged."
  },
  {
    "objectID": "notes/w01/bisection-method.html",
    "href": "notes/w01/bisection-method.html",
    "title": "Bisection Method",
    "section": "",
    "text": "Bisection Method is one of the simplest and most reliable numerical methods for finding a root of a continuous function \\(f(x) = 0\\) over a closed interval \\([a, b]\\). The method works by repeatedly bisecting the interval and then selecting the subinterval in which the function changes sign, ensuring that a root lies within that subinterval."
  },
  {
    "objectID": "notes/w01/bisection-method.html#the-bisection-method-formula",
    "href": "notes/w01/bisection-method.html#the-bisection-method-formula",
    "title": "Bisection Method",
    "section": "The Bisection Method Formula",
    "text": "The Bisection Method Formula\nThe Bisection Method requires that the function \\(f(x)\\) be continuous over the interval \\([a, b]\\), and that the function has opposite signs at the endpoints \\(a\\) and \\(b\\), i.e., \\(f(a) \\cdot f(b) &lt; 0\\). This guarantees that there is at least one root in the interval by the Intermediate Value Theorem.\nThe basic idea of the method is to repeatedly bisect the interval and check the sign of \\(f(x)\\) at the midpoint to determine the subinterval containing the root.\n\nAlgorithm\n\nInitial Guess: Choose an interval \\([a_0, b_0]\\) such that \\(f(a_0) \\cdot f(b_0) &lt; 0\\).\nMidpoint Calculation: Compute the midpoint \\(c_k = \\frac{a_k + b_k}{2}\\) of the interval \\([a_k, b_k]\\).\nCheck the Sign: Evaluate \\(f(c_k)\\).\n\nIf \\(f(c_k) = 0\\), then \\(c_k\\) is the root.\nIf \\(f(a_k) \\cdot f(c_k) &lt; 0\\), set \\(b_{k+1} = c_k\\), and the root lies in \\([a_k, c_k]\\).\nIf \\(f(c_k) \\cdot f(b_k) &lt; 0\\), set \\(a_{k+1} = c_k\\), and the root lies in \\([c_k, b_k]\\).\n\nRepeat: Continue bisecting the interval until the length of the interval is smaller than a specified tolerance \\(\\epsilon\\), or until \\(|f(c_k)| &lt; \\epsilon\\).\n\nThe approximate root will be:\n\\[\nx^* = \\frac{a_k + b_k}{2}\n\\]\n\n\nConvergence\nThe Bisection Method converges linearly. The length of the interval halves at each iteration, ensuring that the method always converges to a solution (if one exists) within the interval.\nThe number of iterations \\(n\\) required to achieve an accuracy of \\(\\epsilon\\) can be estimated by:\n\\[\nn \\geq \\frac{\\log \\left( \\frac{b_0 - a_0}{\\epsilon} \\right)}{\\log 2}\n\\]\n\n\nExample\nLet’s solve the equation \\(f(x) = x^3 - x - 2 = 0\\) in the interval \\([1, 2]\\).\n\nInitial Interval:\n\\(f(1) = 1^3 - 1 - 2 = -2\\)\n\\(f(2) = 2^3 - 2 - 2 = 4\\)\nSince \\(f(1) \\cdot f(2) &lt; 0\\), there is a root in \\([1, 2]\\).\nFirst Iteration:\nMidpoint: \\(c_1 = \\frac{1 + 2}{2} = 1.5\\)\n\\(f(1.5) = 1.5^3 - 1.5 - 2 = -0.125\\)\nSince \\(f(1) \\cdot f(1.5) &lt; 0\\), the root lies in \\([1, 1.5]\\).\nSecond Iteration:\nMidpoint: \\(c_2 = \\frac{1 + 1.5}{2} = 1.25\\)\n\\(f(1.25) = 1.25^3 - 1.25 - 2 = -1.796875\\)\nSince \\(f(1) \\cdot f(1.25) &lt; 0\\), the root lies in \\([1, 1.25]\\).\nFurther Iterations:\nRepeat the process until the interval width is smaller than the desired tolerance \\(\\epsilon\\).\n\n\n\nGeneral Properties of the Bisection Method\n\nGuaranteed Convergence: The method is guaranteed to converge to a root if \\(f(a) \\cdot f(b) &lt; 0\\) and \\(f(x)\\) is continuous on \\([a, b]\\).\nRate of Convergence: The Bisection Method has linear convergence, meaning the error decreases by a constant factor with each iteration. This makes the method slower than other methods like Newton’s Method, but much more reliable.\nRobustness: The method is very robust as it does not require the derivative of the function and is insensitive to the initial guesses, provided the condition \\(f(a) \\cdot f(b) &lt; 0\\) holds.\n\n\n\nApplications of the Bisection Method\n\nRoot Finding: The Bisection Method is used in various fields, including physics, engineering, and mathematics, to find roots of non-linear equations.\nModeling and Simulation: It is used when precise solutions are needed and the function is known to be continuous over the interval.\nInitial Root Estimates: The Bisection Method is often used to find a good initial approximation for more efficient methods like Newton’s Method or the Secant Method.\n\n\n\nAdvantages of the Bisection Method\n\nGuaranteed Convergence: The method always converges if the initial interval contains a root.\nNo Derivatives Needed: Unlike Newton’s Method, the Bisection Method does not require the computation of derivatives.\nSimplicity: The method is easy to understand and implement.\n\n\n\nLimitations of the Bisection Method\n\nSlow Convergence: The method converges linearly, which makes it slower compared to methods like Newton’s Method, which has quadratic convergence.\nOnly One Root: The Bisection Method only finds one root in the interval. If multiple roots exist, it cannot find them all without running the method on different intervals.\nInitial Interval Requirement: The method requires an initial interval \\([a, b]\\) where the function changes sign, which may not always be easy to determine.\n\n\n\nConclusion\nThe Bisection Method is a reliable and simple method for finding roots of continuous functions, especially when no derivative information is available. While slower than other root-finding algorithms, its guaranteed convergence and robustness make it a valuable tool in numerical analysis."
  },
  {
    "objectID": "notes/w01/newtons-method.html",
    "href": "notes/w01/newtons-method.html",
    "title": "Newton’s Method",
    "section": "",
    "text": "Newton’s Method, also known as the Newton-Raphson Method, is a widely used numerical method for finding successively better approximations to the roots (or zeros) of a real-valued function. It is particularly efficient when the initial guess is close to the actual root and when the function is well-behaved (smooth and differentiable)."
  },
  {
    "objectID": "notes/w01/newtons-method.html#the-newtons-method-formula",
    "href": "notes/w01/newtons-method.html#the-newtons-method-formula",
    "title": "Newton’s Method",
    "section": "The Newton’s Method Formula",
    "text": "The Newton’s Method Formula\nNewton’s Method is based on using the tangent line at an approximation of the root to generate a better approximation. The formula for generating the next approximation \\(x_{k+1}\\) from the current approximation \\(x_k\\) is given by:\n\\[\nx_{k+1} = x_k - \\frac{f(x_k)}{f'(x_k)}\n\\]\nwhere:\n\n\\(f(x)\\) is the function whose root we are trying to find.\n\\(f'(x)\\) is the derivative of \\(f(x)\\).\n\\(x_k\\) is the current approximation, and \\(x_{k+1}\\) is the next approximation.\n\n\nGeometrical Interpretation\nNewton’s Method can be interpreted geometrically: given an approximation \\(x_k\\), the tangent line to the curve \\(y = f(x)\\) at the point $ (x*k, f(x_k)) $ is used to estimate where the curve crosses the x-axis, which provides the next approximation \\(x*{k+1}\\).\n\n\nConvergence Criteria\nNewton’s Method converges quadratically under certain conditions, which means that the number of correct digits roughly doubles with each iteration. However, this fast convergence occurs only if:\n\nThe function \\(f(x)\\) is continuous and differentiable in the vicinity of the root.\nThe derivative \\(f'(x)\\) is non-zero at the root.\nThe initial guess is sufficiently close to the actual root.\n\nIf the initial guess is too far from the root, Newton’s Method may fail to converge or may converge very slowly.\n\n\nStep-by-Step Procedure\n\nInitial Guess: Choose an initial approximation \\(x_0\\).\nIteration Formula: Compute successive approximations using the formula:\n\n\\[\nx_{k+1} = x_k - \\frac{f(x_k)}{f'(x_k)}\n\\]\n\nRepeat: Continue iterating until \\(|x_{k+1} - x_k| &lt; \\epsilon\\), where \\(\\epsilon\\) is a small tolerance value, or until \\(|f(x_k)| &lt; \\epsilon\\).\n\n\n\nExample\nLet’s solve the equation \\(f(x) = x^2 - 2 = 0\\) using Newton’s Method, which has a root at \\(x = \\sqrt{2}\\).\n\nFunction and Derivative:\n\\[\nf(x) = x^2 - 2\n\\]\n\\[\nf'(x) = 2x\n\\]\nInitial Guess: Let \\(x_0 = 1.5\\).\nFirst Iteration:\n\\[\nx_1 = x_0 - \\frac{f(x_0)}{f'(x_0)} = 1.5 - \\frac{1.5^2 - 2}{2(1.5)} = 1.4167\n\\]\nSecond Iteration:\n\\[\nx_2 = x_1 - \\frac{f(x_1)}{f'(x_1)} = 1.4167 - \\frac{1.4167^2 - 2}{2(1.4167)} = 1.4142\n\\]\nFurther Iterations: Repeat until the difference between successive approximations is less than a specified tolerance (e.g., \\(\\epsilon = 10^{-5}\\)).\n\nIn this case, after just a few iterations, we have a highly accurate approximation of \\(\\sqrt{2}\\).\n\n\nGeneral Properties of Newton’s Method\n\nQuadratic Convergence: When close to the root, Newton’s Method converges quadratically, meaning that the error decreases roughly as the square of the previous error.\nRequires Derivatives: Unlike the Bisection Method, Newton’s Method requires that the derivative \\(f'(x)\\) be known and be non-zero at the root.\nSensitive to Initial Guess: The method is sensitive to the initial guess, and poor choices of \\(x_0\\) can lead to divergence or slow convergence.\n\n\n\nApplications of Newton’s Method\n\nRoot Finding: Newton’s Method is widely used to find roots of non-linear equations in mathematics, physics, engineering, and economics.\nOptimization: Newton’s Method is the basis of Newton’s optimization method, which is used to find local minima or maxima of differentiable functions by solving \\(f'(x) = 0\\).\nEngineering and Modeling: It is used to solve non-linear models and systems, especially in fields like structural engineering, fluid dynamics, and electrical circuit analysis.\n\n\n\nAdvantages of Newton’s Method\n\nFast Convergence: When it converges, Newton’s Method is extremely fast due to its quadratic convergence rate.\nSimple Iterative Formula: The iteration formula is straightforward and easy to implement.\nFew Iterations: For well-behaved functions and good initial guesses, only a few iterations are required to obtain a highly accurate result.\n\n\n\nLimitations of Newton’s Method\n\nRequires Derivatives: The method requires that \\(f(x)\\) is differentiable, and that the derivative \\(f'(x)\\) can be computed analytically or numerically.\nRisk of Divergence: If the initial guess is too far from the root or if \\(f'(x)\\) is zero or near zero, the method may diverge or fail to converge.\nSlow or No Convergence: For functions with inflection points or flat regions near the root, the method may converge very slowly or not at all. In these cases, alternative methods like the Secant Method or Bisection Method may be better suited.\n\n\n\nConclusion\nNewton’s Method is a powerful and efficient tool for finding roots of equations, especially when the initial guess is close to the solution. While it requires the calculation of derivatives, its fast convergence makes it a preferred method when applicable. However, care must be taken with the choice of initial guess to avoid issues with divergence or slow convergence."
  },
  {
    "objectID": "notes/w02/lagrange-interpolation.html",
    "href": "notes/w02/lagrange-interpolation.html",
    "title": "Lagrange Interpolation",
    "section": "",
    "text": "Lagrange Interpolation is a method of constructing a polynomial that passes through a given set of points. It is particularly useful when you have a small number of data points and want to determine the polynomial function that exactly fits those points."
  },
  {
    "objectID": "notes/w02/lagrange-interpolation.html#the-lagrange-interpolating-polynomial",
    "href": "notes/w02/lagrange-interpolation.html#the-lagrange-interpolating-polynomial",
    "title": "Lagrange Interpolation",
    "section": "The Lagrange Interpolating Polynomial",
    "text": "The Lagrange Interpolating Polynomial\nGiven \\(n\\) distinct data points \\((x_1, y_1), (x_2, y_2), ..., (x_n, y_n)\\), the Lagrange interpolating polynomial is the polynomial \\(P(x)\\) of degree at most \\(n-1\\) that passes through all the points, meaning:\n\\[\nP(x_i) = y_i \\quad \\text{for each} \\ i = 1, 2, ..., n\n\\]\nThe Lagrange form of the polynomial is given by:\n\\[\nP(x) = \\sum_{i=1}^{n} y_i L_i(x)\n\\]\nwhere \\(L_i(x)\\) are the Lagrange basis polynomials, defined as:\n\\[\nL_i(x) = \\prod_{j=1, j \\neq i}^{n} \\frac{x - x_j}{x_i - x_j}\n\\]\nHere, the product is taken over all \\(j \\neq i\\), ensuring that \\(L_i(x_j) = 0\\) for \\(j \\neq i\\) and \\(L_i(x_i) = 1\\). This ensures that \\(P(x_i) = y_i\\) for each \\(i\\).\n\nStep-by-Step Calculation\nSuppose we are given a set of three points: \\((x_1, y_1)\\), \\((x_2, y_2)\\), \\((x_3, y_3)\\). The Lagrange interpolating polynomial is:\n\\[\nP(x) = y_1 L_1(x) + y_2 L_2(x) + y_3 L_3(x)\n\\]\nwhere the Lagrange basis polynomials are:\n\\[\nL_1(x) = \\frac{(x - x_2)(x - x_3)}{(x_1 - x_2)(x_1 - x_3)}\n\\]\n\\[\nL_2(x) = \\frac{(x - x_1)(x - x_3)}{(x_2 - x_1)(x_2 - x_3)}\n\\]\n\\[\nL_3(x) = \\frac{(x - x_1)(x - x_2)}{(x_3 - x_1)(x_3 - x_2)}\n\\]\nBy evaluating these expressions and plugging in the values of \\(y_1\\), \\(y_2\\), and \\(y_3\\), we obtain the polynomial \\(P(x)\\) that passes through all the given points.\n\n\nExample\nLet’s go through an example where we are given three points: \\((1, 2)\\), \\((2, 3)\\), and \\((3, 5)\\).\n\nPoints:\n\\((x_1, y_1) = (1, 2)\\)\n\\((x_2, y_2) = (2, 3)\\)\n\\((x_3, y_3) = (3, 5)\\)\nLagrange basis polynomials:\n\n\\[\nL_1(x) = \\frac{(x - 2)(x - 3)}{(1 - 2)(1 - 3)} = \\frac{(x - 2)(x - 3)}{2}\n\\]\n\\[\nL_2(x) = \\frac{(x - 1)(x - 3)}{(2 - 1)(2 - 3)} = \\frac{(x - 1)(x - 3)}{-1}\n\\]\n\\[\nL_3(x) = \\frac{(x - 1)(x - 2)}{(3 - 1)(3 - 2)} = \\frac{(x - 1)(x - 2)}{2}\n\\]\n\nLagrange interpolating polynomial:\n\n\\[\nP(x) = 2 \\cdot L_1(x) + 3 \\cdot L_2(x) + 5 \\cdot L_3(x)\n\\]\nSubstituting the values for \\(L_1(x)\\), \\(L_2(x)\\), and \\(L_3(x)\\):\n\\[\nP(x) = 2 \\cdot \\frac{(x - 2)(x - 3)}{2} + 3 \\cdot \\frac{(x - 1)(x - 3)}{-1} + 5 \\cdot \\frac{(x - 1)(x - 2)}{2}\n\\]\nSimplifying this expression will give you the final polynomial \\(P(x)\\) that passes through all three points.\n\n\nGeneral Properties of Lagrange Interpolation\n\nUniqueness: There is exactly one polynomial of degree \\(n-1\\) that interpolates \\(n\\) points. This is guaranteed by the fundamental theorem of algebra, which states that a polynomial of degree \\(n-1\\) is uniquely determined by \\(n\\) distinct points.\nEfficiency: Lagrange interpolation is not the most computationally efficient method for large datasets, because each term depends on all the data points, making the calculation costly for large \\(n\\). Methods like Newton’s divided differences are generally preferred for interpolation with larger datasets.\nAccuracy: Interpolation works well if the points are well-distributed and the function is smooth. However, for unevenly spaced points or functions with high curvature, the interpolation polynomial may oscillate significantly, a phenomenon known as Runge’s phenomenon.\n\n\n\nApplications of Lagrange Interpolation\n\nCurve Fitting: Lagrange interpolation can be used to construct a polynomial that exactly fits a given set of data points.\nNumerical Integration: The interpolating polynomial can be used to approximate integrals through methods such as Newton-Cotes formulas.\nGraphics and Animation: In computer graphics, Lagrange interpolation is used to smoothly interpolate between keyframes in animations.\nSignal Processing: It is used in digital signal processing for reconstructing missing samples from a set of known data points.\n\n\n\nDrawbacks\n\nRunge’s Phenomenon: Lagrange interpolation can lead to significant oscillation, especially when interpolating over large intervals with a high degree polynomial.\nNot Easily Updateable: If a new point is added, the entire Lagrange polynomial must be recalculated. In contrast, methods like Newton’s divided differences allow for easier updates when new points are added.\n\n\n\nConclusion\nLagrange interpolation is a powerful tool for constructing polynomials that pass through a set of points, but it can suffer from inefficiencies and oscillations for large datasets. It’s important to understand its benefits and limitations to use it effectively in applications."
  },
  {
    "objectID": "notes/w03/chebyshev-interpolation.html",
    "href": "notes/w03/chebyshev-interpolation.html",
    "title": "Chebyshev Interpolation",
    "section": "",
    "text": "Chebyshev Interpolation is a powerful technique in numerical analysis used to approximate functions with polynomials, particularly minimizing errors and avoiding issues like Runge’s phenomenon. This note provides an overview of Chebyshev Interpolation, including its definition, properties, advantages, and practical implementation."
  },
  {
    "objectID": "notes/w03/chebyshev-interpolation.html#introduction",
    "href": "notes/w03/chebyshev-interpolation.html#introduction",
    "title": "Chebyshev Interpolation",
    "section": "Introduction",
    "text": "Introduction\nInterpolation involves approximating a function \\(f(x)\\) using a polynomial \\(P_n(x)\\) that passes through a set of points (nodes). While polynomial interpolation is straightforward, selecting appropriate nodes is crucial to ensure accuracy and stability. Chebyshev Interpolation leverages Chebyshev nodes to construct interpolating polynomials that minimize the maximum error across the interpolation interval."
  },
  {
    "objectID": "notes/w03/chebyshev-interpolation.html#chebyshev-polynomials",
    "href": "notes/w03/chebyshev-interpolation.html#chebyshev-polynomials",
    "title": "Chebyshev Interpolation",
    "section": "Chebyshev Polynomials",
    "text": "Chebyshev Polynomials\nChebyshev polynomials are a sequence of orthogonal polynomials that arise in various approximation and interpolation problems. They are defined recursively and have properties that make them ideal for minimizing interpolation errors.\n\nDefinition\nThe Chebyshev polynomials of the first kind, \\(T_n(x)\\), are defined by:\n\\[\nT_n(x) = \\cos(n \\arccos x), \\quad \\text{for } x \\in [-1, 1]\n\\]\n\n\nProperties\n\nOrthogonality: Chebyshev polynomials are orthogonal with respect to the weight \\(w(x) = \\frac{1}{\\sqrt{1 - x^2}}\\) on the interval \\([-1, 1]\\).\nExtremal Property: Among all polynomials of degree \\(n\\) with leading coefficient \\(2^{n-1}\\), \\(T_n(x)\\) has the smallest maximum deviation from zero on \\([-1, 1]\\).\nRoots and Extremes: The roots of \\(T_n(x)\\) are given by:\n\\[\nx_k = \\cos\\left( \\frac{2k - 1}{2n} \\pi \\right), \\quad k = 1, 2, \\dots, n\n\\]\nThe extrema (maximum and minimum points) of \\(T_n(x)\\) occur at:\n\\[\nx_k = \\cos\\left( \\frac{k}{n} \\pi \\right), \\quad k = 0, 1, \\dots, n\n\\]"
  },
  {
    "objectID": "notes/w03/chebyshev-interpolation.html#chebyshev-nodes",
    "href": "notes/w03/chebyshev-interpolation.html#chebyshev-nodes",
    "title": "Chebyshev Interpolation",
    "section": "Chebyshev Nodes",
    "text": "Chebyshev Nodes\nChebyshev nodes are specific points in the interval \\([-1, 1]\\) used as interpolation nodes to minimize the interpolation error.\n\nDefinition\nFor \\(n+1\\) Chebyshev nodes, the \\(k\\)-th node \\(x_k\\) is given by:\n\\[\nx_k = \\cos\\left( \\frac{2k + 1}{2n + 2} \\pi \\right), \\quad k = 0, 1, 2, \\dots, n\n\\]\nAlternatively, they can be expressed as:\n\\[\nx_k = \\cos\\left( \\frac{(2k + 1)\\pi}{2(n + 1)} \\right), \\quad k = 0, 1, 2, \\dots, n\n\\]\n\n\nMapping to Arbitrary Intervals\nFor an interval \\([a, b]\\), Chebyshev nodes are mapped as:\n\\[\nx_k = \\frac{a + b}{2} + \\frac{b - a}{2} \\cos\\left( \\frac{(2k + 1)\\pi}{2(n + 1)} \\right), \\quad k = 0, 1, 2, \\dots, n\n\\]\n\n\nImportance\nUsing Chebyshev nodes instead of equally spaced nodes helps in minimizing the oscillatory behavior (Runge’s phenomenon) and ensures better convergence properties of the interpolating polynomial."
  },
  {
    "objectID": "notes/w03/chebyshev-interpolation.html#interpolation-process",
    "href": "notes/w03/chebyshev-interpolation.html#interpolation-process",
    "title": "Chebyshev Interpolation",
    "section": "Interpolation Process",
    "text": "Interpolation Process\nThe Chebyshev Interpolation process involves the following steps:\n\nSelect Chebyshev Nodes: Determine the \\(n+1\\) Chebyshev nodes \\(x_0, x_1, \\dots, x_n\\) in the interval \\([-1, 1]\\).\nEvaluate the Function: Compute the function values \\(f(x_0), f(x_1), \\dots, f(x_n)\\).\nConstruct the Interpolating Polynomial: Use methods such as the Chebyshev series expansion or the barycentric interpolation formula to construct the interpolating polynomial \\(Q_n(x)\\).\nApproximate the Function: Use \\(Q_n(x)\\) to approximate \\(f(x)\\) within the interval.\n\n\nBarycentric Interpolation Formula\nOne efficient method to compute the interpolating polynomial is the barycentric interpolation formula:\n\\[\nQ_n(x) = \\frac{\\sum_{k=0}^n \\frac{w_k f(x_k)}{x - x_k}}{\\sum_{k=0}^n \\frac{w_k}{x - x_k}}\n\\]\nwhere \\(w_k\\) are the barycentric weights defined as:\n\\[\nw_k = (-1)^k \\sin\\left( \\frac{(2k + 1)\\pi}{2n + 2} \\right)\n\\]"
  },
  {
    "objectID": "notes/w03/chebyshev-interpolation.html#advantages-of-chebyshev-interpolation",
    "href": "notes/w03/chebyshev-interpolation.html#advantages-of-chebyshev-interpolation",
    "title": "Chebyshev Interpolation",
    "section": "Advantages of Chebyshev Interpolation",
    "text": "Advantages of Chebyshev Interpolation\n\nMinimized Error: Chebyshev nodes minimize the maximum error (uniform convergence) of the interpolating polynomial.\nReduced Oscillations: Avoids Runge’s phenomenon, where high-degree polynomial interpolations at equally spaced nodes exhibit large oscillations near the interval endpoints.\nEfficient Computation: The barycentric interpolation formula allows for efficient and stable computation of interpolating polynomials.\nOrthogonality: Leveraging the orthogonality of Chebyshev polynomials aids in various approximation and numerical integration techniques."
  },
  {
    "objectID": "notes/w03/chebyshev-interpolation.html#error-analysis",
    "href": "notes/w03/chebyshev-interpolation.html#error-analysis",
    "title": "Chebyshev Interpolation",
    "section": "Error Analysis",
    "text": "Error Analysis\nUnderstanding the error associated with Chebyshev Interpolation is crucial for assessing the approximation’s reliability.\n\nInterpolation Error Formula\nFor a function \\(f(x)\\) sufficiently smooth on \\([-1, 1]\\), the error of the Chebyshev interpolating polynomial \\(Q_n(x)\\) of degree \\(n\\) is given by:\n\\[\n|f(x) - Q_n(x)| \\leq \\frac{M}{(n+1)!} \\cdot \\frac{1}{2^{n+1}}\n\\]\nwhere:\n\n\\(M\\) is an upper bound on the \\((n+1)\\)-th derivative of \\(f(x)\\) on \\([-1, 1]\\).\n\n\n\nWorst-Case Error Estimate\nFor example, if \\(f(x) = e^x\\), all derivatives are \\(f^{(k)}(x) = e^x\\). On \\([-1, 1]\\), \\(e^x \\leq e\\), so \\(M = e\\).\nFor a fifth-degree polynomial (\\(n = 5\\)):\n\\[\n|e^x - Q_5(x)| \\leq \\frac{e}{6!} \\cdot \\frac{1}{2^5} = \\frac{e}{720 \\times 32} \\approx 0.000118\n\\]\n\n\nImplications\nAn error bound of approximately \\(1.18 \\times 10^{-4}\\) implies that at least three decimal digits of the approximation \\(Q_5(x)\\) are accurate across the interval \\([-1, 1]\\)."
  },
  {
    "objectID": "notes/w03/chebyshev-interpolation.html#example",
    "href": "notes/w03/chebyshev-interpolation.html#example",
    "title": "Chebyshev Interpolation",
    "section": "Example",
    "text": "Example\nProblem: Approximate \\(f(x) = e^x\\) on \\([-1, 1]\\) using a fifth-degree Chebyshev interpolating polynomial \\(Q_5(x)\\). Estimate the worst-case error and determine the number of correct decimal digits in the approximation.\nSolution:\n\nDetermine \\(M\\):\n\n\\(f^{(6)}(x) = e^x\\), so \\(M = e\\).\n\nCompute the Error Bound:\n\\[\n|e^x - Q_5(x)| \\leq \\frac{e}{6!} \\cdot \\frac{1}{2^5} = \\frac{2.71828}{720 \\times 32} \\approx 0.000118\n\\]\nInterpret the Error:\n\nThe approximation \\(Q_5(x)\\) deviates from \\(e^x\\) by less than \\(1.18 \\times 10^{-4}\\).\nAt least three decimal digits of \\(Q_5(x)\\) are accurate.\n\n\nConclusion: The fifth-degree Chebyshev interpolating polynomial \\(Q_5(x)\\) approximates \\(e^x\\) with an error less than \\(0.00012\\), ensuring at least three correct decimal digits across \\([-1, 1]\\)."
  },
  {
    "objectID": "notes/w03/chebyshev-interpolation.html#applications",
    "href": "notes/w03/chebyshev-interpolation.html#applications",
    "title": "Chebyshev Interpolation",
    "section": "Applications",
    "text": "Applications\nChebyshev Interpolation is widely used in various fields due to its robustness and efficiency:\n\nNumerical Integration: Chebyshev polynomials are used in Gaussian quadrature methods for approximating integrals.\nApproximation Theory: Provides optimal polynomial approximations for continuous functions.\nSignal Processing: Used in filter design and spectral analysis.\nComputer Graphics: Facilitates curve and surface modeling with minimal errors.\nScientific Computing: Enhances the accuracy of simulations and numerical solutions to differential equations."
  },
  {
    "objectID": "notes/w03/chebyshev-interpolation.html#conclusion",
    "href": "notes/w03/chebyshev-interpolation.html#conclusion",
    "title": "Chebyshev Interpolation",
    "section": "Conclusion",
    "text": "Conclusion\nChebyshev Interpolation offers a reliable method for polynomial approximation, leveraging Chebyshev nodes to minimize interpolation errors and avoid common pitfalls like Runge’s phenomenon. Its mathematical foundations, combined with practical computational techniques, make it an essential tool in numerical analysis and various applied disciplines."
  },
  {
    "objectID": "notes/w03/chebyshev-interpolation.html#references",
    "href": "notes/w03/chebyshev-interpolation.html#references",
    "title": "Chebyshev Interpolation",
    "section": "References",
    "text": "References\n\nTrefethen, L. N. (2000). Approximation Theory and Approximation Practice. SIAM.\nPress, W. H., Teukolsky, S. A., Vetterling, W. T., & Flannery, B. P. (2007). Numerical Recipes: The Art of Scientific Computing. Cambridge University Press.\nOlver, F. W. J., & Townsend, C. T. (2013). A First Course in Chebyshev and Fourier Spectral Methods. Cambridge University Press."
  },
  {
    "objectID": "notes/w04/trapezoidal-rule.html",
    "href": "notes/w04/trapezoidal-rule.html",
    "title": "Trapezoidal Rule",
    "section": "",
    "text": "Overview\n\nThe trapezoidal rule is a numerical method for approximating definite integrals. It works by dividing the interval of integration into sub-intervals and approximating the area under the curve as a series of trapezoids. This method is particularly useful for complex functions or when an analytical solution is not feasible.\n\n\nGeneral Formula\n\nGiven the integral:\n\\[\n\\int_a^b f(x) \\, dx\n\\]\nThe trapezoidal rule estimates the integral by approximating the region under the curve with trapezoids.\n\n\nEqual Sub-Intervals (Uniform Spacing)\n\nWhen the interval \\([a, b]\\) is divided into \\(n\\) equal sub-intervals of width:\n\\[\n\\Delta x = \\frac{b - a}{n}\n\\]\nThe composite trapezoidal rule can be expressed as:\n\\[\nT_n = \\frac{\\Delta x}{2} \\left( y_0 + 2 y_1 + 2 y_2 + \\dots + 2 y_{n-1} + y_n \\right)\n\\]\nwhere:\n\n\\(y_0 = f(a)\\) and \\(y_n = f(b)\\) are the function values at the endpoints.\n\\(y_1, y_2, \\dots, y_{n-1}\\) are the function values at the interior points, each multiplied by 2 because they are shared by two adjacent trapezoids.\n\n\nStep-by-Step Formula in Function Terms\nUsing function values at each point \\(x_i = a + i \\Delta x\\), the formula becomes:\n\\[\nT_n = \\frac{\\Delta x}{2} \\left( f(a) + 2 f(a + \\Delta x) + 2 f(a + 2 \\Delta x) + \\dots + 2 f(a + (n - 1) \\Delta x) + f(b) \\right)\n\\]\nThis formula simplifies integration when the sub-intervals are uniformly spaced.\n\n\nSummation Notation for Uniform Spacing\nAlternatively, the composite trapezoidal rule for uniform spacing can be written as:\n\\[\nT_n = \\frac{\\Delta x}{2} \\left( f(x_0) + 2 \\sum_{i=1}^{n-1} f(x_i) + f(x_n) \\right)\n\\]\nwhere:\n\n\\(x_0 = a\\), \\(x_n = b\\), and \\(x_i = a + i \\Delta x\\).\nThe summation accounts for the contributions of interior points.\n\n\n\n\nUnequal Sub-Intervals (Non-Uniform Spacing)\n\nWhen the sub-intervals are not equally spaced, the formula adjusts to account for varying widths \\(\\Delta x_i\\) between points. The non-uniform trapezoidal rule becomes:\n\\[\nT = \\sum_{i=1}^{n} \\frac{\\Delta x_i}{2} \\left( f(x_{i-1}) + f(x_i) \\right)\n\\]\nwhere:\n\nEach term computes the area of a trapezoid over the individual sub-interval \\([x_{i-1}, x_i]\\).\nThe width of each sub-interval is \\(\\Delta x_i = x_i - x_{i-1}\\), which may vary.\n\n\n\nComparison: Equal vs. Unequal Sub-Intervals\n\n\n\n\n\n\n\n\nProperty\nEqual Sub-Intervals\nUnequal Sub-Intervals\n\n\n\n\nWidth of Sub-Intervals\n\\(\\Delta x = \\frac{b - a}{n}\\) (constant)\n\\(\\Delta x_i = x_i - x_{i-1}\\) (varies)\n\n\nFormula\n\\(\\frac{\\Delta x}{2} \\left( y_0 + 2 y_1 + \\dots + 2 y_{n-1} + y_n \\right)\\)\n\\(\\sum \\frac{\\Delta x_i}{2} \\left( f(x_{i-1}) + f(x_i) \\right)\\)\n\n\nComputational Effort\nEasier to compute with uniform spacing\nMore complicated due to variable widths"
  },
  {
    "objectID": "reality-checks/index.html",
    "href": "reality-checks/index.html",
    "title": "Reality Checks",
    "section": "",
    "text": "Reality Check 1 - Stewart Platform Kinematics"
  },
  {
    "objectID": "homework/w02/exercise3-1-1a.html",
    "href": "homework/w02/exercise3-1-1a.html",
    "title": "Exercise 3.1.1a (C3-P1)",
    "section": "",
    "text": "Use Lagrange interpolation to find a polynomial that passes through the points (0, 1), (2, 3), (3, 0).\nThe Lagrange interpolation polynomial for three points (x_1, y_1), (x_2, y_2), and (x_3, y_3) is given by the formula:\nP(x) = y_1 \\frac{(x - x_2)(x - x_3)}{(x_1 - x_2)(x_1 - x_3)} + y_2 \\frac{(x - x_1)(x - x_3)}{(x_2 - x_1)(x_2 - x_3)} + y_3 \\frac{(x - x_1)(x - x_2)}{(x_3 - x_1)(x_3 - x_2)}\nThe points are:\n\n(x_1, y_1) = (0, 1)\n(x_2, y_2) = (2, 3)\n(x_3, y_3) = (3, 0)\n\n\n\n\nFirst term (corresponding to (x_1, y_1) = (0, 1)):\n\n\n1 \\cdot \\frac{(x - 2)(x - 3)}{(0 - 2)(0 - 3)} = 1 \\cdot \\frac{(x - 2)(x - 3)}{(-2)(-3)} = \\frac{(x - 2)(x - 3)}{6}\n\n\nSecond term (corresponding to (x_2, y_2) = (2, 3))\n\n\n3 \\cdot \\frac{(x - 0)(x - 3)}{(2 - 0)(2 - 3)} = 3 \\cdot \\frac{(x)(x - 3)}{(2)(-1)} = -\\frac{3x(x - 3)}{2}\n\n\nThird term (corresponding to (x_3, y_3) = (3, 0)):\n\n\n0 \\cdot \\frac{(x - 0)(x - 2)}{(3 - 0)(3 - 2)} = 0\n\n\n\n\n\nP(x) = \\frac{(x - 2)(x - 3)}{6} - \\frac{3x(x - 3)}{2}\n\n\n\n\nFirst term:\n\n\\frac{(x - 2)(x - 3)}{6} = \\frac{x^2 - 5x + 6}{6}\n\nSecond term:\n\n-\\frac{3x(x - 3)}{2} = -\\frac{3(x^2 - 3x)}{2} = -\\frac{3x^2}{2} + \\frac{9x}{2}\n\nNow, combine these two terms:\n\nP(x) = \\frac{x^2 - 5x + 6}{6} - \\left(\\frac{3x^2}{2} - \\frac{9x}{2}\\right)\n\nTo combine, first rewrite everything with a denominator of 6:\n\nP(x) = \\frac{x^2 - 5x + 6}{6} - \\frac{9x^2 - 27x}{6}\n\nNow simplify:\n\nP(x) = \\frac{x^2 - 5x + 6 - 9x^2 + 27x}{6}\n\n\nP(x) = \\frac{-8x^2 + 22x + 6}{6}\n\nThis is the final polynomial:\n\nP(x) = \\frac{-4x^2 + 11x + 3}{3}\n\nThis is the interpolating polynomial that passes through the points (0, 1), (2, 3), and (3, 0).\n\n\nCreate graph with resulting polynomial\n# Define the Lagrange interpolating polynomial\ndef lagrange_polynomial(x):\n    return (-4 * x**2 + 11 * x + 3) / 3\n\n# Create an array of x values from -1 to 4 for the graph\nx_values = np.linspace(-1, 4, 400)\n\n# Compute the corresponding y values using the polynomial function\ny_values = lagrange_polynomial(x_values)\n\n# Plot the polynomial curve\nplt.figure(figsize=(8, 6))\nplt.plot(x_values, y_values, label=\"P(x) = (-4x^2 + 11x + 3) / 3\", color=\"blue\")\n\n# Plot the given points (0,1), (2,3), (3,0)\ndata_points_x = [0, 2, 3]\ndata_points_y = [1, 3, 0]\nplt.scatter(data_points_x, data_points_y, color=\"red\", label=\"Data Points\", zorder=5)\n\n# Add labels, title, and legend\nplt.title(\"Lagrange Interpolating Polynomial\")\nplt.xlabel(\"x\")\nplt.ylabel(\"P(x)\")\n\n# Set x and y ticks to have increments of 1\nplt.xticks(np.arange(-1, 5, 1))\nplt.yticks(np.arange(-6, 7, 1))\n\nplt.axhline(0, color='black',linewidth=0.5)\nplt.axvline(0, color='black',linewidth=0.5)\nplt.grid(True)\nplt.legend()\n\n# Show the plot\nplt.show()"
  },
  {
    "objectID": "homework/w02/exercise3-1-1a.html#question",
    "href": "homework/w02/exercise3-1-1a.html#question",
    "title": "Exercise 3.1.1a (C3-P1)",
    "section": "",
    "text": "Use Lagrange interpolation to find a polynomial that passes through the points (0, 1), (2, 3), (3, 0).\nThe Lagrange interpolation polynomial for three points (x_1, y_1), (x_2, y_2), and (x_3, y_3) is given by the formula:\nP(x) = y_1 \\frac{(x - x_2)(x - x_3)}{(x_1 - x_2)(x_1 - x_3)} + y_2 \\frac{(x - x_1)(x - x_3)}{(x_2 - x_1)(x_2 - x_3)} + y_3 \\frac{(x - x_1)(x - x_2)}{(x_3 - x_1)(x_3 - x_2)}\nThe points are:\n\n(x_1, y_1) = (0, 1)\n(x_2, y_2) = (2, 3)\n(x_3, y_3) = (3, 0)\n\n\n\n\nFirst term (corresponding to (x_1, y_1) = (0, 1)):\n\n\n1 \\cdot \\frac{(x - 2)(x - 3)}{(0 - 2)(0 - 3)} = 1 \\cdot \\frac{(x - 2)(x - 3)}{(-2)(-3)} = \\frac{(x - 2)(x - 3)}{6}\n\n\nSecond term (corresponding to (x_2, y_2) = (2, 3))\n\n\n3 \\cdot \\frac{(x - 0)(x - 3)}{(2 - 0)(2 - 3)} = 3 \\cdot \\frac{(x)(x - 3)}{(2)(-1)} = -\\frac{3x(x - 3)}{2}\n\n\nThird term (corresponding to (x_3, y_3) = (3, 0)):\n\n\n0 \\cdot \\frac{(x - 0)(x - 2)}{(3 - 0)(3 - 2)} = 0\n\n\n\n\n\nP(x) = \\frac{(x - 2)(x - 3)}{6} - \\frac{3x(x - 3)}{2}\n\n\n\n\nFirst term:\n\n\\frac{(x - 2)(x - 3)}{6} = \\frac{x^2 - 5x + 6}{6}\n\nSecond term:\n\n-\\frac{3x(x - 3)}{2} = -\\frac{3(x^2 - 3x)}{2} = -\\frac{3x^2}{2} + \\frac{9x}{2}\n\nNow, combine these two terms:\n\nP(x) = \\frac{x^2 - 5x + 6}{6} - \\left(\\frac{3x^2}{2} - \\frac{9x}{2}\\right)\n\nTo combine, first rewrite everything with a denominator of 6:\n\nP(x) = \\frac{x^2 - 5x + 6}{6} - \\frac{9x^2 - 27x}{6}\n\nNow simplify:\n\nP(x) = \\frac{x^2 - 5x + 6 - 9x^2 + 27x}{6}\n\n\nP(x) = \\frac{-8x^2 + 22x + 6}{6}\n\nThis is the final polynomial:\n\nP(x) = \\frac{-4x^2 + 11x + 3}{3}\n\nThis is the interpolating polynomial that passes through the points (0, 1), (2, 3), and (3, 0).\n\n\nCreate graph with resulting polynomial\n# Define the Lagrange interpolating polynomial\ndef lagrange_polynomial(x):\n    return (-4 * x**2 + 11 * x + 3) / 3\n\n# Create an array of x values from -1 to 4 for the graph\nx_values = np.linspace(-1, 4, 400)\n\n# Compute the corresponding y values using the polynomial function\ny_values = lagrange_polynomial(x_values)\n\n# Plot the polynomial curve\nplt.figure(figsize=(8, 6))\nplt.plot(x_values, y_values, label=\"P(x) = (-4x^2 + 11x + 3) / 3\", color=\"blue\")\n\n# Plot the given points (0,1), (2,3), (3,0)\ndata_points_x = [0, 2, 3]\ndata_points_y = [1, 3, 0]\nplt.scatter(data_points_x, data_points_y, color=\"red\", label=\"Data Points\", zorder=5)\n\n# Add labels, title, and legend\nplt.title(\"Lagrange Interpolating Polynomial\")\nplt.xlabel(\"x\")\nplt.ylabel(\"P(x)\")\n\n# Set x and y ticks to have increments of 1\nplt.xticks(np.arange(-1, 5, 1))\nplt.yticks(np.arange(-6, 7, 1))\n\nplt.axhline(0, color='black',linewidth=0.5)\nplt.axvline(0, color='black',linewidth=0.5)\nplt.grid(True)\nplt.legend()\n\n# Show the plot\nplt.show()"
  },
  {
    "objectID": "homework/w02/exercise3-1-2a.html",
    "href": "homework/w02/exercise3-1-2a.html",
    "title": "Exercise 3.1.2a (C3-P2)",
    "section": "",
    "text": "Use Newton’s Divided Differences to find a polynomial that passes through the points (0, 1), (2, 3), (3, 0).\n\n\nThe points are:\n\n(x_1, y_1) = (0, 1)\n(x_2, y_2) = (2, 3)\n(x_3, y_3) = (3, 0)\n\nWe will first construct the divided differences table and use it to construct the Newton interpolating polynomial.\n\n\n\n\n\n\nx\nf[x]\nf[x_1, x_2]\nf[x_1, x_2, x_3]\n\n\n\n\n0\n1\n\n\n\n\n2\n3\n1\n\n\n\n3\n0\n-3\n-\\frac{4}{3}\n\n\n\n\n\n\n\nZeroth order divided differences:\n f[x_1] = y_1 = 1, \\quad f[x_2] = y_2 = 3, \\quad f[x_3] = y_3 = 0 \nFirst order divided differences:\n f[x_1, x_2] = \\frac{f[x_2] - f[x_1]}{x_2 - x_1} = \\frac{3 - 1}{2 - 0} = \\frac{2}{2} = 1 \n f[x_2, x_3] = \\frac{f[x_3] - f[x_2]}{x_3 - x_2} = \\frac{0 - 3}{3 - 2} = \\frac{-3}{1} = -3 \nSecond order divided difference:\n f[x_1, x_2, x_3] = \\frac{f[x_2, x_3] - f[x_1, x_2]}{x_3 - x_1} = \\frac{-3 - 1}{3 - 0} = \\frac{-4}{3} \n\n\n\n\nThe Newton polynomial is given by:\n\nP(x) = f[x_1] + f[x_1, x_2](x - x_1) + f[x_1, x_2, x_3](x - x_1)(x - x_2)\n\nSubstitute the values:\n\nP(x) = 1 + 1(x - 0) + \\left(\\frac{-4}{3}\\right)(x - 0)(x - 2)\n\nSimplify:\n\nP(x) = 1 + x - \\frac{4}{3}(x(x - 2)) = 1 + x - \\frac{4}{3}(x^2 - 2x)\n\n\nP(x) = 1 + x - \\frac{4}{3}x^2 + \\frac{8}{3}x\n\nCombine like terms:\n\nP(x) = 1 + \\left(x + \\frac{8}{3}x\\right) - \\frac{4}{3}x^2 = 1 + \\frac{11x}{3} - \\frac{4x^2}{3}\n\nSo the final polynomial is:\n\nP(x) = \\frac{-4x^2 + 11x + 3}{3}\n\nThis is the Newton interpolating polynomial for the points (0, 1), (2, 3), and (3, 0).\n\n\nCreate graph with resulting polynomial\n# Define the Newton interpolating polynomial\ndef newton_polynomial(x):\n    return (-4 * x**2 + 11 * x + 3) / 3\n\n# Create an array of x values from -1 to 4 for the graph\nx_values = np.linspace(-1, 4, 400)\n\n# Compute the corresponding y values using the polynomial function\ny_values = newton_polynomial(x_values)\n\n# Plot the polynomial curve\nplt.figure(figsize=(8, 6))\nplt.plot(x_values, y_values, label=\"P(x) = (-4x^2 + 11x + 3) / 3\", color=\"blue\")\n\n# Plot the given points (0,1), (2,3), (3,0)\ndata_points_x = [0, 2, 3]\ndata_points_y = [1, 3, 0]\nplt.scatter(data_points_x, data_points_y, color=\"red\", label=\"Data Points\", zorder=5)\n\n# Add labels, title, and legend\nplt.title(\"Newton's Divided Differences Polynomial\")\nplt.xlabel(\"x\")\nplt.ylabel(\"P(x)\")\n\n# Set x and y ticks to have increments of 1\nplt.xticks(np.arange(-1, 5, 1))\nplt.yticks(np.arange(-6, 7, 1))\n\nplt.axhline(0, color='black',linewidth=0.5)\nplt.axvline(0, color='black',linewidth=0.5)\nplt.grid(True)\nplt.legend()\n\n# Show the plot\nplt.show()"
  },
  {
    "objectID": "homework/w02/exercise3-1-2a.html#question",
    "href": "homework/w02/exercise3-1-2a.html#question",
    "title": "Exercise 3.1.2a (C3-P2)",
    "section": "",
    "text": "Use Newton’s Divided Differences to find a polynomial that passes through the points (0, 1), (2, 3), (3, 0).\n\n\nThe points are:\n\n(x_1, y_1) = (0, 1)\n(x_2, y_2) = (2, 3)\n(x_3, y_3) = (3, 0)\n\nWe will first construct the divided differences table and use it to construct the Newton interpolating polynomial.\n\n\n\n\n\n\nx\nf[x]\nf[x_1, x_2]\nf[x_1, x_2, x_3]\n\n\n\n\n0\n1\n\n\n\n\n2\n3\n1\n\n\n\n3\n0\n-3\n-\\frac{4}{3}\n\n\n\n\n\n\n\nZeroth order divided differences:\n f[x_1] = y_1 = 1, \\quad f[x_2] = y_2 = 3, \\quad f[x_3] = y_3 = 0 \nFirst order divided differences:\n f[x_1, x_2] = \\frac{f[x_2] - f[x_1]}{x_2 - x_1} = \\frac{3 - 1}{2 - 0} = \\frac{2}{2} = 1 \n f[x_2, x_3] = \\frac{f[x_3] - f[x_2]}{x_3 - x_2} = \\frac{0 - 3}{3 - 2} = \\frac{-3}{1} = -3 \nSecond order divided difference:\n f[x_1, x_2, x_3] = \\frac{f[x_2, x_3] - f[x_1, x_2]}{x_3 - x_1} = \\frac{-3 - 1}{3 - 0} = \\frac{-4}{3} \n\n\n\n\nThe Newton polynomial is given by:\n\nP(x) = f[x_1] + f[x_1, x_2](x - x_1) + f[x_1, x_2, x_3](x - x_1)(x - x_2)\n\nSubstitute the values:\n\nP(x) = 1 + 1(x - 0) + \\left(\\frac{-4}{3}\\right)(x - 0)(x - 2)\n\nSimplify:\n\nP(x) = 1 + x - \\frac{4}{3}(x(x - 2)) = 1 + x - \\frac{4}{3}(x^2 - 2x)\n\n\nP(x) = 1 + x - \\frac{4}{3}x^2 + \\frac{8}{3}x\n\nCombine like terms:\n\nP(x) = 1 + \\left(x + \\frac{8}{3}x\\right) - \\frac{4}{3}x^2 = 1 + \\frac{11x}{3} - \\frac{4x^2}{3}\n\nSo the final polynomial is:\n\nP(x) = \\frac{-4x^2 + 11x + 3}{3}\n\nThis is the Newton interpolating polynomial for the points (0, 1), (2, 3), and (3, 0).\n\n\nCreate graph with resulting polynomial\n# Define the Newton interpolating polynomial\ndef newton_polynomial(x):\n    return (-4 * x**2 + 11 * x + 3) / 3\n\n# Create an array of x values from -1 to 4 for the graph\nx_values = np.linspace(-1, 4, 400)\n\n# Compute the corresponding y values using the polynomial function\ny_values = newton_polynomial(x_values)\n\n# Plot the polynomial curve\nplt.figure(figsize=(8, 6))\nplt.plot(x_values, y_values, label=\"P(x) = (-4x^2 + 11x + 3) / 3\", color=\"blue\")\n\n# Plot the given points (0,1), (2,3), (3,0)\ndata_points_x = [0, 2, 3]\ndata_points_y = [1, 3, 0]\nplt.scatter(data_points_x, data_points_y, color=\"red\", label=\"Data Points\", zorder=5)\n\n# Add labels, title, and legend\nplt.title(\"Newton's Divided Differences Polynomial\")\nplt.xlabel(\"x\")\nplt.ylabel(\"P(x)\")\n\n# Set x and y ticks to have increments of 1\nplt.xticks(np.arange(-1, 5, 1))\nplt.yticks(np.arange(-6, 7, 1))\n\nplt.axhline(0, color='black',linewidth=0.5)\nplt.axvline(0, color='black',linewidth=0.5)\nplt.grid(True)\nplt.legend()\n\n# Show the plot\nplt.show()"
  },
  {
    "objectID": "homework/w03/c0-p2.html",
    "href": "homework/w03/c0-p2.html",
    "title": "Exercise 3.1.1c (C3-P1)",
    "section": "",
    "text": "Create a Python function that takes as input three points (six scalars, three pairs, or perhaps a 6-element numpy array–choose a method that makes sense to you) and uses the matplotlib package to create a figure window and then render a triangle with small open circles at each of the points and straight lines between each pair of circles. Include code to save your figure to a .png or .jpg file. Validate your function with the points (1, 2), (2, 1), and (2, 3).\n\n\nCreate function and figure\n# Define the function\ndef plot_triangle(points, save_path='triangle_plot.png'):\n    \"\"\"\n    Takes an input of three points (a list of 3 tuples or a 3x2 numpy array)\n    and plots a triangle with small open circles at each of the points.\n    The triangle is rendered with lines connecting each point.\n\n    Parameters:\n    points (list of tuples or numpy array): Points representing the vertices of the triangle.\n    save_path (str): File path to save the plotted figure.\n    \"\"\"\n\n    # Ensure points is a numpy array\n    points = np.array(points)\n\n    # Check if the input is in the correct shape (3x2)\n    if points.shape != (3, 2):\n        raise ValueError(\"Input should be a list of 3 points, each as a pair of (x, y) coordinates.\")\n\n    # Extract the x and y coordinates\n    x_coords = points[:, 0]\n    y_coords = points[:, 1]\n\n    # Close the triangle by repeating the first point at the end\n    x_closed = np.append(x_coords, x_coords[0])\n    y_closed = np.append(y_coords, y_coords[0])\n\n    # Create the plot\n    plt.figure(figsize=(6, 6))\n\n    # Plot the triangle with open circles at each vertex\n    plt.plot(x_closed, y_closed, 'b-', marker='o', markerfacecolor='none',\n             markeredgecolor='r', markersize=10, label='Triangle')\n\n    # Set labels and title\n    plt.title(\"Triangle with Given Vertices\")\n    plt.xlabel(\"x\")\n    plt.ylabel(\"y\")\n\n    # Set axis limits for better visualization\n    plt.xlim(min(x_closed) - 1, max(x_closed) + 1)\n    plt.ylim(min(y_closed) - 1, max(y_closed) + 1)\n\n    # Add grid for better visualization\n    plt.grid(True)\n\n\n    # Save the figure\n    plt.savefig(save_path, dpi=300)\n\n    # Show the plot\n   #  plt.show()\n\n# Test the function with the points (1, 2), (2, 1), and (2, 3)\ntest_points = [(1, 2), (2, 1), (2, 3)]\nplot_triangle(test_points, save_path='triangle_plot.png')\n\n\n\n\n\n\n\n\n\n\n\n\nFunction Definition:\n\nplot_triangle: This function takes in three points and an optional save_path parameter to specify where to save the plot.\nParameters:\n\npoints: A list of three tuples representing the vertices of the triangle or a 3x2 numpy array.\nsave_path: The file path where the plot image will be saved (default is 'triangle_plot.png').\n\n\nInput Validation:\n\nThe function first converts the input points to a numpy array and checks if it has the correct shape (3, 2). If not, it raises a ValueError.\n\nPlotting:\n\nClosing the Triangle: To draw a complete triangle, the first point is appended to the end of the x_coords and y_coords arrays.\nPlotting Lines and Markers:\n\nThe triangle is plotted with blue lines ('b-') connecting the points.\nSmall open red circles (marker='o', markerfacecolor='none', markeredgecolor='r') are placed at each vertex.\n\nLabels and Grid: The plot includes titles, axis labels, and a grid for better visualization.\n\nSaving and Displaying the Plot:\n\nThe plot is saved as a .png file with a resolution of 300 DPI.\nThe plot window is then displayed using plt.show().\n\n\n\n\n\nAfter running the function with the test points (1, 2), (2, 1), and (2, 3), the resulting triangle will be saved as triangle_plot.png and displayed as shown below:\n\n\n\nTriangle Plot"
  },
  {
    "objectID": "homework/w03/c0-p2.html#question",
    "href": "homework/w03/c0-p2.html#question",
    "title": "Exercise 3.1.1c (C3-P1)",
    "section": "",
    "text": "Create a Python function that takes as input three points (six scalars, three pairs, or perhaps a 6-element numpy array–choose a method that makes sense to you) and uses the matplotlib package to create a figure window and then render a triangle with small open circles at each of the points and straight lines between each pair of circles. Include code to save your figure to a .png or .jpg file. Validate your function with the points (1, 2), (2, 1), and (2, 3).\n\n\nCreate function and figure\n# Define the function\ndef plot_triangle(points, save_path='triangle_plot.png'):\n    \"\"\"\n    Takes an input of three points (a list of 3 tuples or a 3x2 numpy array)\n    and plots a triangle with small open circles at each of the points.\n    The triangle is rendered with lines connecting each point.\n\n    Parameters:\n    points (list of tuples or numpy array): Points representing the vertices of the triangle.\n    save_path (str): File path to save the plotted figure.\n    \"\"\"\n\n    # Ensure points is a numpy array\n    points = np.array(points)\n\n    # Check if the input is in the correct shape (3x2)\n    if points.shape != (3, 2):\n        raise ValueError(\"Input should be a list of 3 points, each as a pair of (x, y) coordinates.\")\n\n    # Extract the x and y coordinates\n    x_coords = points[:, 0]\n    y_coords = points[:, 1]\n\n    # Close the triangle by repeating the first point at the end\n    x_closed = np.append(x_coords, x_coords[0])\n    y_closed = np.append(y_coords, y_coords[0])\n\n    # Create the plot\n    plt.figure(figsize=(6, 6))\n\n    # Plot the triangle with open circles at each vertex\n    plt.plot(x_closed, y_closed, 'b-', marker='o', markerfacecolor='none',\n             markeredgecolor='r', markersize=10, label='Triangle')\n\n    # Set labels and title\n    plt.title(\"Triangle with Given Vertices\")\n    plt.xlabel(\"x\")\n    plt.ylabel(\"y\")\n\n    # Set axis limits for better visualization\n    plt.xlim(min(x_closed) - 1, max(x_closed) + 1)\n    plt.ylim(min(y_closed) - 1, max(y_closed) + 1)\n\n    # Add grid for better visualization\n    plt.grid(True)\n\n\n    # Save the figure\n    plt.savefig(save_path, dpi=300)\n\n    # Show the plot\n   #  plt.show()\n\n# Test the function with the points (1, 2), (2, 1), and (2, 3)\ntest_points = [(1, 2), (2, 1), (2, 3)]\nplot_triangle(test_points, save_path='triangle_plot.png')\n\n\n\n\n\n\n\n\n\n\n\n\nFunction Definition:\n\nplot_triangle: This function takes in three points and an optional save_path parameter to specify where to save the plot.\nParameters:\n\npoints: A list of three tuples representing the vertices of the triangle or a 3x2 numpy array.\nsave_path: The file path where the plot image will be saved (default is 'triangle_plot.png').\n\n\nInput Validation:\n\nThe function first converts the input points to a numpy array and checks if it has the correct shape (3, 2). If not, it raises a ValueError.\n\nPlotting:\n\nClosing the Triangle: To draw a complete triangle, the first point is appended to the end of the x_coords and y_coords arrays.\nPlotting Lines and Markers:\n\nThe triangle is plotted with blue lines ('b-') connecting the points.\nSmall open red circles (marker='o', markerfacecolor='none', markeredgecolor='r') are placed at each vertex.\n\nLabels and Grid: The plot includes titles, axis labels, and a grid for better visualization.\n\nSaving and Displaying the Plot:\n\nThe plot is saved as a .png file with a resolution of 300 DPI.\nThe plot window is then displayed using plt.show().\n\n\n\n\n\nAfter running the function with the test points (1, 2), (2, 1), and (2, 3), the resulting triangle will be saved as triangle_plot.png and displayed as shown below:\n\n\n\nTriangle Plot"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "FALL 2024 - SCHEDULE",
    "section": "",
    "text": "Week\n\n\nMonday\n\n\nTuesday\n\n\nWednesday\n\n\nThursday\n\n\nFriday\n\n\n\n\n1\n\n\n16Chapter 1\n\n\n17\n\n\n18Chapter 1\n\n\n19\n\n\n20Chapter 1\n\n\n\n\n2\n\n\n23Add/DropChapter 1\n\n\n24\n\n\n25Chapter 1Quiz 1\n\n\n26\n\n\n27Chapter 3\n\n\n\n\n3\n\n\n30Chapter 3\n\n\n1\n\n\n2Chapter 3Quiz 2\n\n\n3\n\n\n4Chapter 3\n\n\n\n\n4\n\n\n7Chapter 3Reality Check 1\n\n\n8No W drop date\n\n\n9Chapter 5Quiz 3\n\n\n10\n\n\n11Chapter 5\n\n\n\n\n5\n\n\n14Chapter 5\n\n\n15\n\n\n16Chapter 5Quiz 4\n\n\n17\n\n\n18Chapter 5\n\n\n\n\n6\n\n\n21Exam 1 ReviewExam 1-2 Opens\n\n\n22\n\n\n23Exam 1-1In Class\n\n\n24Exam 1-2 Closes\n\n\n25Chapter 2\n\n\n\n\n7\n\n\n28Chapter 2\n\n\n29\n\n\n30Chapter 2\n\n\n31\n\n\n1Chapter 2\n\n\n\n\n8\n\n\n4Chapter 2\n\n\n5\n\n\n6Chapter 4Quiz 5\n\n\n7\n\n\n8Chapter 4\n\n\n\n\n9\n\n\n11Drop w/W dateChapter 42nd Reality Check\n\n\n12\n\n\n13Chapter 4Quiz 6\n\n\n14\n\n\n15Chapter 4\n\n\n\n\n10\n\n\n18Chapter 4\n\n\n19\n\n\n20Chapter 4\n\n\n21\n\n\n22Exam 2 ReviewExam 2-2 Opens\n\n\n\n\n11\n\n\n25Exam 2-1In Class\n\n\n26Exam 2-2 Closes\n\n\n27No Classes\n\n\n28Holiday\n\n\n29Holiday\n\n\n\n\n12\n\n\n2Chapter 10\n\n\n3Discontinuance\n\n\n4Chapter 10\n\n\n5\n\n\n6Chapter 10Quiz 7 (?)\n\n\n\n\n13\n\n\n9Chapter 10\n\n\n10\n\n\n11Chapter 10\n\n\n12\n\n\n13Chapter 10Exam 3-2 Opens\n\n\n\n\n14\n\n\n16Last Day of Class\n\n\n1710:30 Exam 3-1Exam 3-2 Closes3rd Reality Check\n\n\n18\n\n\n19Commencement\n\n\n20"
  }
]